{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b05131d02842e9bb59390b5826659c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import TextStreamer, GenerationConfig\n",
    "\n",
    "model_name='davidkim205/komt-mistral-7b-v1'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "def gen(x):\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.8,\n",
    "        top_p=0.8,\n",
    "        top_k=100,\n",
    "        max_new_tokens=512,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    q = f\"[INST]{x} [/INST]\"\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            q,\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda'),\n",
    "        generation_config=generation_config,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "    result_str = tokenizer.decode(gened[0])\n",
    "\n",
    "    start_tag = f\"\\n\\n### Response: \"\n",
    "    start_index = result_str.find(start_tag)\n",
    "\n",
    "    if start_index != -1:\n",
    "        result_str = result_str[start_index + len(start_tag):].strip()\n",
    "    return result_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "TEST_NAME = \"llm1\"\n",
    "\n",
    "# 데이터 관련\n",
    "os_name = platform.system()\n",
    "if os_name == 'Windows':\n",
    "    PRE_PATH = ''\n",
    "elif os_name == 'Linux':\n",
    "    PRE_PATH = '/kkh/'\n",
    "elif os_name == 'Darwin': # 맥\n",
    "    PRE_PATH = '/kkh/'\n",
    "DATA_PATH = PRE_PATH + \"data/\" # 대회에서 제공한 데이터\n",
    "OUTPUT_PATH = PRE_PATH + \"output/\" # 모델의 출력 값\n",
    "CHECKPOINT_PATH = PRE_PATH + \"checkpoint/\" # 모델의 최종 출력 값\n",
    "PREDICTION_PATH = PRE_PATH + \"prediction/\" # 최종 예측 값\n",
    "LOG_PATH = PRE_PATH + \"log/\"\n",
    "TRAIN_PATH = DATA_PATH + \"train_new2_temp.csv\"\n",
    "VALID_PATH = DATA_PATH + \"dev_new2.csv\"\n",
    "TEST_PATH = DATA_PATH + \"test.csv\"\n",
    "SUBMIT_PATH = PREDICTION_PATH + \"submission_\" + TEST_NAME + \".csv\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(TRAIN_PATH))\n",
    "val_df = pd.read_csv(os.path.join(VALID_PATH))\n",
    "test_df = pd.read_csv(os.path.join(TEST_PATH))\n",
    "\n",
    "sampled_df = train_df.sample(n=5, random_state=42)  # random_state는 결과를 재현 가능하게 합니다.\n",
    "combined_string = '\\n'.join(sampled_df.apply(lambda row: f\"{row['fname']}, {row['dialogue']}, {row['summary']}, {row['topic']}\", axis=1).tolist())\n",
    "print(combined_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3915 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화문: test_0\n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
      "<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/INST] 핵심 키워드: 직원, 메시지, 제한, 이메일, 공식 메모, 근무 시간, 경고, 직무 정지, 해고, 타이핑, 배포\n",
      "\n",
      "요약문: 모든 직원들에게 이메일 통신과 공식 메모로 통신을 제한하고, 메시지 프로그램 사용은 금지된다. 이 사무실 내에서 직원들은 이 새로운 정책에 따라 즉시 메시지를 계속 사용하지 않아야 하며, 두 번째 위반 시에는 해고될 것이다. 모든 직원에게 오후 4시 전에 타이핑하여 배포해야 한다.</s>\n",
      "\"<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요. [/INST] 핵심 키워드: 직원, 메시지, 제한, 이메일, 공식 메모, 근무 시간, 경고, 직무 정지, 해고, 타이핑, 배포\n",
      "\n",
      "요약문: 모든 직원들에게 이메일 통신과 공식 메모로 통신을 제한하고, 메시지 프로그램 사용은 금지된다. 이 사무실 내에서 직원들은 이 새로운 정책에 따라 즉시 메시지를 계속 사용하지 않아야 하며, 두 번째 위반 시에는 해고될 것이다. 모든 직원에게 오후 4시 전에 타이핑하여 배포해야 한다.</s>\"\n",
      "=====================================\n",
      "대화문: test_1\n",
      "#Person1#: 드디어 왔네! 왜 그렇게 오래 걸렸어?\n",
      "#Person2#: 또 교통 체증에 걸렸어. 까르푸 교차로에서 엄청난 교통 체증이 있었어.\n",
      "#Person1#: 그곳은 출퇴근 시간에 항상 교통이 많이 밀리는 편이야. 집에 가는 다른 길을 찾아 보도록 해. \n",
      "#Person2#: 솔직히 말하면 피할 수 없는 것 같아.\n",
      "#Person1#: 아마 너가 대중교통을 이용하기 시작한다면 더 좋을 것 같아.\n",
      "#Person2#: 그건 고려해봐야 할 것 같아. 대중교통 시스템이 꽤 괜찮아.\n",
      "#Person1#: 환경에도 더 좋을 거야.\n",
      "#Person2#: 알아. 내 차가 이 도시의 오염 문제에 얼마나 기여하고 있는지 나도 느낄 수 있어.\n",
      "#Person1#: 지하철을 타는 것이 운전하는 것보다 훨씬 스트레스를 덜 받을 수 있을 거야.\n",
      "#Person2#: 유일한 문제는 차를 가지고 있는 자유를 정말로 그리워할 것 같다는 거야.\n",
      "#Person1#: 그럼, 날씨가 좋을 때는 자전거로 출근해봐. 그게 너의 차가 주는 자유와 같을 거야.\n",
      "#Person2#: 그게 맞는 말이야. 운동도 좀 해야겠어!\n",
      "#Person1#: 그럼, 너 출근할 때 운전하는 걸 그만두려고 해?\n",
      "#Person2#: 그래, 나에게도 환경에게도 좋지 않아.\n",
      "<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 드디어 왔네! 왜 그렇게 오래 걸렸어?\n",
      "#Person2#: 또 교통 체증에 걸렸어. 까르푸 교차로에서 엄청난 교통 체증이 있었어.\n",
      "#Person1#: 그곳은 출퇴근 시간에 항상 교통이 많이 밀리는 편이야. 집에 가는 다른 길을 찾아 보도록 해. \n",
      "#Person2#: 솔직히 말하면 피할 수 없는 것 같아.\n",
      "#Person1#: 아마 너가 대중교통을 이용하기 시작한다면 더 좋을 것 같아.\n",
      "#Person2#: 그건 고려해봐야 할 것 같아. 대중교통 시스템이 꽤 괜찮아.\n",
      "#Person1#: 환경에도 더 좋을 거야.\n",
      "#Person2#: 알아. 내 차가 이 도시의 오염 문제에 얼마나 기여하고 있는지 나도 느낄 수 있어.\n",
      "#Person1#: 지하철을 타는 것이 운전하는 것보다 훨씬 스트레스를 덜 받을 수 있을 거야.\n",
      "#Person2#: 유일한 문제는 차를 가지고 있는 자유를 정말로 그리워할 것 같다는 거야.\n",
      "#Person1#: 그럼, 날씨가 좋을 때는 자전거로 출근해봐. 그게 너의 차가 주는 자유와 같을 거야.\n",
      "#Person2#: 그게 맞는 말이야. 운동도 좀 해야겠어!\n",
      "#Person1#: 그럼, 너 출근할 때 운전하는 걸 그만두려고 해?\n",
      "#Person2#: 그래, 나에게도 환경에게도 좋지 않아. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/INST] 핵심 키워드: 교통 체증, 대중교통, 자전거, 환경\n",
      "\n",
      "요약문: \"교통 체증이 있었기 때문에 차를 이용해 출근했다. 대중교통을 이용하거나 자전거를 타는 것이 더 좋을 것 같다. 자전거를 타면 운동도 할 수 있고, 환경에도 좋다. 그래서 차를 이용하지 말고 대중교통이나 자전거를 이용해 출근하자.\"</s>\n",
      "\"<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 드디어 왔네! 왜 그렇게 오래 걸렸어?\n",
      "#Person2#: 또 교통 체증에 걸렸어. 까르푸 교차로에서 엄청난 교통 체증이 있었어.\n",
      "#Person1#: 그곳은 출퇴근 시간에 항상 교통이 많이 밀리는 편이야. 집에 가는 다른 길을 찾아 보도록 해. \n",
      "#Person2#: 솔직히 말하면 피할 수 없는 것 같아.\n",
      "#Person1#: 아마 너가 대중교통을 이용하기 시작한다면 더 좋을 것 같아.\n",
      "#Person2#: 그건 고려해봐야 할 것 같아. 대중교통 시스템이 꽤 괜찮아.\n",
      "#Person1#: 환경에도 더 좋을 거야.\n",
      "#Person2#: 알아. 내 차가 이 도시의 오염 문제에 얼마나 기여하고 있는지 나도 느낄 수 있어.\n",
      "#Person1#: 지하철을 타는 것이 운전하는 것보다 훨씬 스트레스를 덜 받을 수 있을 거야.\n",
      "#Person2#: 유일한 문제는 차를 가지고 있는 자유를 정말로 그리워할 것 같다는 거야.\n",
      "#Person1#: 그럼, 날씨가 좋을 때는 자전거로 출근해봐. 그게 너의 차가 주는 자유와 같을 거야.\n",
      "#Person2#: 그게 맞는 말이야. 운동도 좀 해야겠어!\n",
      "#Person1#: 그럼, 너 출근할 때 운전하는 걸 그만두려고 해?\n",
      "#Person2#: 그래, 나에게도 환경에게도 좋지 않아. [/INST] 핵심 키워드: 교통 체증, 대중교통, 자전거, 환경\n",
      "\n",
      "요약문: \"교통 체증이 있었기 때문에 차를 이용해 출근했다. 대중교통을 이용하거나 자전거를 타는 것이 더 좋을 것 같다. 자전거를 타면 운동도 할 수 있고, 환경에도 좋다. 그래서 차를 이용하지 말고 대중교통이나 자전거를 이용해 출근하자.\"</s>\"\n",
      "=====================================\n",
      "대화문: test_2\n",
      "#Person1#: 케이트, 무슨 일이 일어났는지 너는 믿지 못할거야. \n",
      "#Person2#: 어떤 말이야?\n",
      "#Person1#: 마샤와 히어로가 이혼하려고 해.\n",
      "#Person2#: 너 농담하는 거지. 무슨 일이 있었어?\n",
      "#Person1#: 음, 정확히는 모르겠지만, 그들이 2개월 동안 별거 중이다가 이혼을 신청했다고 들었어.\n",
      "#Person2#: 정말 놀랍다. 나는 항상 그들이 잘 어울린다고 생각했어. 아이들은 어떻게 되는 거야? 어느 쪽이 양육권을 가지게 되는 거야?\n",
      "#Person1#: 마샤가 양육권을 가지게 되는 것 같아, 집과 주식을 누가 소유하는지에 대한 다툼도 없었고, 다른 세부 사항을 가지고 이혼에 이의를 제기하는 일도 없었대.\n",
      "#Person2#: 우리가 평소에 듣던 이혼 소식과는 다르네. 그래도, 여전히 믿기지 않아, 마샤와 히어로, 완벽한 커플이었는데. 이혼이 최종적으로 언제 확정되는 거야?\n",
      "#Person1#: 새해 초에 확정될 것 같아.\n",
      "<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 케이트, 무슨 일이 일어났는지 너는 믿지 못할거야. \n",
      "#Person2#: 어떤 말이야?\n",
      "#Person1#: 마샤와 히어로가 이혼하려고 해.\n",
      "#Person2#: 너 농담하는 거지. 무슨 일이 있었어?\n",
      "#Person1#: 음, 정확히는 모르겠지만, 그들이 2개월 동안 별거 중이다가 이혼을 신청했다고 들었어.\n",
      "#Person2#: 정말 놀랍다. 나는 항상 그들이 잘 어울린다고 생각했어. 아이들은 어떻게 되는 거야? 어느 쪽이 양육권을 가지게 되는 거야?\n",
      "#Person1#: 마샤가 양육권을 가지게 되는 것 같아, 집과 주식을 누가 소유하는지에 대한 다툼도 없었고, 다른 세부 사항을 가지고 이혼에 이의를 제기하는 일도 없었대.\n",
      "#Person2#: 우리가 평소에 듣던 이혼 소식과는 다르네. 그래도, 여전히 믿기지 않아, 마샤와 히어로, 완벽한 커플이었는데. 이혼이 최종적으로 언제 확정되는 거야?\n",
      "#Person1#: 새해 초에 확정될 것 같아. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/INST] 핵심 키워드: 이혼, 마샤, 히어로, 양육권, 이혼 소식, 확정, 마샤와 히어로\n",
      "\n",
      "요약문: 마샤와 히어로가 이혼하려고 하는 소식이 전해졌다. 마샤가 양육권을 가지게 되는 것 같아, 집과 주식을 누가 소유하는지에 대한 다툼도 없었고, 다른 세부 사항을 가지고 이혼에 이의를 제기하는 일도 없었다. 새해 초에 확정될 것 같아.</s>\n",
      "\"<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 케이트, 무슨 일이 일어났는지 너는 믿지 못할거야. \n",
      "#Person2#: 어떤 말이야?\n",
      "#Person1#: 마샤와 히어로가 이혼하려고 해.\n",
      "#Person2#: 너 농담하는 거지. 무슨 일이 있었어?\n",
      "#Person1#: 음, 정확히는 모르겠지만, 그들이 2개월 동안 별거 중이다가 이혼을 신청했다고 들었어.\n",
      "#Person2#: 정말 놀랍다. 나는 항상 그들이 잘 어울린다고 생각했어. 아이들은 어떻게 되는 거야? 어느 쪽이 양육권을 가지게 되는 거야?\n",
      "#Person1#: 마샤가 양육권을 가지게 되는 것 같아, 집과 주식을 누가 소유하는지에 대한 다툼도 없었고, 다른 세부 사항을 가지고 이혼에 이의를 제기하는 일도 없었대.\n",
      "#Person2#: 우리가 평소에 듣던 이혼 소식과는 다르네. 그래도, 여전히 믿기지 않아, 마샤와 히어로, 완벽한 커플이었는데. 이혼이 최종적으로 언제 확정되는 거야?\n",
      "#Person1#: 새해 초에 확정될 것 같아. [/INST] 핵심 키워드: 이혼, 마샤, 히어로, 양육권, 이혼 소식, 확정, 마샤와 히어로\n",
      "\n",
      "요약문: 마샤와 히어로가 이혼하려고 하는 소식이 전해졌다. 마샤가 양육권을 가지게 되는 것 같아, 집과 주식을 누가 소유하는지에 대한 다툼도 없었고, 다른 세부 사항을 가지고 이혼에 이의를 제기하는 일도 없었다. 새해 초에 확정될 것 같아.</s>\"\n",
      "=====================================\n",
      "대화문: test_3\n",
      "#Person1#: 생일 축하해, 이건 너를 위한 거야, 브라이언.\n",
      "#Person2#: 기억해줘서 너무 행복해, 들어와서 파티를 즐겨. 모두 여기 있어, 분명히 너도 즐거울 거야.\n",
      "#Person1#: 브라이언, 너와 춤을 추는 기쁨을 가져도 될까?\n",
      "#Person2#: 좋아.\n",
      "#Person1#: 정말 멋진 파티야.\n",
      "#Person2#: 그래, 넌 항상 모두에게 인기가 많아. 그리고 오늘 너는 정말 예뻐 보여.\n",
      "#Person1#: 고마워, 그런 말 해줘서. 내 목걸이가 드레스와 잘 어울리길 바라. 둘 다 나를 잘 보이게 해주는 것 같아.\n",
      "#Person2#: 넌 멋져, 정말로 빛나고 있어.\n",
      "#Person1#: 고마워, 이건 정말 좋은 파티야. 너의 생일을 축하하기 위해 함께 술 한 잔 해야겠어\n",
      "<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 생일 축하해, 이건 너를 위한 거야, 브라이언.\n",
      "#Person2#: 기억해줘서 너무 행복해, 들어와서 파티를 즐겨. 모두 여기 있어, 분명히 너도 즐거울 거야.\n",
      "#Person1#: 브라이언, 너와 춤을 추는 기쁨을 가져도 될까?\n",
      "#Person2#: 좋아.\n",
      "#Person1#: 정말 멋진 파티야.\n",
      "#Person2#: 그래, 넌 항상 모두에게 인기가 많아. 그리고 오늘 너는 정말 예뻐 보여.\n",
      "#Person1#: 고마워, 그런 말 해줘서. 내 목걸이가 드레스와 잘 어울리길 바라. 둘 다 나를 잘 보이게 해주는 것 같아.\n",
      "#Person2#: 넌 멋져, 정말로 빛나고 있어.\n",
      "#Person1#: 고마워, 이건 정말 좋은 파티야. 너의 생일을 축하하기 위해 함께 술 한 잔 해야겠어 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/INST] 핵심 키워드: 파티, 생일, 모든 것, 인기, 예뻐, 목걸이, 멋지다, 춤, 잘 어울리다, 술\n",
      "\n",
      "요약문: 파티는 모든 것이 너무 예쁘고, 멋지다. 그리고 내 목걸이와 잘 어울리며, 인기가 많고, 너는 예뻐 보인다. 그래서 춤을 추는 기쁨을 느낄 수 있고, 술을 함께 해야겠어.</s>\n",
      "\"<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 생일 축하해, 이건 너를 위한 거야, 브라이언.\n",
      "#Person2#: 기억해줘서 너무 행복해, 들어와서 파티를 즐겨. 모두 여기 있어, 분명히 너도 즐거울 거야.\n",
      "#Person1#: 브라이언, 너와 춤을 추는 기쁨을 가져도 될까?\n",
      "#Person2#: 좋아.\n",
      "#Person1#: 정말 멋진 파티야.\n",
      "#Person2#: 그래, 넌 항상 모두에게 인기가 많아. 그리고 오늘 너는 정말 예뻐 보여.\n",
      "#Person1#: 고마워, 그런 말 해줘서. 내 목걸이가 드레스와 잘 어울리길 바라. 둘 다 나를 잘 보이게 해주는 것 같아.\n",
      "#Person2#: 넌 멋져, 정말로 빛나고 있어.\n",
      "#Person1#: 고마워, 이건 정말 좋은 파티야. 너의 생일을 축하하기 위해 함께 술 한 잔 해야겠어 [/INST] 핵심 키워드: 파티, 생일, 모든 것, 인기, 예뻐, 목걸이, 멋지다, 춤, 잘 어울리다, 술\n",
      "\n",
      "요약문: 파티는 모든 것이 너무 예쁘고, 멋지다. 그리고 내 목걸이와 잘 어울리며, 인기가 많고, 너는 예뻐 보인다. 그래서 춤을 추는 기쁨을 느낄 수 있고, 술을 함께 해야겠어.</s>\"\n",
      "=====================================\n",
      "대화문: test_4\n",
      "#Person1#: 이 올림픽 공원이 정말 크네요!\n",
      "#Person2#: 네. 지금 우리는 이 공원의 중심인 올림픽 스타디움에 있어요. \n",
      "#Person1#: 멋지네요! 언제 완공될 예정인가요?\n",
      "#Person2#: 이 스타디움은 6월에 완공될 예정이예요. \n",
      "#Person1#: 관람석에는 몇 개의 좌석이 있나요?\n",
      "#Person2#: 아, 총 5000개의 좌석이 있어요. \n",
      "#Person1#: 이렇게 크다니 몰랐어요!\n",
      "#Person2#: 그렇습니다! 저기 보세요, 그것들이 트랙이에요. 그리고 점프 피트는 저쪽에 있어요.\n",
      "#Person1#: 아... 알겠습니다. 저기요, 이 표지판을 보세요, 등반 금지예요. \n",
      "#Person2#: 우리는 외국인 방문객을 위해 영어로 번역된 표지판을 많이 설치했어요. \n",
      "<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 이 올림픽 공원이 정말 크네요!\n",
      "#Person2#: 네. 지금 우리는 이 공원의 중심인 올림픽 스타디움에 있어요. \n",
      "#Person1#: 멋지네요! 언제 완공될 예정인가요?\n",
      "#Person2#: 이 스타디움은 6월에 완공될 예정이예요. \n",
      "#Person1#: 관람석에는 몇 개의 좌석이 있나요?\n",
      "#Person2#: 아, 총 5000개의 좌석이 있어요. \n",
      "#Person1#: 이렇게 크다니 몰랐어요!\n",
      "#Person2#: 그렇습니다! 저기 보세요, 그것들이 트랙이에요. 그리고 점프 피트는 저쪽에 있어요.\n",
      "#Person1#: 아... 알겠습니다. 저기요, 이 표지판을 보세요, 등반 금지예요. \n",
      "#Person2#: 우리는 외국인 방문객을 위해 영어로 번역된 표지판을 많이 설치했어요.  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/INST] 핵심 키워드: 올림픽 스타디움, 완성, 좌석, 등반 금지\n",
      "\n",
      "요약문: 이 올림픽 스타디움은 6월에 완공될 예정이며, 총 5000개의 좌석이 있습니다. 이 공원에는 트랙이와 점프 피트가 있습니다. 하지만 등반은 금지되어 있습니다.</s>\n",
      "\"<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 이 올림픽 공원이 정말 크네요!\n",
      "#Person2#: 네. 지금 우리는 이 공원의 중심인 올림픽 스타디움에 있어요. \n",
      "#Person1#: 멋지네요! 언제 완공될 예정인가요?\n",
      "#Person2#: 이 스타디움은 6월에 완공될 예정이예요. \n",
      "#Person1#: 관람석에는 몇 개의 좌석이 있나요?\n",
      "#Person2#: 아, 총 5000개의 좌석이 있어요. \n",
      "#Person1#: 이렇게 크다니 몰랐어요!\n",
      "#Person2#: 그렇습니다! 저기 보세요, 그것들이 트랙이에요. 그리고 점프 피트는 저쪽에 있어요.\n",
      "#Person1#: 아... 알겠습니다. 저기요, 이 표지판을 보세요, 등반 금지예요. \n",
      "#Person2#: 우리는 외국인 방문객을 위해 영어로 번역된 표지판을 많이 설치했어요.  [/INST] 핵심 키워드: 올림픽 스타디움, 완성, 좌석, 등반 금지\n",
      "\n",
      "요약문: 이 올림픽 스타디움은 6월에 완공될 예정이며, 총 5000개의 좌석이 있습니다. 이 공원에는 트랙이와 점프 피트가 있습니다. 하지만 등반은 금지되어 있습니다.</s>\"\n",
      "=====================================\n",
      "대화문: test_5\n",
      "#Person1#: 진짜 짜증나! 이런 회사에서 일하는 건 나에게 아무런 도움이 안 돼!\n",
      "#Person2#: 그럼 어떻게 할 거야? 그냥 그만두려고?\n",
      "#Person1#: 그게 바로 내가 할 거야! 내 회사를 창업하기로 결정했어! 사업 계획서를 작성하고, 투자자를 모집하고, 나 자신을 위해 일하기로 했어!\n",
      "#Person2#: 너 사업 계획서를 작성해 본 적 있어?\n",
      "#Person1#: 음, 아니, 그렇게 어렵지 않을 거야! 그러니까, 당신이 어떤 사업을 하고, 어떻게 일을 할 것인지 설명하면 되는 거잖아, 그게 전부지? \n",
      "#Person2#: 너는 더 이상 틀릴 수 없어! 잘 작성된 사업 계획서에는 사업 아이디어를 두 페이지 이내로 강조하는 요약문이 포함되어야 해. 그리고 회사에 대해 설명해야 해. 법적 구조, 역사 등의 정보를 포함해서 말이야.\n",
      "#Person1#: 음, 그 정도면 충분히 할 수 있을 것 같아.\n",
      "#Person2#: 기다려, 더 있어! 그 다음에는 상품이나 서비스를 소개하고 설명해야 해. 그것들이 무엇이고 경쟁자와 어떻게 다른지 말이야. 그리고 어려운 부분인 시장 분석이야. 수백 가지 변수를 조사하고 분석해야 해! 1인당 GDP부터 인구가 평균적으로 얼마나 많은 아이를 가지고 있는지와 같은 사회경제적 요인을 고려해야 해! 이 모든 정보는 당신이 전략과 실행 단계로 넘어가서 실제로 어떻게 아이디어를 실행할 것인지 자세히 설명할 수 있도록 도와줄 거야.\n",
      "#Person1#: 이런. 그게 다야?\n",
      "#Person2#: 거의 다야, 투자자들에게 가장 중요한 정보는 재무 분석이야. 여기서 매출, 현금 흐름, 이익을 계산하고 예측해야 해. 결국, 사람들은 투자에 대한 수익을 언제 볼 수 있을지 알고 싶어할 거야!\n",
      "#Person1#: 음. 나는 그냥 내 예전 일을 계속하고 사업을 시작하는 모든 번거로움을 피할 거 같아!\n",
      "<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 진짜 짜증나! 이런 회사에서 일하는 건 나에게 아무런 도움이 안 돼!\n",
      "#Person2#: 그럼 어떻게 할 거야? 그냥 그만두려고?\n",
      "#Person1#: 그게 바로 내가 할 거야! 내 회사를 창업하기로 결정했어! 사업 계획서를 작성하고, 투자자를 모집하고, 나 자신을 위해 일하기로 했어!\n",
      "#Person2#: 너 사업 계획서를 작성해 본 적 있어?\n",
      "#Person1#: 음, 아니, 그렇게 어렵지 않을 거야! 그러니까, 당신이 어떤 사업을 하고, 어떻게 일을 할 것인지 설명하면 되는 거잖아, 그게 전부지? \n",
      "#Person2#: 너는 더 이상 틀릴 수 없어! 잘 작성된 사업 계획서에는 사업 아이디어를 두 페이지 이내로 강조하는 요약문이 포함되어야 해. 그리고 회사에 대해 설명해야 해. 법적 구조, 역사 등의 정보를 포함해서 말이야.\n",
      "#Person1#: 음, 그 정도면 충분히 할 수 있을 것 같아.\n",
      "#Person2#: 기다려, 더 있어! 그 다음에는 상품이나 서비스를 소개하고 설명해야 해. 그것들이 무엇이고 경쟁자와 어떻게 다른지 말이야. 그리고 어려운 부분인 시장 분석이야. 수백 가지 변수를 조사하고 분석해야 해! 1인당 GDP부터 인구가 평균적으로 얼마나 많은 아이를 가지고 있는지와 같은 사회경제적 요인을 고려해야 해! 이 모든 정보는 당신이 전략과 실행 단계로 넘어가서 실제로 어떻게 아이디어를 실행할 것인지 자세히 설명할 수 있도록 도와줄 거야.\n",
      "#Person1#: 이런. 그게 다야?\n",
      "#Person2#: 거의 다야, 투자자들에게 가장 중요한 정보는 재무 분석이야. 여기서 매출, 현금 흐름, 이익을 계산하고 예측해야 해. 결국, 사람들은 투자에 대한 수익을 언제 볼 수 있을지 알고 싶어할 거야!\n",
      "#Person1#: 음. 나는 그냥 내 예전 일을 계속하고 사업을 시작하는 모든 번거로움을 피할 거 같아! "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/INST] 핵심 키워드: 창업, 사업 계획서, 회사, 투자자, 재무 분석, 회사 설명, 상품 소개, 시장 분석, 예측\n",
      "\n",
      "요약문: 이런 회사에서 일하는 건 나에게 아무런 도움이 안 돼. 그래서 내 회사를 창업하기로 결정했어. 사업 계획서를 작성하고, 투자자를 모집하고, 나 자신을 위해 일하기로 했어. 사업 계획서에는 사업 아이디어를 두 페이지 이내로 강조하는 요약문이 포함되어야 하고, 회사에 대해 설명해야 해. 법적 구조, 역사 등의 정보를 포함해서 말이야. 그리고 상품이나 서비스를 소개하고 설명해야 해. 그것들이 무엇이고 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m대화문: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcombined_string\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdialogue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=====================================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mgen\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m GenerationConfig(\n\u001b[1;32m     11\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m     12\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m gened \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m result_str \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(gened[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     32\u001b[0m start_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Response: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1033\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1030\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1033\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1047\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:808\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    797\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    798\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    799\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    805\u001b[0m         cache_position,\n\u001b[1;32m    806\u001b[0m     )\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 808\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:549\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:443\u001b[0m, in \u001b[0;36mMistralSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    432\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    433\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    439\u001b[0m     )\n\u001b[1;32m    441\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 443\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    445\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:355\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    348\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    349\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    350\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    351\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    352\u001b[0m         ):\n\u001b[1;32m    353\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    365\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    366\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/utils/modeling.py:416\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    414\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 416\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    row['summary'] = '\"' + gen(f\"{combined_string} \\n\\n\\n\\\n",
    "        - 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\\n\\\n",
    "        - 아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\\n\\\n",
    "        - 요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\\n\\\n",
    "        - 그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\\n\\\n",
    "    \\n{row['dialogue']}\") + '\"'\n",
    "    print(f\"@ row['fname']: {row['fname']}\")\n",
    "    print(f\"@ row['dialogue']: {row['dialogue']}\")\n",
    "    print(f\"@ row['summary']: {row['summary']}\")\n",
    "    print('=====================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경�<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경 \n",
      "\n",
      "\n",
      "        - 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "        - 아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "        - 요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "        - 요약문의 형태는 대화문을 제 3자가 설명하듯이 적어줘.\n",
      "        - 사람 이름 대신에, #Person1# 이나 #Person2# 와 같은 키워드 형태로 넣어줘.\n",
      "        - 그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m test_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 3\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcombined_string\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m        - 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m        - 아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m        - 요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m        - 요약문의 형태는 대화문을 제 3자가 설명하듯이 적어줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m        - 사람 이름 대신에, #Person1# 이나 #Person2# 와 같은 키워드 형태로 넣어줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;43m        - 그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdialogue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@ row[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@ row[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mgen\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m GenerationConfig(\n\u001b[1;32m     11\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m     12\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m gened \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m result_str \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(gened[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     32\u001b[0m start_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Response: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1047\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1033\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1034\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1035\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1044\u001b[0m )\n\u001b[1;32m   1046\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1047\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m   1050\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "summary_list = []\n",
    "for index, row in test_df.iterrows():\n",
    "    row['summary'] = '\"' + gen(f\"{combined_string} \\n\\n\\n\\\n",
    "        - 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\\n\\\n",
    "        - 아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\\n\\\n",
    "        - 요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\\n\\\n",
    "        - 요약문의 형태는 대화문을 제 3자가 설명하듯이 적어줘.\\n\\\n",
    "        - 사람 이름 대신에, #Person1# 이나 #Person2# 와 같은 키워드 형태로 넣어줘.\\n\\\n",
    "        - 그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\\n\\\n",
    "    \\n{row['dialogue']}\") + '\"'\n",
    "    print(f\"@ row['fname']: {row['fname']}\")\n",
    "    print(f\"@ row['dialogue']: {row['dialogue']}\")\n",
    "    print(f\"@ row['summary']: {row['summary']}\")\n",
    "    print('=====================================')\n",
    "    summary_list.append(row['summary'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
