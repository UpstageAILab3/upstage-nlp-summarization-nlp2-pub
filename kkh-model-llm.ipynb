{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8363a6099145f2800bbd112b335feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import TextStreamer, GenerationConfig\n",
    "\n",
    "model_name='davidkim205/komt-mistral-7b-v1'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16, low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "def gen(x):\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=0.8,\n",
    "        top_p=0.8,\n",
    "        top_k=100,\n",
    "        max_new_tokens=512,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    q = f\"[INST]{x} [/INST]\"\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            q,\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda'),\n",
    "        generation_config=generation_config,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "    result_str = tokenizer.decode(gened[0])\n",
    "\n",
    "    start_tag = f\"\\n\\n### Response: \"\n",
    "    start_index = result_str.find(start_tag)\n",
    "\n",
    "    if start_index != -1:\n",
    "        result_str = result_str[start_index + len(start_tag):].strip()\n",
    "    return result_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경\n",
      "train_9762, #Person1#: 오늘은 사람들이 어떻게 건강을 유지하는지 알아보려고 합니다. 죄송하지만, 당신은 정말 건강해 보여요. 어떻게 건강을 유지하시나요?\n",
      "#Person2#: 별다른 비결은 없어요. 비 오지 않는 날에는 매일 자전거로 출근하고, 음식을 좋아해서 원할 때 먹어요. 다만 밤 9시 이후에는 먹지 않으려고 노력하고 있어요.\n",
      "#Person1#: 정말요? 자전거로 출근하려면 얼마나 걸리나요?\n",
      "#Person2#: 대략 45분 정도 걸려요.\n",
      "#Person1#: 출근 후에 다른 운동을 하시나요?\n",
      "#Person2#: 아니요, 대부분 집에 가서 저녁을 먹는 편이에요.\n",
      "#Person1#: 알겠어요, 감사합니다. 다른 분에게도 여쭤봐야겠네요. 실례합니다., #Person1#은 건강 유지 방법에 대해 #Person2#에게 인터뷰를 합니다. #Person2#는 자전거로 출근하고 밤 9시 이후에는 먹지 않는다고 말합니다., 인터뷰\n",
      "train_9620, #Person1#: 후식으로 뭐 드시고 싶으세요?\n",
      "#Person2#: 뭐 있나요?\n",
      "#Person1#: 애플 파이, 아이스크림, 초콜릿 케이크, 그리고 과일 칵테일이 있어요.\n",
      "#Person2#: 애플 파이에 아이스크림을 더할 수 있나요?\n",
      "#Person1#: 물론이죠. 오늘 아침에 애플 파이를 만들었어요. 그래서 아주 맛있고 신선해요.\n",
      "#Person2#: 집에서 만든 애플 파이 정말 맛있어요. 레몬에이드 한 잔 더 먹을 수 있을까요?\n",
      "#Person1#: 그럼요. 직접 가져가시겠어요? 냉장고에 있어요.\n",
      "#Person2#: 네. 음료 드실래요?\n",
      "#Person1#: 네. 아이스티 하나 먹을게요. 레몬에이드 옆에 있을 거예요.\n",
      "#Person2#: 후식은 드시나요?\n",
      "#Person1#: 저도 애플 파이 먹을 거예요, 하지만 아이스크림은 빼고요. 체중조절 중이라서요., #Person2#는 #Person1#이 만든 애플 파이와 레몬에이드를 먹을 예정입니다. #Person1#은 아이스티와 아이스크림 없는 애플 파이를 먹을 예정인데, 이는 #Person1#이 체중을 조절하고 있기 때문입니다., 후식\n",
      "train_513, #Person1#: 안녕하세요, 로라, 어떤 것에 대해 이야기하고 싶으신가요?\n",
      "#Person2#: 안녕하세요, 스미스 교수님. 저는 전공을 바꾸는 것에 대해 이야기하고 싶어요. 저는 3년 만에 졸업 하면 미술관에서 일하려고 결정했고, 그래서 저는 제 전공을 미술사로 바꾸어야 한다고 생각해요.\n",
      "#Person1#: 로라, 이 결정에 대해 좀 더 생각해 보시는 것이 어떨까요? 당신은 경영학을 전공하면서 좋은 성적을 거두었고, 모든 조직은 좋은 관리자가 필요하다는 것을 알아두세요.\n",
      "#Person2#: 그건 사실이지만, 저는 여전히 미술에 대해 많이 알아야 하지 않나요?\n",
      "#Person1#: 미술사에 대한 몇 가지 강의에 참석하고 지역 미술관에서 일주일에 몇 시간씩 자원 봉사자로 일하며 그곳에서 일하는 것을 정말로 좋아하는지 확인해보세요., 로라는 경영에서 미술사로 전공을 바꾸고 싶어한다. 스미스 교수는 그녀에게 좀 더 생각한 후에 결정을 내리라고 조언한다., 전공 변경하기\n",
      "train_8295, #Person1#: 집을 구매하려는 제 제안에 대해 소유자들이 반대 제안을 내놓았나요?\n",
      "#Person2#: 귀하의 제안에 대한 반응으로 판매자들은 삼백삼십오만 달러의 반대 제안을 결정했습니다.\n",
      "#Person1#: 그것은 꽤 좋아 보이는데, 어떻게 해야 할지 잘 모르겠어요.\n",
      "#Person2#: 이 제안을 받아들이거나 거절하고 다른 제안을 내놓을 수 있습니다.\n",
      "#Person1#: 만약 다른 제안을 내고 그들이 거절한다면 어떻게 되나요?\n",
      "#Person2#: 개인적으로는 한 번 더 제안을 해보는 것을 고려해볼 것 같지만, 어떻게 할지 결정하는 것은 귀하에게 달려 있습니다.\n",
      "#Person1#: 삼백삼십만 달러로 반대 제안을 해보는 것은 어떨까요?\n",
      "#Person2#: 귀하의 현재 제안으로 판매자에게 연락하겠습니다.\n",
      "#Person1#: 이것이 꽤 빠르게 진행될 것이라고 생각하나요?\n",
      "#Person2#: 보통 두 번째 제안에 대한 반응은 첫 번째보다 조금 더 빠르게 진행됩니다., #Person2#는 #Person1#에게 판매자들이 #Person1#의 집 구매 제안에 대해 반대 제안을 결정했다고 알립니다. 그 후 #Person1#은 #Person2#의 조언에 따라 한 번 더 제안을 결정합니다., 반대 제안\n",
      "train_1985, #Person1#: 교수님, 약속을 잡을 수 있을까요?\n",
      "#Person2#: 내일 오후 2시에서 4시 사이에 시간이 됩니다. 특별히 원하는 시간이 있나요?\n",
      "#Person1#: 2시가 가장 좋을 것 같습니다.\n",
      "#Person2#: 좋습니다, 제 사무실 위치를 알고 있나요?\n",
      "#Person1#: 아니요, 잘 모르겠습니다.\n",
      "#Person2#: 기억하세요, E동 3층에 있습니다.\n",
      "#Person1#: 알겠습니다.\n",
      "#Person2#: 걱정하지 마세요, 도착하면 잘 찾을 수 있을 겁니다. 그때 만나죠.\n",
      "#Person1#: 그때 뵙겠습니다.\n",
      "#Person2#: 만나는 것을 기대하겠어요!, #Person1#은 #Person2#와의 약속을 잡고 싶어합니다. 그들은 언제 어디에서 만날지 확인합니다., 약속 잡기\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "TEST_NAME = \"llm1\"\n",
    "\n",
    "# 데이터 관련\n",
    "os_name = platform.system()\n",
    "if os_name == 'Windows':\n",
    "    PRE_PATH = ''\n",
    "elif os_name == 'Linux':\n",
    "    PRE_PATH = '/kkh/'\n",
    "elif os_name == 'Darwin': # 맥\n",
    "    PRE_PATH = '/kkh/'\n",
    "DATA_PATH = PRE_PATH + \"data/\" # 대회에서 제공한 데이터\n",
    "OUTPUT_PATH = PRE_PATH + \"output/\" # 모델의 출력 값\n",
    "CHECKPOINT_PATH = PRE_PATH + \"checkpoint/\" # 모델의 최종 출력 값\n",
    "PREDICTION_PATH = PRE_PATH + \"prediction/\" # 최종 예측 값\n",
    "LOG_PATH = PRE_PATH + \"log/\"\n",
    "TRAIN_PATH = DATA_PATH + \"train_new2_temp.csv\"\n",
    "VALID_PATH = DATA_PATH + \"dev_new2.csv\"\n",
    "TEST_PATH = DATA_PATH + \"test.csv\"\n",
    "SUBMIT_PATH = PREDICTION_PATH + \"submission_\" + TEST_NAME + \".csv\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(TRAIN_PATH))\n",
    "val_df = pd.read_csv(os.path.join(VALID_PATH))\n",
    "test_df = pd.read_csv(os.path.join(TEST_PATH))\n",
    "\n",
    "sampled_df = train_df.sample(n=5, random_state=42)  # random_state는 결과를 재현 가능하게 합니다.\n",
    "combined_string = '\\n'.join(sampled_df.apply(lambda row: f\"{row['fname']}, {row['dialogue']}, {row['summary']}, {row['topic']}\", axis=1).tolist())\n",
    "print(combined_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화문: train_1\n",
      "#Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\n",
      "#Person2#: 안녕하세요, 피터스 박사님. 잘 지냈습니다, 감사합니다. 리키와 함께 백신 접종을 위해 왔습니다.\n",
      "#Person1#: 좋습니다. 백신 접종 기록을 보니, 리키는 이미 소아마비, 디프테리아, B형 간염 백신을 맞았군요. 그는 14개월이므로, 이제 A형 간염, 수두, 홍역 백신을 맞아야 합니다.\n",
      "#Person2#: 풍진과 볼거리는 어떻게 되나요?\n",
      "#Person1#: 지금은 이 백신들만 접종할 수 있고, 몇 주 후에 나머지를 접종할 수 있습니다.\n",
      "#Person2#: 좋습니다. 박사님, 저도 디프테리아 예방접종이 필요할 것 같아요. 마지막으로 맞은 게 아마도 15년 전이었던 것 같아요!\n",
      "#Person1#: 저희가 기록을 확인하고 간호사에게 부스터를 접종하도록 하겠습니다. 이제, 리키의 팔을 꽉 잡아주세요, 조금 찌릿할 수 있습니다.\n",
      "<s> [INST]train_1057, #Person1#: 그래도 저는 이 벽지를 원하지 않았어요. 그리고 프로그램을 열려고 할 때마다 여장을 한 부시 대통령만 보여요. \n",
      "#Person2#: 그 끔찍한 바이러스에 대해 들었어요! 자동으로 주소록에 있는 모든 사람에게 첨부 파일로 이메일을 보내요.\n",
      "#Person1#: 글쎄요, 이미 제 컴퓨터에 올라와 있어요. 어떻게 없앨 수 있죠?\n",
      "#Person3#: 다음 선거에서 투표로 없애세요.\n",
      "#Person1#: 이제 그만하고 진지하게 대답해줘요!\n",
      "#Person3#: IT 부서에게 바이러스 제거 프로그램을 실행하도록 요청하세요. 2005년까지 문제가 해결될 것이라고 생각해요., #Person1#의 컴퓨터에 끔찍한 바이러스가 걸렸고, #Person2#는 IT 부서에게 바이러스 제거 프로그램을 실행하도록 제안했다., 컴퓨터 바이러스\n",
      "train_10667, #Person1#: 우리 회사에 관심이 있는 이유는 무엇인가요?\n",
      "#Person2#: 귀사는 세계적으로 유명합니다. 그래서 개인적인 발전을 위한 더 나은 기회가 있을 것이라고 생각합니다.\n",
      "#Person1#: 맞습니다. 이 직무에 필요한 자격을 갖추고 있다고 생각하나요?\n",
      "#Person2#: 그럼요. 제 자격은 귀사의 직무 설명에 부합합니다.\n",
      "#Person1#: 하지만 이 직무에 대한 경험이 없습니다.\n",
      "#Person2#: 그건 사실입니다. 하지만 배우는 것에 열정이 있고, 빠르게 배울 수 있습니다.\n",
      "#Person1#: 추가 교육이 필요하다면, 교육비를 아시나요?\n",
      "#Person2#: 아니요. 월급은 얼마인가요?\n",
      "#Person1#: 월 800위안입니다.\n",
      "#Person2#: 내일 답변을 드려도 괜찮을까요?\n",
      "#Person1#: 예. 물론입니다., #Person2#는 세계적으로 유명한 #Person1#의 회사에 관심이 있으며, 경험이 없음에도 불구하고 #Person2#는 자신이 직무에 필요한 자격을 갖추고 있다고 생각합니다., 직무 인터뷰\n",
      "train_5261, #Person1#: 데이비드, 우리가 여기 앉아서 아무것도 안하는 건 잘못된 거에요.\n",
      "#Person2#: 왜요? 토요일 오후 아닌가요?\n",
      "#Person1#: 그렇지만, 집 주변에 할 일이 많아요.\n",
      "#Person2#: 기다려도 돼요.\n",
      "#Person1#: 부엌 벽과 찬장을 닦는 일을 끝내야 해요.\n",
      "#Person2#: 그건 내일 할 수 있어요. 오늘 꼭 해야 하는 건 아니에요.\n",
      "#Person1#: 좋아요. 하지만 내일은 꼭 해야 해요, 월요일에 페인터들이 오니까요.\n",
      "#Person2#: 그래요. 그게 생각나게 해줘서 고마워요. 부엌 싱크대 밑의 누수에 대해 뭔가 해야겠어요.\n",
      "#Person1#: 좋은 생각이에요.\n",
      "#Person2#: 부엌을 닦는 것에 대해 얘기하자면-밥은 어디에 있나요?\n",
      "#Person1#: 그는 조지아와 점심을 먹고 있어요.\n",
      "#Person2#: 뭐라고요! 또요?\n",
      "#Person1#: 곧 들어올 거에요.\n",
      "#Person2#: 그는 그 여자와 너무 많은 시간을 보내지 않아야 해요.\n",
      "#Person1#: 참을성을 가져야 해요, 데이비드. 열아홉은 매우 어려운 나이라는 걸 알아요.\n",
      "#Person2#: 그래, 알아요. 하지만 그는 더 공부해야 해요., #Person1#은 집 주변에 할 일이 많다고 생각한다. 데이비드는 내일 집안일을 할 것이다. #Person1#은 데이비드에게 밥이 조지아와 점심을먹고 있다고 말한다. 데이비는는 그것에 대해 불행해한다., 일상 대화\n",
      "train_311, #Person1#: 안녕하세요. 방금 거리에서 쇼핑을 하다가 지갑을 잃어버렸어요. 아마도 누군가가 훔쳐간 것 같아요.\n",
      "#Person2#: 그런 일이 있어서 죄송합니다. 지갑에 무엇이 들어있었는지 말씀해주실 수 있나요?\n",
      "#Person1#: 휴대폰, 여권, 그리고 약간의 현금이 있었어요.\n",
      "#Person2#: 언제 미국에 오셨나요?\n",
      "#Person1#: 며칠 전에 왔어요.\n",
      "#Person2#: 언제, 어디에서 잃어버렸는지 기억하실 수 있나요?\n",
      "#Person1#: 전혀 모르겠어요.\n",
      "#Person2#: 알겠습니다. 기록해두겠습니다. 미국에서의 비상 연락처는 누구신가요?\n",
      "#Person1#: 근처에 사는 친구인 팀이에요.\n",
      "#Person2#: 알겠습니다. 단서가 나오는 대로 연락드리겠습니다., #Person1#은 #Person2#에게 지갑을 잃어버렸다고 보고한다. #Person2#는 단서가 발견되면 연락할 수 있도록 #Person1#의 비상 연락처를 물어본다., 지갑 잃어버림\n",
      "train_10237, #Person1#: 스티븐 박사님, 제가 신입생 연도가 끝나기 전에 전공을 바꾸려고 생각하고 있습니다.\n",
      "#Person2#: 지금 어떤 과목을 공부하고 있나요?\n",
      "#Person1#: 이번 학기에는 세 가지 일반 요구 과목과 미국 역사, 미국 문학을 수강하고 있습니다. 지난 학기에는 네 가지 요구 과목과 신입생 프랑스어를 수강했습니다.\n",
      "#Person2#: 주로 모든 신입생이 수강해야 하는 일반 요구 과목을 수강했으므로 전공을 바꾸는 데는 늦지 않았다고 생각합니다. 또한 우리에게는 12개의 선택 과목이 있으므로 문학 과목들이 그 중에 포함될 것이므로 학점 시간을 잃지 않고 전공을 바꿀 수 있습니다.\n",
      "#Person1#: 아직 전공을 바꿀 수 있다는 것을 알게 되어 매우 기쁩니다. 저는 신문 기사를 쓰는 것에 관심이 있고, 학위를 마치고 나면 어떤 신문사에서 일하고 싶습니다.\n",
      "#Person2#: 오, 당신은 좋은 작가가 될 것 같습니다.\n",
      "#Person1#: 스티븐 박사님, 학생들이 실습을 시작하는 시기는 언제인가요?\n",
      "#Person2#: 그들은 보통 2학년 때부터 보도 실습을 시작합니다. 신문학 121은 일반적으로 배경 지식 과목으로 신입생 연도에 수강합니다.\n",
      "#Person1#: 알겠습니다. 다음 학기에 그 과목을 수강하겠습니다. 도움을 주셔서 감사합니다.\n",
      "#Person2#: 천만에요. 제 학과에서 당신을 만나는 것을 기대하겠습니다., #Person2#는 전공을 바꾸고 싶어하고 스티븐 박사에게 #Person2#가 수강한 과목들에 대해 말합니다. 스티븐 박사는 #Person2#가 학점 시간을 잃지 않고 전공을 바꿀 수 있으며, 학생들이 실습을 시작하는 것은 2학년 때라고 말합니다., 전공 변경\n",
      "train_9762, #Person1#: 오늘은 사람들이 어떻게 건강을 유지하는지 알아보려고 합니다. 죄송하지만, 당신은 정말 건강해 보여요. 어떻게 건강을 유지하시나요?\n",
      "#Person2#: 별다른 비결은 없어요. 비 오지 않는 날에는 매일 자전거로 출근하고, 음식을 좋아해서 원할 때 먹어요. 다만 밤 9시 이후에는 먹지 않으려고 노력하고 있어요.\n",
      "#Person1#: 정말요? 자전거로 출근하려면 얼마나 걸리나요?\n",
      "#Person2#: 대략 45분 정도 걸려요.\n",
      "#Person1#: 출근 후에 다른 운동을 하시나요?\n",
      "#Person2#: 아니요, 대부분 집에 가서 저녁을 먹는 편이에요.\n",
      "#Person1#: 알겠어요, 감사합니다. 다른 분에게도 여쭤봐야겠네요. 실례합니다., #Person1#은 건강 유지 방법에 대해 #Person2#에게 인터뷰를 합니다. #Person2#는 자전거로 출근하고 밤 9시 이후에는 먹지 않는다고 말합니다., 인터뷰\n",
      "train_9620, #Person1#: 후식으로 뭐 드시고 싶으세요?\n",
      "#Person2#: 뭐 있나요?\n",
      "#Person1#: 애플 파이, 아이스크림, 초콜릿 케이크, 그리고 과일 칵테일이 있어요.\n",
      "#Person2#: 애플 파이에 아이스크림을 더할 수 있나요?\n",
      "#Person1#: 물론이죠. 오늘 아침에 애플 파이를 만들었어요. 그래서 아주 맛있고 신선해요.\n",
      "#Person2#: 집에서 만든 애플 파이 정말 맛있어요. 레몬에이드 한 잔 더 먹을 수 있을까요?\n",
      "#Person1#: 그럼요. 직접 가져가시겠어요? 냉장고에 있어요.\n",
      "#Person2#: 네. 음료 드실래요?\n",
      "#Person1#: 네. 아이스티 하나 먹을게요. 레몬에이드 옆에 있을 거예요.\n",
      "#Person2#: 후식은 드시나요?\n",
      "#Person1#: 저도 애플 파이 먹을 거예요, 하지만 아이스크림은 빼고요. 체중조절 중이라서요., #Person2#는 #Person1#이 만든 애플 파이와 레몬에이드를 먹을 예정입니다. #Person1#은 아이스티와 아이스크림 없는 애플 파이를 먹을 예정인데, 이는 #Person1#이 체중을 조절하고 있기 때문입니다., 후식\n",
      "train_513, #Person1#: 안녕하세요, 로라, 어떤 것에 대해 이야기하고 싶으신가요?\n",
      "#Person2#: 안녕하세요, 스미스 교수님. 저는 전공을 바꾸는 것에 대해 이야기하고 싶어요. 저는 3년 만에 졸업 하면 미술관에서 일하려고 결정했고, 그래서 저는 제 전공을 미술사로 바꾸어야 한다고 생각해요.\n",
      "#Person1#: 로라, 이 결정에 대해 좀 더 생각해 보시는 것이 어떨까요? 당신은 경영학을 전공하면서 좋은 성적을 거두었고, 모든 조직은 좋은 관리자가 필요하다는 것을 알아두세요.\n",
      "#Person2#: 그건 사실이지만, 저는 여전히 미술에 대해 많이 알아야 하지 않나요?\n",
      "#Person1#: 미술사에 대한 몇 가지 강의에 참석하고 지역 미술관에서 일주일에 몇 시간씩 자원 봉사자로 일하며 그곳에서 일하는 것을 정말로 좋아하는지 확인해보세요., 로라는 경영에서 미술사로 전공을 바꾸고 싶어한다. 스미스 교수는 그녀에게 좀 더 생각한 후에 결정을 내리라고 조언한다., 전공 변경하기\n",
      "train_8295, #Person1#: 집을 구매하려는 제 제안에 대해 소유자들이 반대 제안을 내놓았나요?\n",
      "#Person2#: 귀하의 제안에 대한 반응으로 판매자들은 삼백삼십오만 달러의 반대 제안을 결정했습니다.\n",
      "#Person1#: 그것은 꽤 좋아 보이는데, 어떻게 해야 할지 잘 모르겠어요.\n",
      "#Person2#: 이 제안을 받아들이거나 거절하고 다른 제안을 내놓을 수 있습니다.\n",
      "#Person1#: 만약 다른 제안을 내고 그들이 거절한다면 어떻게 되나요?\n",
      "#Person2#: 개인적으로는 한 번 더 제안을 해보는 것을 고려해볼 것 같지만, 어떻게 할지 결정하는 것은 귀하에게 달려 있습니다.\n",
      "#Person1#: 삼백삼십만 달러로 반대 제안을 해보는 것은 어떨까요?\n",
      "#Person2#: 귀하의 현재 제안으로 판매자에게 연락하겠습니다.\n",
      "#Person1#: 이것이 꽤 빠르게 진행될 것이라고 생각하나요?\n",
      "#Person2#: 보통 두 번째 제안에 대한 반응은 첫 번째보다 조금 더 빠르게 진행됩니다., #Person2#는 #Person1#에게 판매자들이 #Person1#의 집 구매 제안에 대해 반대 제안을 결정했다고 알립니다. 그 후 #Person1#은 #Person2#의 조언에 따라 한 번 더 제안을 결정합니다., 반대 제안\n",
      "train_1985, #Person1#: 교수님, 약속을 잡을 수 있을까요?\n",
      "#Person2#: 내일 오후 2시에서 4시 사이에 시간이 됩니다. 특별히 원하는 시간이 있나요?\n",
      "#Person1#: 2시가 가장 좋을 것 같습니다.\n",
      "#Person2#: 좋습니다, 제 사무실 위치를 알고 있나요?\n",
      "#Person1#: 아니요, 잘 모르겠습니다.\n",
      "#Person2#: 기억하세요, E동 3층에 있습니다.\n",
      "#Person1#: 알겠습니다.\n",
      "#Person2#: 걱정하지 마세요, 도착하면 잘 찾을 수 있을 겁니다. 그때 만나죠.\n",
      "#Person1#: 그때 뵙겠습니다.\n",
      "#Person2#: 만나는 것을 기대하겠어요!, #Person1#은 #Person2#와의 약속을 잡고 싶어합니다. 그들은 언제 어디에서 만날지 확인합니다., 약속 잡기 \n",
      "\n",
      "\n",
      " 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\n",
      "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\n",
      "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\n",
      "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\n",
      "    \n",
      "#Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\n",
      "#Person2#: 안녕하세요, 피터스 박사님. 잘 지냈습니다, 감사합니다. 리키와 함께 백신 접종을 위해 왔습니다.\n",
      "#Person1#: 좋습니다. 백신 접종 기록을 보니, 리키는 이미 소아마비, 디프테리아, B형 간염 백신을 맞았군요. 그는 14개월이므로, 이제 A형 간염, 수두, 홍역 백신을 맞아야 합니다.\n",
      "#Person2#: 풍진과 볼거리는 어떻게 되나요?\n",
      "#Person1#: 지금은 이 백신들만 접종할 수 있고, 몇 주 후에 나머지를 접종할 수 있습니다.\n",
      "#Person2#: 좋습니다. 박사님, 저도 디프테리아 예방접종이 필요할 것 같아요. 마지막으로 맞은 게 아마도 15년 전이었던 것 같아요!\n",
      "#Person1#: 저희가 기록을 확인하고 간호사에게 부스터를 접종하도록 하겠습니다. 이제, 리키의 팔을 꽉 잡아주세요, 조금 찌릿할 수 있습니다. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:615: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 738.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m대화문: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcombined_string\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdialogue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=====================================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m, in \u001b[0;36mgen\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m GenerationConfig(\n\u001b[1;32m     11\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m     12\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m gened \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m result_str \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(gened[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     32\u001b[0m start_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Response: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1047\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1033\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1034\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1035\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1044\u001b[0m )\n\u001b[1;32m   1046\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1047\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m   1050\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 738.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    print(f\"대화문: {row['fname']}\")\n",
    "    print(row['dialogue'])\n",
    "    row['summary'] = '\"' + gen(f\"{combined_string} \\n\\n\\n 위와 같은 대화문과 요약문이 존재하니, 참고해줘.\\n\\\n",
    "    아래 대화문에서 핵심 키워드를 3개 정도 추출해서 출력해주고, 핵심 키워드를 꼭 포함해서 요약문을 작성해줘.\\n\\\n",
    "    요약문은 한 문장 또는 두 문장으로 표현해주고, 더불어, 요약문의 len() 길이는 101을 넘지 않도록 요약해줘.\\n\\\n",
    "    그리고, 내가 적었던 문장을 다시 출력하지 말아줘.\\n\\\n",
    "    \\n{row['dialogue']}\") + '\"'\n",
    "    print(row['summary'])\n",
    "    print('=====================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
