{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 eda aeda back\n",
    "\n",
    "### 1) Set functions\n",
    "- [\"Okt\", \"Kkma\", \"Komoran\", \"Mecab\", \"Hannanum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 분할을 원하지 않는 단어 모아두기\n",
    "# no_tokenized = ['#Person#', '#Person1#', '#Person2#', '#Person3#', \n",
    "# '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#사람1#',\n",
    "# '#PhoneNumber#', '#Address#', '#PassportNumber#',\n",
    "# '#DateOfBirth#','#SSN#','#CardNumber#','#CarNumber#','#Email#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jamo import h2j, j2hcj\n",
    "\n",
    "# def get_jongsung_TF(sample_text):\n",
    "#     sample_text_list = list(sample_text)\n",
    "#     last_word = sample_text_list[-1]\n",
    "#     last_word_jamo_list = list(j2hcj(h2j(last_word)))\n",
    "#     last_jamo = last_word_jamo_list[-1]\n",
    "\n",
    "#     jongsung_TF = \"T\"\n",
    "\n",
    "#     if last_jamo in ['ㅏ', 'ㅑ', 'ㅓ', 'ㅕ', 'ㅗ', 'ㅛ', 'ㅜ', 'ㅠ', 'ㅡ', 'ㅣ', 'ㅘ', 'ㅚ', 'ㅙ', 'ㅝ', 'ㅞ', 'ㅢ', 'ㅐ,ㅔ', 'ㅟ', 'ㅖ', 'ㅒ']:\n",
    "#         jongsung_TF = \"F\"\n",
    "\n",
    "#     return jongsung_TF\n",
    "    \n",
    "\n",
    "# # tmp 경로에 저장된 사용자 사전 명사에 새로운 단어 추가\n",
    "# with open('../mecab-0.996-ko-0.9.2/mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv', \"r\", encoding='utf-8') as f:\n",
    "#   user_dict = f.readlines()\n",
    "\n",
    "# for word in no_tokenized:\n",
    "#   jongsung_TF = get_jongsung_TF(word)\n",
    "#   line = '{},*,*,*,NNP,*,{},{},*,*,*,*,*\\n'.format(word, jongsung_TF, word)\n",
    "\n",
    "#   user_dict.append(line)\n",
    "  \n",
    "# print(user_dict[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 재저장\n",
    "# with open('../mecab-0.996-ko-0.9.2/mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv', 'w', encoding='utf-8') as f:\n",
    "#   for line in user_dict:\n",
    "#     f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "from koeda import EasyDataAugmentation, AEasierDataAugmentation\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import time\n",
    "\n",
    "# EDA\n",
    "def augment_text_data_with_EDA(text_col, repetition):\n",
    "    # 단어 바꾸기\n",
    "    \"\"\"입력된 문장에 대해서 EDA를 통해 데이터 증강\"\"\"\n",
    "    eda = EasyDataAugmentation(\n",
    "        morpheme_analyzer=\"Mecab\"\n",
    "        )\n",
    "    \n",
    "    random.seed(42)\n",
    "\n",
    "    result = text_col.progress_apply(eda, p=(0.8, 0.01, 0.02, 0.01), repetition=repetition)\n",
    "    print(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# AEDA\n",
    "def augment_text_data_with_AEDA(text_col, repetition):\n",
    "    # 단어 사이에 문자 추가하기\n",
    "    \"\"\"입력된 문장에 대해서 AEDA를 통해 데이터 증강\"\"\"\n",
    "    aeda = AEasierDataAugmentation(\n",
    "        morpheme_analyzer=\"Mecab\",\n",
    "        punctuations=[\".\", \",\", \"!\", \"?\", \";\", \":\"]\n",
    "    )\n",
    "\n",
    "    random.seed(42)\n",
    "    \n",
    "    # result = text_col.progress_apply(aeda, p=0.05, repetition=repetition)\n",
    "    result = []\n",
    "    for i in tqdm(range(len(text_col))):\n",
    "        time.sleep(0.01)\n",
    "        a = aeda(text_col[i], p = 0.05, repetition=repetition)\n",
    "        result.append(a)\n",
    "\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas tqdm 호출\n",
    "tqdm.pandas() # tqdm의 pandas전용 메소드를 호출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) application train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original data\n",
    "train = pd.read_csv('../data/back_result_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbba147bf9ed427b95a7c1c3584e260f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5610     #Person1#: 안녕하세요! 트랜스퍼시픽항공 입니다. 어떻게 도와 드릴까요? #...\n",
      "3047     #Person1#: 마이크, 내일 오후에 저 좀 도와주실 수 있나요? 오후 에시부터...\n",
      "18927    #Person1#: 안녕, 마크. 어떻게 지내?#Person2#: 잘 지내, 신디....\n",
      "1972     이득 #Person1#: 오늘은 무엇을 도와드릴까요, 앨리스? #Person2# 생...\n",
      "13554    #Person1#: 무엇을 주문하시겠어요, 고객님?#Person2#: 중국 음식을 ...\n",
      "                               ...                        \n",
      "9052     #Person1#: 소피, 어젯밤에 Frank Jones를 주최한 퀴즈만듭니다쇼가 ...\n",
      "4303     #Person1#: 역사 교수님께서 나에게 정치 분야의 직업을 고려해 보라고 하셨지...\n",
      "16008    #Person1#: 크리스, 오늘어오전 11시에 할아버지, 할머니께 전화해야에하는 ...\n",
      "10279    #Person1#: 여기는 11번 경찰서입니다. 무엇을 도와드릴까요? #Person...\n",
      "2264     #Person1#: 마르쉐, 과학 강좌를 들어야 할까요? #Person2#: 네, ...\n",
      "Name: dialogue, Length: 2500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# eda\n",
    "train2 = train.sample(n=2500, random_state=42)\n",
    "train2['dialogue'] = augment_text_data_with_EDA(train2['dialogue'], 1)\n",
    "train2.to_csv('../data/back_mecab_eda_augmentation_made30000.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aeda\n",
    "# train3 = train.copy()\n",
    "# train3['dialogue'] = augment_text_data_with_AEDA(train3['dialogue'], 1)\n",
    "# train3.to_csv('../data/mecab_aeda_augmentation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f862290f56ee4c1fa4e49a8dcb941419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n)):\n\u001b[0;32m---> 14\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43maeda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdialogue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepetition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(a)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/koeda/aeda.py:35\u001b[0m, in \u001b[0;36mAEasierDataAugmentation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maeda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/koeda/aeda.py:42\u001b[0m, in \u001b[0;36mAEasierDataAugmentation.aeda\u001b[0;34m(self, data, p, repetition)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m repetition \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aeda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aeda, repeat(data, repetition), repeat(p, repetition))\n\u001b[1;32m     46\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/koeda/aeda.py:73\u001b[0m, in \u001b[0;36mAEasierDataAugmentation._aeda\u001b[0;34m(self, data, p)\u001b[0m\n\u001b[1;32m     70\u001b[0m qs \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(split_words)), q)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_special_selection(split_words, qs):\n\u001b[0;32m---> 73\u001b[0m     qs \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_words\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(split_words):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m qs:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/random.py:499\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    497\u001b[0m selected_add \u001b[38;5;241m=\u001b[39m selected\u001b[38;5;241m.\u001b[39madd\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[0;32m--> 499\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[43mrandbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[1;32m    501\u001b[0m         j \u001b[38;5;241m=\u001b[39m randbelow(n)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/random.py:246\u001b[0m, in \u001b[0;36mRandom._randbelow_with_getrandbits\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    244\u001b[0m getrandbits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetrandbits\n\u001b[1;32m    245\u001b[0m k \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m.\u001b[39mbit_length()  \u001b[38;5;66;03m# don't use (n-1) here because n can be 1\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgetrandbits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 0 <= r < 2**k\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m r \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[1;32m    248\u001b[0m     r \u001b[38;5;241m=\u001b[39m getrandbits(k)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 자동화 안되서 분할 적용하기 위해 수동으로 적용\n",
    "aeda = AEasierDataAugmentation(\n",
    "    morpheme_analyzer=\"Mecab\",\n",
    "    punctuations=[\".\", \",\", \"!\", \"?\", \";\", \":\"]\n",
    ")\n",
    "# sampling \n",
    "train_sample = train.sample(n=2500, random_state=42).reset_index(drop = True)\n",
    "\n",
    "random.seed(42)\n",
    "# result = text_col.progress_apply(aeda, p=0.05, repetition=repetition)\n",
    "result = []\n",
    "n = len(train_sample['dialogue'])\n",
    "for i in tqdm(range(n)):\n",
    "    a = aeda(train_sample['dialogue'][i], p = 0.05, repetition=1)\n",
    "    result.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962b712b125a4d03bbaf42bdeae075ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2탄\n",
    "for i in tqdm(range(1867, n)):\n",
    "    a = aeda(train_sample['dialogue'][i], p = 0.05, repetition=1)\n",
    "    result.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3탄\n",
    "# for i in tqdm(range(7268, 9000)):\n",
    "#     a = aeda(train_sample['dialogue'][i], p = 0.05, repetition=1)\n",
    "#     result.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4탄\n",
    "# for i in tqdm(range(19825, n)):\n",
    "#     a = aeda(train_sample['dialogue'][i], p = 0.05, repetition=1)\n",
    "#     result.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 비교\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 동일한 개수 확인\n",
    "len(train_sample['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "train3 = train_sample.copy()\n",
    "train3['dialogue'] = result\n",
    "train3.to_csv('../data/back_mecab_aeda_augmentation_made30000.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통합 후 저장\n",
    "train_merge = pd.concat([train, train2, train3])\n",
    "train_merge.to_csv('../data/back_augment_train_merge_made30000.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
