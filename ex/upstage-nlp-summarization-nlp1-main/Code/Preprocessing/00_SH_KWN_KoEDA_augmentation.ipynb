{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 data augmentation (using koeda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoEDA  \n",
    "- `영어용으로 구현된 Easy data augmentation 과 An Easier Data Augmentation 프로젝트를 한글용으로 재구성한 프로젝트입니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎯 EasyDataAugmentation 파라미터\n",
    " - `p = (alpha_sr,alpha_ri,alpha_rs,prob_rd)` 은 <br> SR, RI , RS , RD 에 대한 각각의 변환을 어느정도 비율로 할 것인지 결정\n",
    " > - Synonym Replacement __(SR)__ : 유의어 교체\n",
    " > - Random Insertion __(RI)__ : 임의 단어 삽입\n",
    " > - Random Swap __(RS)__ : 두 단어 위치 변경\n",
    " > - Random Deletion __(RD)__ : 임의 단어 삭제\n",
    " - morpheme_analyzer 는 사용될 형태소 분석기를 지정하는 파라미터로, <br> [\"Okt\", \"Kkma\", \"Komoran\", \"Mecab\", \"Hannanum\"] 중 하나를 선택할 수 있다.  <br>__(단, 일부는 설치 필요하며, 각각 형태소를 나누는 기준이 다르다. )__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아버지가 휴게실에 들어가신다\n",
      "['아버지방 에가 들어가신다', '아버지가 방에 안방 휴게실 들어가신다', '아버지가 침실에 들어가신다']\n",
      "탈의실 아버지가 방에 들어가시ㄴ다\n",
      "['아버지가 골방에 들어가시ㄴ다', '아버지가 방에 들어가시ㄴ다', '침투하 아버지가 방 침실 골방 에 들어가시ㄴ다']\n",
      "아버지가 방에 들어가시ㄴ다\n",
      "['부친가 방에 들어가시ㄴ다', 'ㄴ다가 방시 에들어가아버지', '아버지가 시에방 들어가ㄴ다']\n",
      "들어가가 방에 아버지신다\n",
      "['아버지방 에가 들어가신다', '아버지가 방에 안방 휴게실 들어가신다', '아버지가 침실에 들어가신다']\n",
      "아버지가 방에 들어가시ㄴ다이\n",
      "['침실 평원 독방 부모 아버지가 방에 들어가이시ㄴ다', '아버지가 방에 들어가이시ㄴ다', '아버지가 방에 들어가이시ㄴ다']\n"
     ]
    }
   ],
   "source": [
    "from koeda import EDA\n",
    "from koeda import EasyDataAugmentation\n",
    "\n",
    "\n",
    "eda = EasyDataAugmentation(\n",
    "    morpheme_analyzer=\"Okt\"\n",
    "    )\n",
    "\n",
    "eda1 = EasyDataAugmentation(\n",
    "    morpheme_analyzer=\"Kkma\"\n",
    "    )\n",
    "\n",
    "eda2 = EasyDataAugmentation(\n",
    "    morpheme_analyzer=\"Komoran\"\n",
    "    )\n",
    "\n",
    "eda3 = EasyDataAugmentation(\n",
    "    morpheme_analyzer=\"Mecab\"\n",
    "    )\n",
    "\n",
    "eda4 = EasyDataAugmentation(\n",
    "    morpheme_analyzer=\"Hannanum\"\n",
    "    )\n",
    "\n",
    "text = \"아버지가 방에 들어가신다\"\n",
    "\n",
    "result = eda(text)\n",
    "print(result)\n",
    "# 아버지가 정실에 들어가신다\n",
    "\n",
    "result = eda(text,p=(0.9, 0.5, 0.5, 0.0), repetition=3)\n",
    "print(result)\n",
    "# ['아버지가 객실 아빠 안방 방에 정실 들어가신다', '아버지가 탈의실 방 휴게실 에 안방 탈의실 들어가신다']\n",
    "\n",
    "result1 = eda1(text)\n",
    "print(result1)\n",
    "# 아버지가 정실에 들어가신다\n",
    "\n",
    "result1 = eda1(text,p=(0.5, 0.5, 0.5, 0.0), repetition=3)\n",
    "print(result1)\n",
    "# ['아버지가 객실 아빠 안방 방에 정실 들어가신다', '아버지가 탈의실 방 휴게실 에 안방 탈의실 들어가신다']\n",
    "\n",
    "result2 = eda2(text)\n",
    "print(result2)\n",
    "# 아버지가 정실에 들어가신다\n",
    "\n",
    "result2 = eda2(text,p=(0.5, 0.5, 0.5, 0.0), repetition=3)\n",
    "print(result2)\n",
    "# ['아버지가 객실 아빠 안방 방에 정실 들어가신다', '아버지가 탈의실 방 휴게실 에 안방 탈의실 들어가신다']\n",
    "\n",
    "result3 = eda3(text)\n",
    "print(result3)\n",
    "# 아버지가 정실에 들어가신다\n",
    "\n",
    "result3 = eda3(text,p=(0.9, 0.9, 0.0, 0.0), repetition=2)\n",
    "print(result)\n",
    "# ['아버지가 객실 아빠 안방 방에 정실 들어가신다', '아버지가 탈의실 방 휴게실 에 안방 탈의실 들어가신다']\n",
    "\n",
    "result4 = eda4(text)\n",
    "print(result4)\n",
    "# 아버지가 정실에 들어가신다\n",
    "\n",
    "result4 = eda4(text,p=(0.5, 0.5, 0.5, 0.0), repetition=3)\n",
    "print(result4)\n",
    "# ['아버지가 객실 아빠 안방 방에 정실 들어가신다', '아버지가 탈의실 방 휴게실 에 안방 탈의실 들어가신다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koeda import EasyDataAugmentation\n",
    "\n",
    "def augment_text_data_with_EDA(text,repetition):\n",
    "    \"\"\"입력된 문장에 대해서 EDA를 통해 데이터 증강\"\"\"\n",
    "    eda = EasyDataAugmentation(\n",
    "        morpheme_analyzer=\"Okt\"\n",
    "        )\n",
    "\n",
    "    result = eda(text,p=(0.5, 0.5, 0.5, 0.5), repetition=repetition)\n",
    "\n",
    "    # 증강 결과 출력\n",
    "    print(\"원문: \" , text)\n",
    "    print(\"--\"*100)\n",
    "    for i in range(repetition):\n",
    "        print(f\"증강문{i+1}: \", result[i])\n",
    "    # return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 data augmentation (using SR / KWN wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNet 로드\n",
    "with open(\"wordnet.pickle\", \"rb\") as f:\n",
    "    wordnet = pickle.load(f)\n",
    "\n",
    "def replace_entities_with_placeholders(text, placeholder_prefix=\"#REPL#\"):\n",
    "    entities = re.findall(r\"#.+?#\", text)\n",
    "    for i, entity in enumerate(entities):\n",
    "        text = text.replace(entity, f\"{placeholder_prefix}{i}#\", 1)\n",
    "    return text, entities\n",
    "\n",
    "def replace_placeholders_with_entities(text, entities, placeholder_prefix=\"#REPL#\"):\n",
    "    for i, entity in enumerate(entities):\n",
    "        text = text.replace(f\"{placeholder_prefix}{i}#\", entity, 1)\n",
    "    return text\n",
    "\n",
    "def augment_text(text, wordnet):\n",
    "    text, entities = replace_entities_with_placeholders(text)\n",
    "    \n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in wordnet:\n",
    "            synonyms = wordnet[word]\n",
    "            if synonyms:\n",
    "                words[i] = random.choice(synonyms)\n",
    "                break\n",
    "    \n",
    "    augmented_text = \" \".join(words)\n",
    "    augmented_text = replace_placeholders_with_entities(augmented_text, entities)\n",
    "    \n",
    "    return augmented_text\n",
    "\n",
    "input_file = \"../data/augment/last_back_train.csv\"\n",
    "output_file = \"../data/augment/back_kwn37500_train.csv\"\n",
    "augmented_data = []\n",
    "\n",
    "with open(input_file, encoding='utf-8') as csvfile:\n",
    "    reader = list(csv.DictReader(csvfile))  # 데이터를 메모리에 로드하기 위해 list로 변환\n",
    "    original_data_len = len(reader)\n",
    "    target_augment_count = 37500 - original_data_len  # 증강을 원하는 목표 수\n",
    "    \n",
    "    # 기존 데이터를 augmented_data에 추가\n",
    "    for row in reader:\n",
    "        augmented_data.append(row)\n",
    "    \n",
    "    # 데이터 증강 시작\n",
    "    while len(augmented_data) < 37500:\n",
    "        for row in reader:\n",
    "            # 대화와 요약 증강\n",
    "            augmented_dialogue = augment_text(row['dialogue'], wordnet)\n",
    "            # augmented_summary = augment_text(row['summary'], wordnet)\n",
    "            augmented_row = {\n",
    "                'fname': row['fname'],\n",
    "                'dialogue': augmented_dialogue,\n",
    "                'summary': row['summary'],\n",
    "                'topic': row['topic']\n",
    "            }\n",
    "            \n",
    "            # 증강된 데이터 추가\n",
    "            augmented_data.append(augmented_row)\n",
    "            \n",
    "            # 목표 데이터 수에 도달했는지 확인\n",
    "            if len(augmented_data) >= 37500:\n",
    "                break\n",
    "\n",
    "# 증강된 데이터를 CSV 파일로 저장\n",
    "with open(output_file, mode='w', encoding='utf-8', newline='') as f:\n",
    "    fieldnames = ['fname', 'dialogue', 'summary', 'topic']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in augmented_data[:37500]:  # 최대 50,000개 데이터만 저장\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...</td>\n",
       "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
       "      <td>건강검진 받기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>#Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\\n#Person2#...</td>\n",
       "      <td>파커 부인이 리키를 데리고 백신 접종을 하러 갔다. 피터스 박사는 기록을 확인한 후...</td>\n",
       "      <td>백신</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>#Person1#: 실례합니다, 열쇠 한 묶음 보셨나요?\\n#Person2#: 어떤...</td>\n",
       "      <td>#Person1#은 열쇠 한 묶음을 찾고 있고, 그것을 찾기 위해 #Person2#...</td>\n",
       "      <td>열쇠 찾기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>#Person1#: 왜 너는 여자친구가 있다는 걸 말해주지 않았어?\\n#Person...</td>\n",
       "      <td>#Person1#은 #Person2#가 여자친구가 있고 그녀와 결혼할 것이라는 사실...</td>\n",
       "      <td>여자친구가 있다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>#Person1#: 안녕, 숙녀분들! 오늘 밤 당신들은 정말 멋져 보여. 이 춤을 ...</td>\n",
       "      <td>말릭이 니키에게 춤을 요청한다. 말릭이 발을 밟는 것을 신경 쓰지 않는다면 니키는 ...</td>\n",
       "      <td>댄스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>train_7710</td>\n",
       "      <td>#Person1#: 이제, 선씨, 사고를 명확하게 보셨나요? #Person2#: 아...</td>\n",
       "      <td>선씨는 사고를 목격하고 #Person1#에게 자세한 정보를 알려줍니다.</td>\n",
       "      <td>사고 목격자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>train_7711</td>\n",
       "      <td>#Person1#: 전산 사용법을 배우기 시작해봅시다, 퍼블러. 컴퓨터에는 하드웨어...</td>\n",
       "      <td>#Person1#과 퍼블러는 컴퓨터 사용법을 공부하고 있으며, #Person1#은 ...</td>\n",
       "      <td>컴퓨터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>train_7712</td>\n",
       "      <td>#Person1#: 좋은 아침입니다, 도와드릴 일이 있나요? #Person2#: 아...</td>\n",
       "      <td>구찌와 메이가 옷을 사러 쇼핑을 갔습니다. 처음에는 메이가 무심하게 행동하지만, 구...</td>\n",
       "      <td>옷 구매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>train_7713</td>\n",
       "      <td>#Person1#: 친구의 결혼식을 폐해 어떤 천을 골라 슈트를 만들어 주실 수 있...</td>\n",
       "      <td>#Person1#은 친구의 결혼식을 위해 갈색 줄무늬 슈트를 만들고 싶어합니다. #...</td>\n",
       "      <td>옷 선택</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>train_7714</td>\n",
       "      <td>#Person1#: 안녕하세요, 엘리자베스님. 어떻게 지내세요? #Person2#:...</td>\n",
       "      <td>엘리자베스는 극장에서 돌아오는 길에 지갑을 잃어버렸다는 사실로 걱정하고 있다. #P...</td>\n",
       "      <td>지갑 잃어버림</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname                                           dialogue  \\\n",
       "0         train_0  #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...   \n",
       "1         train_1  #Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\\n#Person2#...   \n",
       "2         train_2  #Person1#: 실례합니다, 열쇠 한 묶음 보셨나요?\\n#Person2#: 어떤...   \n",
       "3         train_3  #Person1#: 왜 너는 여자친구가 있다는 걸 말해주지 않았어?\\n#Person...   \n",
       "4         train_4  #Person1#: 안녕, 숙녀분들! 오늘 밤 당신들은 정말 멋져 보여. 이 춤을 ...   \n",
       "...           ...                                                ...   \n",
       "69995  train_7710  #Person1#: 이제, 선씨, 사고를 명확하게 보셨나요? #Person2#: 아...   \n",
       "69996  train_7711  #Person1#: 전산 사용법을 배우기 시작해봅시다, 퍼블러. 컴퓨터에는 하드웨어...   \n",
       "69997  train_7712  #Person1#: 좋은 아침입니다, 도와드릴 일이 있나요? #Person2#: 아...   \n",
       "69998  train_7713  #Person1#: 친구의 결혼식을 폐해 어떤 천을 골라 슈트를 만들어 주실 수 있...   \n",
       "69999  train_7714  #Person1#: 안녕하세요, 엘리자베스님. 어떻게 지내세요? #Person2#:...   \n",
       "\n",
       "                                                 summary     topic  \n",
       "0      스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...   건강검진 받기  \n",
       "1      파커 부인이 리키를 데리고 백신 접종을 하러 갔다. 피터스 박사는 기록을 확인한 후...        백신  \n",
       "2      #Person1#은 열쇠 한 묶음을 찾고 있고, 그것을 찾기 위해 #Person2#...     열쇠 찾기  \n",
       "3      #Person1#은 #Person2#가 여자친구가 있고 그녀와 결혼할 것이라는 사실...  여자친구가 있다  \n",
       "4      말릭이 니키에게 춤을 요청한다. 말릭이 발을 밟는 것을 신경 쓰지 않는다면 니키는 ...        댄스  \n",
       "...                                                  ...       ...  \n",
       "69995            선씨는 사고를 목격하고 #Person1#에게 자세한 정보를 알려줍니다.    사고 목격자  \n",
       "69996  #Person1#과 퍼블러는 컴퓨터 사용법을 공부하고 있으며, #Person1#은 ...       컴퓨터  \n",
       "69997  구찌와 메이가 옷을 사러 쇼핑을 갔습니다. 처음에는 메이가 무심하게 행동하지만, 구...      옷 구매  \n",
       "69998  #Person1#은 친구의 결혼식을 위해 갈색 줄무늬 슈트를 만들고 싶어합니다. #...      옷 선택  \n",
       "69999  엘리자베스는 극장에서 돌아오는 길에 지갑을 잃어버렸다는 사실로 걱정하고 있다. #P...   지갑 잃어버림  \n",
       "\n",
       "[70000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = pd.read_csv(\"../data/augment/kwn70000_train.csv\")\n",
    "train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Only kwn augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "\n",
    "# WordNet 로드\n",
    "with open(\"wordnet.pickle\", \"rb\") as f:\n",
    "    wordnet = pickle.load(f)\n",
    "\n",
    "# 기존 함수들...\n",
    "def replace_entities_with_placeholders(text, placeholder_prefix=\"#REPL#\"):\n",
    "    entities = re.findall(r\"#.+?#\", text)\n",
    "    for i, entity in enumerate(entities):\n",
    "        text = text.replace(entity, f\"{placeholder_prefix}{i}#\", 1)\n",
    "    return text, entities\n",
    "\n",
    "def replace_placeholders_with_entities(text, entities, placeholder_prefix=\"#REPL#\"):\n",
    "    for i, entity in enumerate(entities):\n",
    "        text = text.replace(f\"{placeholder_prefix}{i}#\", entity, 1)\n",
    "    return text\n",
    "\n",
    "def augment_text(text, wordnet):\n",
    "    text, entities = replace_entities_with_placeholders(text)\n",
    "    \n",
    "    words = text.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in wordnet:\n",
    "            synonyms = wordnet[word]\n",
    "            if synonyms:\n",
    "                words[i] = random.choice(synonyms)\n",
    "                break\n",
    "    \n",
    "    augmented_text = \" \".join(words)\n",
    "    augmented_text = replace_placeholders_with_entities(augmented_text, entities)\n",
    "    \n",
    "    return augmented_text\n",
    "\n",
    "input_file = \"../data/augment/back_result_train.csv\"\n",
    "output_file = \"../data/augment/back_kwn10000_augmented.csv\"  # 변경된 파일명\n",
    "new_augmented_data = []  # 새롭게 생성된 데이터만을 저장할 리스트\n",
    "\n",
    "with open(input_file, encoding='utf-8') as csvfile:\n",
    "    reader = list(csv.DictReader(csvfile))\n",
    "    original_data_len = len(reader)\n",
    "    target_augment_count = 10000  # 변경: 새롭게 생성할 데이터의 목표 수\n",
    "    \n",
    "    # 데이터 증강 시작\n",
    "    while len(new_augmented_data) < target_augment_count:  # 변경: 새로운 리스트의 크기를 확인\n",
    "        for row in reader:\n",
    "            # 대화와 요약 증강 (요약은 증강하지 않기로 함)\n",
    "            augmented_dialogue = augment_text(row['dialogue'], wordnet)\n",
    "            augmented_row = {\n",
    "                'fname': row['fname'],\n",
    "                'dialogue': augmented_dialogue,\n",
    "                'summary': row['summary'],  # 원본 요약 사용\n",
    "                'topic': row['topic']\n",
    "            }\n",
    "            \n",
    "            # 증강된 데이터 추가\n",
    "            new_augmented_data.append(augmented_row)\n",
    "            \n",
    "            # 목표 데이터 수에 도달했는지 확인\n",
    "            if len(new_augmented_data) >= target_augment_count:\n",
    "                break\n",
    "\n",
    "# 증강된 데이터를 CSV 파일로 저장\n",
    "with open(output_file, mode='w', encoding='utf-8', newline='') as f:\n",
    "    fieldnames = ['fname', 'dialogue', 'summary', 'topic']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in new_augmented_data:  # 새로운 리스트의 데이터만 저장\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
