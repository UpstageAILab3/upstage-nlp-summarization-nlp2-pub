{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼 파라미터 튜닝\n",
    "### Trainer 클래스의 hyperparameter_search를 사용하여 튜닝하기\n",
    "- 필요에 맞게 `config_data`의 `model_name`과 `data_path` 수정 (`config_data['general']['model_name]`, `config_data['general']['data_path]`)\n",
    "- 튜닝하고 싶은 하이퍼파라미터와 튜닝할 범위 설정 \n",
    "    - 함수 `my_hp_space`에서 변경\n",
    "- 함수 `my_objective`에서 `['eval_loss', 'eval_rouge-1', 'eval_rouge-2', 'eval_rouge-l']` 중 최적화하고 싶은 것으로 변경\n",
    "    - `eval_loss`의 경우 `trainer.hyperparameter_search(direction=\"maximize\", ...)`에서  `direction='minimize'`로 수정\n",
    "- `trainer.hyperparameter_search(direction=\"maximize\", n_trial=5, ...)`에서 필요에 맞게 `n_trial` 변경\n",
    "- 이외 필요에 맞게 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from rouge import Rouge\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset , DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모델 이름(model_name)과 파일 경로 변경\n",
    "\n",
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"digit82/kobart-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Address#', '#CarNumber#', '#CardNumber#', '#DateOfBirth#', '#Email#', '#PassportNumber#', \n",
    "                           '#Person#', '#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', \n",
    "                           '#Person7#', '#PhoneNumber#', '#SSN#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 20,             # checkpoint 생성 개수\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3    ,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": None\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능에 대한 평가 지표를 정의합니다. 본 대회에서는 ROUGE 점수를 통해 모델의 성능을 평가합니다.\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거합니다.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD: {replaced_labels[2]}\")\n",
    "\n",
    "    # 최종적인 ROUGE 점수를 계산합니다.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE 점수 중 F-1 score를 통해 평가합니다.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리를 위한 클래스로, 데이터셋을 데이터프레임으로 변환하고 인코더와 디코더의 입력을 생성합니다.\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # 실험에 필요한 컬럼을 가져옵니다.\n",
    "    def make_set_as_df(file_path, is_train = True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname','dialogue','summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    # BART 모델의 입력, 출력 형태를 맞추기 위해 전처리를 진행합니다.\n",
    "    def make_input(self, dataset,is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x)) # Ground truth를 디코더의 input으로 사용하여 학습합니다.\n",
    "            decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validation에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validation에 대해 각각 데이터프레임을 구축합니다.\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    model_name = config_data[\"general\"][\"model_name\"]\n",
    "    bart_config = BartConfig().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(model_name,config=bart_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config_data['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer)) # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    generate_model.to(device)\n",
    "    return generate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer():\n",
    "    model_name = config_data[\"general\"][\"model_name\"]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config_data['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocess(config_data['tokenizer']['bos_token'], config_data['tokenizer']['eos_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "tokenizer = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = config_data[\"general\"][\"data_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "train_label:\n",
      " 스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \n",
      "#Person2#: 요즘 숨쉬기가 좀 힘들어요.\n",
      "#Person1#: 최근에 감기 같은 것에 걸리신 적이 있나요?\n",
      "#Person2#: 아니요, 감기는 아니에요. 그냥 숨을 쉴 때마다 가슴이 무겁게 느껴져요.\n",
      "#Person1#: 알고 있는 알레르기가 있나요?\n",
      "#Person2#: 아니요, 알고 있는 알레르기는 없어요.\n",
      "#Person1#: 이런 증상이 항상 나타나나요, 아니면 활동할 때 주로 나타나나요?\n",
      "#Person2#: 운동을 할 때 많이 나타나요.\n",
      "#Person1#: 저는 당신을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 거예요.\n",
      "#Person2#: 도와주셔서 감사합니다, 의사 선생님.\n",
      "val_label:\n",
      " #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다. \n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n"
     ]
    }
   ],
   "source": [
    "train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config_data, preprocessor, data_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 trainer 클래스와 매개변수를 정의합니다.\n",
    "def load_trainer_for_train(training_args, config,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    # Validation loss가 더 이상 개선되지 않을 때 학습을 중단시키는 EarlyStopping 기능을 사용합니다.\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer 클래스를 정의합니다.\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        model_init=model_init,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=config_data['general']['output_dir'], # model output directory\n",
    "            overwrite_output_dir=config_data['training']['overwrite_output_dir'],\n",
    "            num_train_epochs=config_data['training']['num_train_epochs'],  # total number of training epochs\n",
    "            learning_rate=config_data['training']['learning_rate'], # learning_rate\n",
    "            per_device_train_batch_size=config_data['training']['per_device_train_batch_size'], # batch size per device during training\n",
    "            per_device_eval_batch_size=config_data['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
    "            warmup_ratio=config_data['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
    "            weight_decay=config_data['training']['weight_decay'],  # strength of weight decay\n",
    "            lr_scheduler_type=config_data['training']['lr_scheduler_type'],\n",
    "            optim =config_data['training']['optim'],\n",
    "            gradient_accumulation_steps=config_data['training']['gradient_accumulation_steps'],\n",
    "            evaluation_strategy=config_data['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
    "            save_strategy =config_data['training']['save_strategy'],\n",
    "            save_total_limit=config_data['training']['save_total_limit'], # number of total save model.\n",
    "            fp16=config_data['training']['fp16'],\n",
    "            load_best_model_at_end=config_data['training']['load_best_model_at_end'], # 최종적으로 가장 높은 점수 저장\n",
    "            seed=config_data['training']['seed'],\n",
    "            logging_dir=config_data['training']['logging_dir'], # directory for storing logs\n",
    "            logging_strategy=config_data['training']['logging_strategy'],\n",
    "            predict_with_generate=config_data['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
    "            generation_max_length=config_data['training']['generation_max_length'],\n",
    "            do_train=config_data['training']['do_train'],\n",
    "            do_eval=config_data['training']['do_eval'],\n",
    "            report_to=config_data['training']['report_to'] # (선택) wandb를 사용할 때 설정합니다.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝하고자 하는 hyperparameter와 범위 지정\n",
    "\n",
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", low=1e-5, high=0.01), # learning_rate\n",
    "        \"per_device_train_batch_size\" : trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32, 50]),\n",
    "        \"per_device_eval_batch_size\" : trial.suggest_categorical(\"per_device_eval_batch_size\", [4, 8, 16, 32, 50]),\n",
    "        \"weight_decay\" : trial.suggest_float(\"weight_decay\", 4e-5, 0.01),\n",
    "        \"lr_scheduler_type\" : trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine\"]),\n",
    "        \"optim\" : trial.suggest_categorical(\"optim\", [\"adamw_hf\", \"adamw_torch\", \"adamw_torch_fused\", \"adafactor\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_objective(metrics):\n",
    "    return metrics[\"eval_rouge-1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make trainer complete ----------\n"
     ]
    }
   ],
   "source": [
    "trainer = load_trainer_for_train(training_args, config_data, tokenizer,train_inputs_dataset,val_inputs_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "[I 2024-03-18 08:59:56,971] A new study created in memory with name: no-name-00a5e695-0ab2-4537-b818-dae732f039c2\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/5000 07:55 < 31:47, 2.10 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.460900</td>\n",
       "      <td>1.357787</td>\n",
       "      <td>0.272626</td>\n",
       "      <td>0.071159</td>\n",
       "      <td>0.258078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.042400</td>\n",
       "      <td>2.906148</td>\n",
       "      <td>0.121920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.847600</td>\n",
       "      <td>3.106741</td>\n",
       "      <td>0.121920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.765400</td>\n",
       "      <td>7.355337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 #Person1# 에게 자신의 약혼혈에 대해 이야기합니다. #Person2# 는 #Person1# 에게 약을 복용하는 것을 제안합니다.                                                                        \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 #Person1# 에게 오늘 밤의 날에 대해 이야기합니다. #Person2# 는 #Person1# 에게 도움을 청합니다.                                                                           \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 의 도움으로 인해 #Person2# 의 도움으로 인해 #Person1# 의 도움으로 인해 #Person1# 의 도움으로 치킨을 주문한다.                                                                      \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "['eval_loss', 'eval_rouge-1', 'eval_rouge-2', 'eval_rouge-l']\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:                                                                                                     \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:                                                                                                     \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:                                                                                                     \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "['eval_loss', 'eval_rouge-1', 'eval_rouge-2', 'eval_rouge-l']\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:                                                                                                     \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:                                                                                                     \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:                                                                                                     \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "['eval_loss', 'eval_rouge-1', 'eval_rouge-2', 'eval_rouge-l']\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1# \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1# \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1##Person1# \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "['eval_loss', 'eval_rouge-1', 'eval_rouge-2', 'eval_rouge-l']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "[I 2024-03-18 09:07:55,555] Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 0.003969161664476582, 'per_device_train_batch_size': 50, 'per_device_eval_batch_size': 16, 'weight_decay': 0.005519606991801111, 'lr_scheduler_type': 'cosine', 'optim': 'adamw_hf'}. Best is trial 0 with value: 0.0.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6231' max='62300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6231/62300 09:02 < 1:21:20, 11.49 it/s, Epoch 2/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.221700</td>\n",
       "      <td>1.478840</td>\n",
       "      <td>0.290275</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.275440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 66/125 00:38 < 00:34, 1.69 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 #Person2# 의 도움으로 체크인을 구매합니다.    \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 #Person2# 의 도움으로 체크인을 구매합니다.    \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 #Person2# 의 도움으로 체크인을 구매합니다.    \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "['eval_loss', 'eval_rouge-1', 'eval_rouge-2', 'eval_rouge-l']\n"
     ]
    }
   ],
   "source": [
    "# 필요에 맞게 n_trial 변경\n",
    "trainer.hyperparameter_search(direction=\"maximize\", compute_objective=my_objective, n_trials=5, hp_space = my_hp_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
