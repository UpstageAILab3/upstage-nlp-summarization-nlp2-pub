{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, input_len, summ_len, is_train=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.source_len = input_len\n",
    "        self.summ_len = summ_len\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            self.input_ids = tokenizer(self.df['dialogue'].tolist(), return_tensors=\"pt\", padding=True,\n",
    "                                add_special_tokens=True, truncation=True, max_length=512, return_token_type_ids=False).input_ids\n",
    "            self.labels = tokenizer(self.df['summary'].tolist(), return_tensors=\"pt\", padding=True,\n",
    "                                add_special_tokens=True, truncation=True, max_length=100, return_token_type_ids=False).input_ids\n",
    "        else:\n",
    "            self.input_ids = tokenizer(self.df['dialogue'].tolist(), return_tensors=\"pt\", padding=True,\n",
    "                                add_special_tokens=True, truncation=True, max_length=512, return_token_type_ids=False).input_ids\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            return self.input_ids[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.input_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"psyche/KoT5-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict={'additional_special_tokens': ['#Person1#', '#Person2#','#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#', '#PhoneNumber#', \n",
    "                                                   '#Address#', '#PassportNumber#', '#CardNumber#', '#Email#', '#DateOfBirth#',]}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/new_train.csv')\n",
    "val_df = pd.read_csv('../data/new_dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df[['dialogue', 'summary']], tokenizer, 400, 256)\n",
    "val_dataset = CustomDataset(val_df[['dialogue', 'summary']], tokenizer, 400, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_params)\n",
    "val_loader = DataLoader(val_dataset, **val_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_words(tokenizer, preds, labels):\n",
    "    decoded_preds = tokenizer.batch_decode(preds, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거합니다.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = ['<usr>', f\"{tokenizer.unk_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "    return replaced_predictions, replaced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능에 대한 평가 지표를 정의합니다. 본 대회에서는 ROUGE 점수를 통해 모델의 성능을 평가합니다.\n",
    "def compute_metrics(replaced_predictions, replaced_labels):\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # 최종적인 ROUGE 점수를 계산합니다.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE 점수 중 F-1 score를 통해 평가합니다.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, device, train_loader, optimizer, log_interval, train_step):\n",
    "    model.train()\n",
    "    current_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "\n",
    "        input_ids = data[0].to(device, dtype=torch.long)\n",
    "        labels = data[1].to(device, dtype=torch.long)\n",
    "\n",
    "        loss = model(input_ids=input_ids, labels=labels).loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            train_loss = current_loss / batch_idx\n",
    "\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, \n",
    "                batch_idx * len(input_ids), \n",
    "                len(train_loader) * len(input_ids), \n",
    "                100 * batch_idx / len(train_loader), \n",
    "                train_loss))\n",
    "            \n",
    "            if wandb is not None:\n",
    "                wandb.log({\n",
    "                    \"Loss/Train\": train_loss, \n",
    "                }, step=train_step)\n",
    "        train_step += 1\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(tokenizer, model, device, val_loader, train_step):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_idx, data in enumerate(val_loader):\n",
    "            input_ids = data[0].to(device, dtype=torch.long)\n",
    "            labels = data[1].to(device, dtype=torch.long)\n",
    "\n",
    "            pred_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=256, \n",
    "                num_beams=4,\n",
    "                repetition_penalty=2.0, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "\n",
    "            loss = model(input_ids=input_ids, labels=labels).loss\n",
    "            total_loss += loss.item()\n",
    "            replaced_predictions, replaced_labels = ids_to_words(tokenizer, pred_ids, labels)\n",
    "            result = compute_metrics(replaced_predictions, replaced_labels)\n",
    "\n",
    "        val_loss = total_loss / len(val_loader)\n",
    "        if wandb is not None:\n",
    "            wandb.log({\n",
    "                \"Loss/Val\": total_loss,\n",
    "                \"Rouge-1/Val\": result['rouge-1'],\n",
    "                \"Rouge-2/Val\": result['rouge-2'],\n",
    "                \"Rouge-L/Val\": result['rouge-l'],\n",
    "            }, step=train_step)\n",
    "        print(\"Validation: Val Loss: {:.6f}, Rouge-1/Val: {:.6f}, Rouge-2/Val: {:.6f}, Rouge-l/Val: {:.6f}\".format(val_loss, result['rouge-1'], result['rouge-2'], result['rouge-l']))\n",
    "        \n",
    "        print('-'*150)\n",
    "        print(f\"PRED: {replaced_predictions[0]}\")\n",
    "        print(f\"GOLD: {replaced_labels[0]}\")\n",
    "        print('-'*150)\n",
    "        print(f\"PRED: {replaced_predictions[1]}\")\n",
    "        print(f\"GOLD: {replaced_labels[1]}\")\n",
    "        print('-'*150)\n",
    "        print(f\"PRED: {replaced_predictions[2]}\")\n",
    "        print(f\"GOLD: {replaced_labels[2]}\")\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tokenizer, model, device, test_loader, fname):\n",
    "    model.eval()\n",
    "    summary = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids in tqdm(test_loader):\n",
    "            input_ids = input_ids.to(device, dtype=torch.long)\n",
    "\n",
    "            pred_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=256, \n",
    "                num_beams=4,\n",
    "                repetition_penalty=2.0, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "            for ids in pred_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "                \n",
    "    remove_tokens = ['<usr>', f\"{tokenizer.unk_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": fname,\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fdgsie26) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3301f68659cf4a71bbb52fa4dd6f4fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss/Train</td><td>█▇▆▆▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/Val</td><td>▄▁▁▁▁▃▄▅▆█</td></tr><tr><td>Rouge-1/Val</td><td>▃█▆▄▁▁▅▂▂▂</td></tr><tr><td>Rouge-2/Val</td><td>▄▅█▃▁▂▄▄▄▃</td></tr><tr><td>Rouge-L/Val</td><td>▄██▆▁▂▆▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss/Train</td><td>0.24355</td></tr><tr><td>Loss/Val</td><td>39.44158</td></tr><tr><td>Rouge-1/Val</td><td>0.40597</td></tr><tr><td>Rouge-2/Val</td><td>0.15798</td></tr><tr><td>Rouge-L/Val</td><td>0.35636</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">KoT5-summarization-fourth-test</strong> at: <a href='https://wandb.ai/ch_hee/DS/runs/fdgsie26' target=\"_blank\">https://wandb.ai/ch_hee/DS/runs/fdgsie26</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240318_104143-fdgsie26/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fdgsie26). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b3424ce85e4b17ba366695ad340c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112700009511577, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/code/wandb/run-20240318_121926-tnrh65yl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch_hee/DS/runs/tnrh65yl' target=\"_blank\">KoT5-summarization-fifth-test</a></strong> to <a href='https://wandb.ai/ch_hee/DS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch_hee/DS' target=\"_blank\">https://wandb.ai/ch_hee/DS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch_hee/DS/runs/tnrh65yl' target=\"_blank\">https://wandb.ai/ch_hee/DS/runs/tnrh65yl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ch_hee/DS/runs/tnrh65yl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f36f83bbbb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 10\n",
    "\n",
    "log_interval = 310\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"psyche/KoT5-summarization\").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "run_name = f\"KoT5-summarization-fifth-test\"\n",
    "log_dir = f\"runs/{run_name}\"\n",
    "\n",
    "project_name = 'DS'\n",
    "run_tags=[project_name]\n",
    "wandb.init(\n",
    "    entity=\"ch_hee\",\n",
    "    project=project_name,\n",
    "    name=run_name,\n",
    "    tags=run_tags,\n",
    "    reinit=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './logs'\n",
    "model_path = os.path.join(log_dir, 'models-fifth')\n",
    "os.makedirs(model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_point = 0\n",
    "path = os.path.join(model_path, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [2472/12464 (20%)]\tTrain Loss: 0.904415\n",
      "Train Epoch: 1 [4952/12464 (40%)]\tTrain Loss: 0.785810\n",
      "Train Epoch: 1 [7432/12464 (60%)]\tTrain Loss: 0.745230\n",
      "Train Epoch: 1 [9912/12464 (80%)]\tTrain Loss: 0.712366\n",
      "Train Epoch: 1 [12392/12464 (99%)]\tTrain Loss: 0.690205\n",
      "Validation: Val Loss: 0.554155, Rouge-1/Val: 0.380810, Rouge-2/Val: 0.143115, Rouge-l/Val: 0.380810\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   차에서 이상한 소리가 나서 #Person2# 은 브레이크를 새로 교체해야 합니다. #Person1# 는 내일 아침에 차를 다시 가져오는 것을 제안하지만, 그것은 좋은 생각이 아닙니다.                  \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   아마존 고객 서비스에서 책을 읽다가 한 페이지가 빠져있는 것을 발견합니다. #Person1# 은 주문 번호를 알려주고, 라 살바토레의 '헌터의 종이 봉투 밤'을 사진으로 찍어서 고객에게 업로드하는 것을 도와줍니다. \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  <extra_id_14> #Person2# 는 여름 휴가 동안 회사에서 일을 할 예정이다. #Person1# 는 회사의 생일 파티를 도와주고, 대가족이 모일 것이라고 말한다. 그들은 모두 준비를 도와야 하고, 파티가 끝나면 청소를 돕기로 한다.    \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 2 [2472/12464 (20%)]\tTrain Loss: 0.545851\n",
      "Train Epoch: 2 [4952/12464 (40%)]\tTrain Loss: 0.541015\n",
      "Train Epoch: 2 [7432/12464 (60%)]\tTrain Loss: 0.540210\n",
      "Train Epoch: 2 [9912/12464 (80%)]\tTrain Loss: 0.539389\n",
      "Train Epoch: 2 [12392/12464 (99%)]\tTrain Loss: 0.535983\n",
      "Validation: Val Loss: 0.530383, Rouge-1/Val: 0.462993, Rouge-2/Val: 0.230009, Rouge-l/Val: 0.449388\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 차에서 이상한 소리가 난다고 말합니다. #Person1# 는 브레이크를 교체해야 하고 내일 아침에 차를 다시 가져오라고 제안합니다.                \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 이 아마존 고객 서비스에 전화를 걸어 책을 읽다가 한 페이지가 빠져있는 것을 발견합니다. #Person1# 은 #Person2# 에게 사진을 찍어 업로드하고, 문제가 확인되면 2일 내로 새 책을 보내줄 것입니다. \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 이번 여름 휴가에 회사에서 일할 것이라고 말한다. #Person1# 는 내일 생일 파티를 도와줄 것이며, 파티가 시작하기 전에 모든 것을 준비하고, 테이블을 정리하고, 예쁘게 보이게 하는 일을 한다.  \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 3 [2472/12464 (20%)]\tTrain Loss: 0.464456\n",
      "Train Epoch: 3 [4952/12464 (40%)]\tTrain Loss: 0.466043\n",
      "Train Epoch: 3 [7432/12464 (60%)]\tTrain Loss: 0.470018\n",
      "Train Epoch: 3 [9912/12464 (80%)]\tTrain Loss: 0.470373\n",
      "Train Epoch: 3 [12392/12464 (99%)]\tTrain Loss: 0.473392\n",
      "Validation: Val Loss: 0.520083, Rouge-1/Val: 0.460899, Rouge-2/Val: 0.193936, Rouge-l/Val: 0.443805\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 차에서 이상한 소리가 난다고 말하고 브레이크를 교체해야 한다고 말합니다. #Person1# 는 내일 아침에 차를 다시 가져오는 것을 제안하지만, #Person3# 은 그것이 좋은 생각이 아니라고 생각합니다.  \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 아마존 고객 서비스에 전화를 걸어 책을 읽다가 한 페이지가 빠져있는 것을 발견합니다. #Person2# 는 해당 책의 빠진 부분을 사진으로 찍어 업로드하고, 문제가 확인되면 새 책을 보내줄 것입니다. \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 이번 여름 휴가에 회사에서 일할 것이라고 말한다. 회사는 음식을 준비하고 음악을 제공하며, 생일 파티를 도와줄 것이다.              \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 4 [2472/12464 (20%)]\tTrain Loss: 0.421007\n",
      "Train Epoch: 4 [4952/12464 (40%)]\tTrain Loss: 0.422317\n",
      "Train Epoch: 4 [7432/12464 (60%)]\tTrain Loss: 0.422738\n",
      "Train Epoch: 4 [9912/12464 (80%)]\tTrain Loss: 0.422940\n",
      "Train Epoch: 4 [12392/12464 (99%)]\tTrain Loss: 0.422954\n",
      "Validation: Val Loss: 0.530640, Rouge-1/Val: 0.404670, Rouge-2/Val: 0.141353, Rouge-l/Val: 0.363637\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 차에서 이상한 소리가 나서 #Person2# 에게 브레이크를 교체하라고 요청합니다. #Person1# 는 오늘 오후에 차를 돌려받을 수 있을 줄 알았지만, 부품이 도착하기 전에는 작업을 시작할 수 없습니다. 그래서 그들은 내일 아침에 차를 다시 가져오기로 합니다. \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   아마존 고객 서비스에서 #Person2# 가 책을 읽다가 한 페이지가 빠져있는 것을 발견했습니다. #Person1# 은 이 부분을 사진으로 찍어 올리고, 문제가 확인되면 2일 내로 새 책을 보내줄 것입니다.            \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 이번 여름 휴가에 회사에서 일하며, 파티를 도와줄 것이다. #Person2# 는 요리를 할 필요가 없고, 대신 조수일 뿐이다.                        \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 5 [2472/12464 (20%)]\tTrain Loss: 0.367874\n",
      "Train Epoch: 5 [4952/12464 (40%)]\tTrain Loss: 0.372051\n",
      "Train Epoch: 5 [7432/12464 (60%)]\tTrain Loss: 0.375970\n",
      "Train Epoch: 5 [9912/12464 (80%)]\tTrain Loss: 0.376555\n",
      "Train Epoch: 5 [12392/12464 (99%)]\tTrain Loss: 0.379503\n",
      "Validation: Val Loss: 0.530250, Rouge-1/Val: 0.441302, Rouge-2/Val: 0.174501, Rouge-l/Val: 0.400770\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 의 차에서 이상한 소리가 나는 것을 보고 브레이크를 교체하려고 합니다. #Person1# 는 오늘 오후에 차를 돌려받을 수 있을 것이라고 생각하지만, 내일 아침에 차를 다시 가져오는 것을 제안합니다.       \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 아마존 고객 서비스에 전화를 걸어 책을 읽다가 한 페이지가 빠져있는 것을 발견했습니다. #Person2# 는 이 책의 빠진 부분을 사진으로 찍어서 업로드하고, 문제가 확인되면 2일 내로 새 책을 보내줄 것입니다. \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 이번 여름 휴가에 회사에서 일하며, 파티를 도와줄 예정이다. #Person1# 은 요리를 할 필요가 없고, #Person2# 의 조수일 뿐이다.                 \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 6 [2472/12464 (20%)]\tTrain Loss: 0.331912\n",
      "Train Epoch: 6 [4952/12464 (40%)]\tTrain Loss: 0.336033\n",
      "Train Epoch: 6 [7432/12464 (60%)]\tTrain Loss: 0.341187\n",
      "Train Epoch: 6 [9912/12464 (80%)]\tTrain Loss: 0.342616\n",
      "Train Epoch: 6 [12392/12464 (99%)]\tTrain Loss: 0.343569\n",
      "Validation: Val Loss: 0.548991, Rouge-1/Val: 0.448170, Rouge-2/Val: 0.167062, Rouge-l/Val: 0.432297\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 의 차에서 이상한 소리가 나고, #Person2# 는 내일까지 차를 #Person1# 에게 맡기기로 결정한다. 하지만 오늘 오후에 차를 돌려받을 수 있을 줄 알았다. 결국, 그들은 내일 아침에 차를 다시 가져오기로 한다. \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 아마존 고객 서비스에 전화를 걸어 어제 받은 책의 한 페이지를 잃어버렸다고 알립니다. #Person2# 는 #Person1# 에게 문제의 소지가 있다면 2일 내로 새 책을 보내줄 것이라고 알려줍니다.     \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 #Person1# 에게 이번 여름 휴가에 회사에서 일하며, 파티를 도와주고, 음식을 가져다 놓고, 테이블을 정리하고, 예쁘게 보이게 하는 것을 도와줄 것이라고 말한다.          \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 7 [2472/12464 (20%)]\tTrain Loss: 0.306758\n",
      "Train Epoch: 7 [4952/12464 (40%)]\tTrain Loss: 0.308810\n",
      "Train Epoch: 7 [7432/12464 (60%)]\tTrain Loss: 0.307304\n",
      "Train Epoch: 7 [9912/12464 (80%)]\tTrain Loss: 0.308028\n",
      "Train Epoch: 7 [12392/12464 (99%)]\tTrain Loss: 0.309460\n",
      "Validation: Val Loss: 0.569060, Rouge-1/Val: 0.389456, Rouge-2/Val: 0.124454, Rouge-l/Val: 0.336735\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 의 차에서 이상한 소리가 나고, #Person1# 은 내일까지 브레이크를 교체해야 합니다. #Person2# 은 내일 아침에 차를 다시 가져오는 것을 제안하지만, 그녀는 그것이 좋은 생각이 아니라고 생각합니다.             \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 의 웹사이트에서 받은 책의 한 페이지를 사진으로 찍어서 아마존 고객 서비스 페이지에 업로드하고, 문제가 확인되면 2일 내로 새 책을 보내줄 것입니다.             \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 은 이번 여름 휴가에 회사에서 일하며, 파티를 도와주고, 음식을 가져다 놓고, 테이블을 정리하고, 예쁘게 보이게 하는 일을 돕게 될 것입니다. #Person2# 는 설거지를 하지 않지만, #Person1# 은 그렇게 나쁘지 않다고 생각합니다. \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 8 [2472/12464 (20%)]\tTrain Loss: 0.276565\n",
      "Train Epoch: 8 [4952/12464 (40%)]\tTrain Loss: 0.278543\n",
      "Train Epoch: 8 [7432/12464 (60%)]\tTrain Loss: 0.279855\n",
      "Train Epoch: 8 [9912/12464 (80%)]\tTrain Loss: 0.281075\n",
      "Train Epoch: 8 [12392/12464 (99%)]\tTrain Loss: 0.282241\n",
      "Validation: Val Loss: 0.586076, Rouge-1/Val: 0.414377, Rouge-2/Val: 0.179309, Rouge-l/Val: 0.370339\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 의 차에서 이상한 소리가 나고, #Person1# 은 내일까지 차를 #Person2# 에게 맡겨야 합니다. 그들은 내일 아침에 차를 다시 가져오기로 결정합니다.       \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 #Person1# 에게 어제 받은 책의 한 페이지를 사진으로 찍어서 아마존 고객 서비스 페이지에 업로드하고, 문제가 확인되면 새 책을 보내줄 것이라고 말합니다.    \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 여름 휴가에 회사에서 일하며, 파티를 도와주고, 음식을 가져다 놓고, 테이블을 정리하고, 예쁘게 보이게 하는 일을 한다. #Person1# 는 설거지를 하지 않는다. \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 9 [2472/12464 (20%)]\tTrain Loss: 0.247730\n",
      "Train Epoch: 9 [4952/12464 (40%)]\tTrain Loss: 0.249527\n",
      "Train Epoch: 9 [7432/12464 (60%)]\tTrain Loss: 0.250896\n",
      "Train Epoch: 9 [9912/12464 (80%)]\tTrain Loss: 0.254630\n",
      "Train Epoch: 9 [12392/12464 (99%)]\tTrain Loss: 0.256779\n",
      "Validation: Val Loss: 0.601861, Rouge-1/Val: 0.371212, Rouge-2/Val: 0.130042, Rouge-l/Val: 0.355339\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 의 차에서 이상한 소리가 나고 있다. #Person1# 은 내일까지 차를 #Person2# 에게 맡길 수 없다. 그래서 그들은 내일 아침에 차를 다시 가져오는 것에 대해 논의한다.    \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 #Person1# 의 웹사이트에서 받은 책의 한 페이지가 빠져있는 것을 발견합니다. 아마존 고객 서비스는 문제를 확인하고 2일 내로 새 책을 보내줄 것입니다.      \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 이번 여름 휴가에 회사에서 일하며, 파티를 도와주고, 음식을 가져다 놓고, 테이블을 정리하고, 예쁘게 보이게 하는 일을 한다. #Person1# 는 설거지를 하지 않는다. \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n",
      "Train Epoch: 10 [2472/12464 (20%)]\tTrain Loss: 0.226680\n",
      "Train Epoch: 10 [4952/12464 (40%)]\tTrain Loss: 0.229974\n",
      "Train Epoch: 10 [7432/12464 (60%)]\tTrain Loss: 0.230758\n",
      "Train Epoch: 10 [9912/12464 (80%)]\tTrain Loss: 0.233891\n",
      "Train Epoch: 10 [12392/12464 (99%)]\tTrain Loss: 0.235047\n",
      "Validation: Val Loss: 0.623436, Rouge-1/Val: 0.413248, Rouge-2/Val: 0.135313, Rouge-l/Val: 0.355983\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 의 차에서 이상한 소리가 나고 있다. #Person1# 은 내일까지 차를 맡겨야 한다고 생각하지만, #Person2# 는 내일 아침에 차를 다시 가져오는 것을 제안한다. 하지만 #Person3# 은 시내로 운전하면서 목숨을 걸고 있다고 생각한다. \n",
      "GOLD: #Person2# 의 차에서 이상한 소리가 납니다. #Person1# 는 브레이크를 교체해야 할 것으로 생각하지만, #Person1# 는 내일까지 그것을 고칠 수 없습니다. #Person2# 는 오늘 밤에 공연을 보러 가고 싶어합니다; #Person1# 는 #Person2# 에게 버스를 이용할 것을 제안합니다.                                      \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 의 책을 읽다가 한 페이지가 빠져있는 것을 발견하고, 이를 사진으로 찍어 웹사이트의 고객 서비스 페이지에 업로드하도록 요청합니다. 문제가 확인되면 2일 내로 새 책을 보내줄 것입니다.  \n",
      "GOLD: #Person2# 님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지가 빠져 있다고 합니다. #Person1# 은 문제가 확인되면 새 책을 보내드릴 것이라고 말합니다.                                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 이번 여름 휴가에 회사에서 파티를 돕는 일을 할 것이라고 말한다. #Person1# 의 회사는 음식을 준비하고 제공하고 음악을 제공한다.                 \n",
      "GOLD: #Person2# 는 #Person1# 에게 여름 휴가 동안 파티를 도와주는 회사에서 일할 것이라고 말한다. #Person1# 는 그것이 멋진 직업이라고 생각한다.                                                                  \n",
      "\n",
      "Saved Model!!!\n"
     ]
    }
   ],
   "source": [
    "train_step = 0\n",
    "for epoch in range(1, epoch + 1):\n",
    "    train_step = train(epoch, model, device, train_loader, optimizer, log_interval, train_step)\n",
    "    validate(tokenizer, model, device, val_loader, train_step)\n",
    "    save_dir = os.path.dirname(path)\n",
    "    torch.save(model, os.path.join(save_dir, f'epoch-{epoch}-{path.split(\"/\")[-1]}'))\n",
    "    print('Saved Model!!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_df[['dialogue']], tokenizer, 512, 100, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "    'batch_size': 8,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "test_loader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('../code/logs/models-fourth/epoch-10-model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>더슨 씨는 #Person1# 에게 모든 사무실 통신은 이메일 통신과 공식 메모로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1# 은 또 교통 체증에 걸렸다. #Person2# 는 #Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>케이트는 #Person1# 에게 마샤와 히어로가 별거 중이다가 이혼을 신청했다고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>#Person1# 은 브라이언의 생일을 축하하고 파티에 초대한다. 브라이언은 #P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person2# 는 #Person1# 에게 올림픽 공원의 크기, 좌석 수, 그리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>잭이 찰리에게 집에 와서 비디오 게임을 하자고 제안한다. 찰리는 자신이 캐릭터를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2# 는 #Person1# 에게 어떻게 컨트리 음악에 관심을 가지게 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>앨리스는 #Person1# 에게 세탁기와 건조기 안에 비누를 넣지 않았다고 말합...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>매튜는 계약이 다음 달에 끝나기 때문에 집을 찾고 있다. 스티브는 분류된 광고를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>프랭크가 승진하여 친구들 모두를 위한 큰 파티를 열려고 한다. 벳시는 축하의 말...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0    더슨 씨는 #Person1# 에게 모든 사무실 통신은 이메일 통신과 공식 메모로...\n",
       "1      test_1   #Person1# 은 또 교통 체증에 걸렸다. #Person2# 는 #Person...\n",
       "2      test_2    케이트는 #Person1# 에게 마샤와 히어로가 별거 중이다가 이혼을 신청했다고...\n",
       "3      test_3   #Person1# 은 브라이언의 생일을 축하하고 파티에 초대한다. 브라이언은 #P...\n",
       "4      test_4   #Person2# 는 #Person1# 에게 올림픽 공원의 크기, 좌석 수, 그리...\n",
       "..        ...                                                ...\n",
       "494  test_495    잭이 찰리에게 집에 와서 비디오 게임을 하자고 제안한다. 찰리는 자신이 캐릭터를...\n",
       "495  test_496   #Person2# 는 #Person1# 에게 어떻게 컨트리 음악에 관심을 가지게 ...\n",
       "496  test_497    앨리스는 #Person1# 에게 세탁기와 건조기 안에 비누를 넣지 않았다고 말합...\n",
       "497  test_498    매튜는 계약이 다음 달에 끝나기 때문에 집을 찾고 있다. 스티브는 분류된 광고를...\n",
       "498  test_499    프랭크가 승진하여 친구들 모두를 위한 큰 파티를 열려고 한다. 벳시는 축하의 말...\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = predict(tokenizer, model, device, test_loader, test_df['fname'])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
