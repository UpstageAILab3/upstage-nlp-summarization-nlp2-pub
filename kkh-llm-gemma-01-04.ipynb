{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma 장점\n",
    "\n",
    "- 다양한 모델 제공: Gemma는 Gemma 2B와 Gemma 7B 두 가지 유형으로 제공, 각 유형은 pre-trained 및 instruction-tuned 된 두가지 타입의 모델 제공\n",
    "- 책임감 있는 AI 툴킷: Gemma를 활용하여 안전한 AI 애플리케이션을 제작할 수 있는 가이드와 필수 도구를 제공하는 새로운 책임감 있는 생성형 AI 툴킷이 함께 제공\n",
    "- 프레임워크 지원: Kera JAX, PyTorch, TensorFlow와 같은 주요 프레임워크에서 추론 및 SFT을 위한 툴체인을 제공\n",
    "- 다양한 하드웨어 지원: NVIDIA GPU와 구글 클라우드 TPU 등에 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma를 위한 라이브러리\n",
    "\n",
    "- pip install -q -U transformers==4.38.2\n",
    "- pip install -q -U datasets==2.18.0\n",
    "- pip install -q -U bitsandbytes==0.42.0\n",
    "- pip install -q -U peft==0.9.0\n",
    "- pip install -q -U trl==0.7.11\n",
    "- pip install -q -U accelerate==0.27.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemma 기타\n",
    "\n",
    "- 트랜스포머 디코더 쪽이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 허깅페이스 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c54b081d2654888bc457f92c968bb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_NAME = \"beomi-gemma-ko-2b-01\"\n",
    "TEST_NAME = \"google-gemma-2b-it-02\"\n",
    "\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# 데이터 관련\n",
    "os_name = platform.system()\n",
    "if os_name == 'Windows':\n",
    "    PRE_PATH = ''\n",
    "elif os_name == 'Linux':\n",
    "    PRE_PATH = '/kkh/'\n",
    "elif os_name == 'Darwin': # 맥\n",
    "    PRE_PATH = '/kkh/'\n",
    "DATA_PATH = PRE_PATH + \"data/\" # 대회에서 제공한 데이터\n",
    "# TRAIN_PATH = DATA_PATH + \"train_kkh_new.csv\"\n",
    "TRAIN_PATH = DATA_PATH + \"train_hdj.csv\"\n",
    "VALID_PATH = DATA_PATH + \"dev_kkh_new.csv\"\n",
    "TEST_PATH = DATA_PATH + \"test.csv\"\n",
    "PREDICTION_PATH = PRE_PATH + \"prediction/\" # 최종 예측 값\n",
    "SUBMIT_PATH = PREDICTION_PATH + \"submission_\" + TEST_NAME + \".csv\"\n",
    "\n",
    "# BASE_MODEL = \"beomi/gemma-ko-2b\"\n",
    "BASE_MODEL = \"google/gemma-2b-it\"\n",
    "# BASE_MODEL = \"/kkh/gemma_model/gemma-2b-it-sum-ko-10epc\"\n",
    "ADAPTER_MODEL = PRE_PATH + \"gemma_model/adapter/\" + TEST_NAME\n",
    "FINETUNE_MODEL = PRE_PATH + \"gemma_model/finetune/\" + TEST_NAME\n",
    "\n",
    "DATASET_TRAIN = load_dataset('csv', data_files={'train': TRAIN_PATH})\n",
    "DATASET_TEST = load_dataset('csv', data_files={'test': TEST_PATH})\n",
    "TRAIN_DATA = DATASET_TRAIN['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'fname': 'train_0', 'dialogue': '#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\\n#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\\n#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\\n#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\\n#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\\n#Person2#: 알겠습니다.\\n#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\\n#Person2#: 네.\\n#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \\n#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\\n#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\\n#Person2#: 알겠습니다, 감사합니다, 의사선생님.', 'summary': '스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.', 'topic': '건강검진 받기'}\n",
      "=============================\n",
      "train 대화문:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "=============================\n",
      "train 요약문:\n",
      "스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n",
      "=============================\n",
      "test 대화문:\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "print(TRAIN_DATA[0])\n",
    "print('=============================')\n",
    "print(f\"train 대화문:\\n{TRAIN_DATA[0]['dialogue']}\")\n",
    "print('=============================')\n",
    "print(f\"train 요약문:\\n{TRAIN_DATA[0]['summary']}\")\n",
    "print('=============================')\n",
    "print(f\"test 대화문:\\n{TRAIN_DATA[0]['dialogue']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7678a6793d0a4a53af6bc5d67e2f41d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "# 모델 자체를 몇 비트로 로딩할 것인지를 정하는 것이다.\n",
    "# 32, 16, 8에 비해 4비트는 메모리를 적게 사용하면서 속도가 빠르지만, 정확도가 떨어진다.\n",
    "# 서버 자원이 적을 경우 주로 사용한다.\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "# device_map=\"auto\"는 데이터를 CPU 또는 GPU로 자동 연결해주는 기능이다. GPU가 여러개 이면, 자동 분산도 해준다.\n",
    "# quantization_config=quantization_config 에 대한 설명은 위 코드에 있다.\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, quantization_config=quantization_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Gemma-it의 프롬프트 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\n다음 글을 해설자가 설명하듯이 요약해주세요.:\\n\\n#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\\n#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\\n#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\\n#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\\n#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\\n#Person2#: 알겠습니다.\\n#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\\n#Person2#: 네.\\n#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \\n#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\\n#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\\n#Person2#: 알겠습니다, 감사합니다, 의사선생님.<end_of_turn>\\n<start_of_turn>model\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = TRAIN_DATA[0]['dialogue']\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"다음 글을 해설자가 설명하듯이 요약해주세요.:\\n\\n{}\".format(ex)\n",
    "    }\n",
    "]\n",
    "\n",
    "# tokenize: 문장을 토큰 단위를 자를 것인지 지정한다.\n",
    "# add_generation_prompt: 다음 발화자가 말할 수 있도록, 프롬프트를 적어준다. 예를 들어, user와 model이 대화를 하는 중이라면, user 발화 끝 부분에 \"<start_of_turn>model\" 과 같이 붙여준다.\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Gemma-it 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n",
    "outputs = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.01,\n",
    "    top_k=10,\n",
    "    top_p=0.2\n",
    ")\n",
    "\n",
    "# do_sample=True: 생성할 때 확률적인 샘플링을 사용하여 보다 다양한 출력을 생성합니다. False로 설정 시 가장 높은 확률의 토큰을 선택합니다.\n",
    "# temperature=0.5: 모델의 출력 확률 분포를 조정합니다. 값이 낮을수록 보수적이고, 높을수록 다양하게 생성합니다.\n",
    "# top_k=50: 모델이 선택할 수 있는 상위 50개의 토큰 중 하나를 샘플링합니다.\n",
    "# top_p=0.95: 확률 분포의 상위 95%에 해당하는 토큰을 선택해 생성하는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**해설:**\n",
      "\n",
      "이 문의에서 주요 내용은 다음과 같습니다.\n",
      "\n",
      "- 건강검진은 5년 동안 받아야 할 수 있는 기회가 있다고 얘기합니다.\n",
      "- 심각한 질병을 피하기 위해서는 이를 조기에 발견하는 것이 중요합니다.\n",
      "- 담배는 폐암과 심장병의 주요 원인이므로, 끊임없이 피우는 것이 중요합니다.\n",
      "- 의사에게 의문이 있으면 더 많은 정보를 드리겠다고 약속합니다.\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 학습용 프롬프트 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    prompt_list = []\n",
    "    for i in range(len(example['dialogue'])):\n",
    "        prompt_list.append(r\"\"\"<bos><start_of_turn>user\n",
    "다음 글을 요약해주세요:\n",
    "\n",
    "{}\n",
    "\n",
    "<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\n",
    "{}\n",
    "\n",
    "<end_of_turn><eos>\"\"\".format(example['dialogue'][i], example['summary'][i]))\n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "다음 글을 요약해주세요:\n",
      "\n",
      "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n",
      "\n",
      "<end_of_turn><eos>\n"
     ]
    }
   ],
   "source": [
    "prompt_ex_one = generate_prompt(TRAIN_DATA[:1])[0]\n",
    "print(prompt_ex_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 QLoRA 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha = 8,\n",
    "    lora_dropout = 0.05,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# r (8로 증가):\n",
    "# 장점: 더 복잡한 표현이 가능해져 성능이 개선될 수 있음.\n",
    "# 단점: 메모리 사용량이 늘어나고, 계산 비용이 증가.\n",
    "# lora_alpha (16로 증가):\n",
    "# 장점: LoRA의 출력 강도가 커져서, 모델 성능이 좋아질 가능성.\n",
    "# 단점: 오버피팅 가능성 증가, 훈련 시간이 더 길어질 수 있음.\n",
    "# lora_dropout (0.1로 증가):\n",
    "# 장점: 과적합 방지에 도움이 되어, 모델의 일반화 성능이 향상.\n",
    "# 단점: 너무 큰 드롭아웃 값은 학습 성능 저하로 이어질 수 있음.\n",
    "# target_modules: LoRA를 적용할 모델 레이어들입니다. 주로 트랜스포머의 어텐션 및 피드포워드 관련 레이어에 적용됩니다.\n",
    "# target_modules: LoRA가 적용되는 모듈의 범위를 줄이면 연산량 감소, 특정 성능 유지. 하지만, 너무 적은 모듈에 적용하면 학습 성능 저하.\n",
    "# ???task_type=\"CAUSAL_LM\": 이 설정은 모델이 Causal Language Modeling 작업에 적합하도록 맞춰집니다.\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# load_in_4bit=True:\n",
    "# 장점: 메모리 사용량이 줄어들어 대형 모델을 작은 GPU에서도 실행 가능.\n",
    "# 단점: 양자화로 인해 성능이 약간 떨어질 수 있음.\n",
    "\n",
    "# bnb_4bit_quant_type=\"fp4\" (fp4로 변경):\n",
    "# 장점: 더 높은 계산 정밀도를 제공, 양자화로 인한 성능 손실을 줄임.\n",
    "# 단점: 메모리 사용량이 약간 늘어날 수 있음.\n",
    "\n",
    "# bnb_4bit_compute_dtype=torch.bfloat16 (bfloat16으로 변경):\n",
    "# 장점: float16보다 더 넓은 범위를 처리해, 안정성 향상.\n",
    "# 단점: 연산 속도가 약간 느려질 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb8e451a7de45b69f2da9218bee952c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map=\"auto\", quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "# 오른쪽에만 패딩을 넣는 이유는 주로 Causal Language Modeling (예측 기반 언어 모델)에서 모델이 입력의 왼쪽에서 오른쪽으로 순차적으로 문맥을 처리하기 때문입니다. 오른쪽에 패딩을 넣으면 패딩된 부분이 미래의 토큰처럼 처리되지 않으며, 자연스러운 문맥 예측이 가능합니다. 특히 GPT 계열 모델처럼 시퀀스 생성 방식의 모델에서 이러한 방식은 매우 중요합니다.\n",
    "# 왼쪽에 패딩을 넣으면 패딩이 문맥에 영향을 줄 수 있어 예측 성능이 떨어질 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Trainer 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc3d9bb40234d9ebefb20d563362e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlp/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=TRAIN_DATA,\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"outputs\",\n",
    "        num_train_epochs = 2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        warmup_ratio=1,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        fp16_full_eval=True,  # kkh 추가함\n",
    "        logging_steps=100,\n",
    "        push_to_hub=False,\n",
    "        report_to='none',\n",
    "    ),\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=generate_prompt,\n",
    ")\n",
    "\n",
    "# model=model: 미리 학습된 모델을 트레이너에 전달합니다.\n",
    "# train_dataset=TRAIN_DATA: 훈련에 사용할 데이터셋.\n",
    "# max_seq_length=512: 입력 시퀀스의 최대 길이.\n",
    "# output_dir=\"outputs\": 훈련 후 결과를 저장할 디렉토리.\n",
    "# num_train_epochs=1: 전체 데이터셋에 대해 1번의 에포크로 훈련.\n",
    "# max_steps=100: 최대 100 스텝까지 훈련.\n",
    "# per_device_train_batch_size=1: 장치당 배치 크기.\n",
    "# gradient_accumulation_steps=4: 4 스텝마다 경사도를 누적.\n",
    "# optim=\"paged_adamw_8bit\": 8비트 AdamW 옵티마이저 사용.\n",
    "# warmup_ratio=0.02: 학습률 워밍업 비율.\n",
    "# learning_rate=2e-4: 학습률.\n",
    "# fp16=True: 16비트 부동소수점 연산 사용.\n",
    "# fp16_full_eval=True: 평가 시에도 FP16 사용.\n",
    "# logging_steps=100: 100 스텝마다 로그 기록.\n",
    "# push_to_hub=False: 허브로 푸시하지 않음.\n",
    "# report_to='none': 로깅을 사용하지 않음.\n",
    "# peft_config=lora_config: LoRA(매개변수 효율적인 미세 조정) 설정.\n",
    "# formatting_func=generate_prompt: 데이터셋 전처리용 함수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='945' max='4668' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 945/4668 21:14 < 1:23:50, 0.74 it/s, Epoch 0.61/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.272100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.216600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m best_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 가장 낮은 train loss를 추적하기 위한 변수\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(trainer\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_train_epochs)):  \u001b[38;5;66;03m# 에포크 루프\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     train_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 한 에포크의 학습 진행\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_output\u001b[38;5;241m.\u001b[39mtraining_loss  \u001b[38;5;66;03m# 현재 에포크의 train loss\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# 가장 낮은 train loss가 발견되면 모델 저장\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:361\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 361\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/transformers/trainer.py:2341\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2339\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[0;32m-> 2341\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2345\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/optimizer.py:136\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_patched_step_method\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called:\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;66;03m# If the optimizer step was skipped, gradient overflow was detected.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/amp/grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 351\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/accelerate/optimizer.py:191\u001b[0m, in \u001b[0;36mpatch_optimizer_step.<locals>.patched_step\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpatched_step\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    190\u001b[0m     accelerated_optimizer\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py:287\u001b[0m, in \u001b[0;36mOptimizer8bit.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state(group, p, gindex, pindex)\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch_state(p)\n\u001b[0;32m--> 287\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_paged:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# all paged operation are asynchronous, we need\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m# to sync to make sure all tensors are in the right state\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/optim/optimizer.py:542\u001b[0m, in \u001b[0;36mOptimizer2State.update_step\u001b[0;34m(self, group, p, gindex, pindex)\u001b[0m\n\u001b[1;32m    540\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax2\u001b[39m\u001b[38;5;124m\"\u001b[39m], state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_max2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_max2\u001b[39m\u001b[38;5;124m\"\u001b[39m], state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock_wise\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 542\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_update_8bit_blockwise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbetas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbetas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqmap1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqmap2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabsmax1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabsmax2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgnorm_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgnorm_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_zeros\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskip_zeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/functional.py:1788\u001b[0m, in \u001b[0;36moptimizer_update_8bit_blockwise\u001b[0;34m(optimizer_name, g, p, state1, state2, beta1, beta2, eps, step, lr, qmap1, qmap2, absmax1, absmax2, weight_decay, gnorm_scale, skip_zeros)\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient+optimizer bit data type combination not supported: grad \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, optimizer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate1\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1785\u001b[0m     )\n\u001b[1;32m   1786\u001b[0m post_call(prev_device)\n\u001b[0;32m-> 1788\u001b[0m \u001b[43mis_on_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqmap1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqmap2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabsmax1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabsmax2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1790\u001b[0m prev_device \u001b[38;5;241m=\u001b[39m pre_call(g\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1791\u001b[0m optim_func(\n\u001b[1;32m   1792\u001b[0m     get_ptr(p),\n\u001b[1;32m   1793\u001b[0m     get_ptr(g),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1808\u001b[0m     ct\u001b[38;5;241m.\u001b[39mc_int32(g\u001b[38;5;241m.\u001b[39mnumel()),\n\u001b[1;32m   1809\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes/functional.py:426\u001b[0m, in \u001b[0;36mis_on_gpu\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    424\u001b[0m     on_gpu \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_paged\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_paged:\n\u001b[0;32m--> 426\u001b[0m         \u001b[43mgpu_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m on_gpu:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll input tensors need to be on the same GPU, but found some tensors to not be on a GPU:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[(t\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;250m \u001b[39mt\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mt\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mtensors]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    430\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_train_loss = float('inf')  # 가장 낮은 train loss를 추적하기 위한 변수\n",
    "for epoch in range(int(trainer.args.num_train_epochs)):  # 에포크 루프\n",
    "    train_output = trainer.train()  # 한 에포크의 학습 진행\n",
    "    train_loss = train_output.training_loss  # 현재 에포크의 train loss\n",
    "\n",
    "    # 가장 낮은 train loss가 발견되면 모델 저장\n",
    "    if train_loss < best_train_loss:\n",
    "        best_train_loss = train_loss\n",
    "        trainer.model.save_pretrained(ADAPTER_MODEL + \"_\" + str(best_train_loss))  # 가장 낮은 train loss 시점의 모델 저장\n",
    "        print(f\"Best model saved with train loss: {best_train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(ADAPTER_MODEL + \"_1.2166\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Finetuned Model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf97be4c7f194c169fcef5074d03906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ADAPTER_MODEL = ADAPTER_MODEL + \"_1.2166\" # 최고의 모델을 폴더에서 찾아서 적어야 함\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(FINETUNE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Fine-tuned 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe239460add472e9806ae4c22d1b56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Fine-tuned 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_0,실장님이 더슨 씨에게 내부 메모로 전달해야 하는지 물어봅니다. 더슨 씨는 실장님에게 모든 직원들에게 메모를 준비하라고 요청합니다.\n",
      "test_1,\"#Person2#는 교통 체증에 걸렸고, #Person1#은 #Person2#에게 대중교통을 이용하라고 조언한다. #Person2#는 #Person1#이 자전거로 출근하라고 제안한다.\"\n",
      "test_2,#Person1#은 케이트에게 마샤와 히어로가 이혼하려고 한다고 말한다. 케이트는 놀라며 이혼이 놀라운 일이라고 생각한다.\n",
      "test_3,\"브라이언은 #Person1#의 생일 파티에서 춤을 추고, #Person1#은 그를 위해 술을 마시는 것을 기쁘게 생각한다.\"\n",
      "test_4,#Person2#는 #Person1#에게 올림픽 공원의 중심인 올림픽 스타디움에 대해 설명합니다.\n",
      "test_5,\"#Person1#은 #Person2#에게 사업 계획서 작성에 대해 묻습니다. #Person2#는 #Person1#에게 사업 아이디어, 회사, 상품, 서비스, 시장 분석, 재무 분석, 투자자 정보 등을 포함하는 사업 계획서 작성에 대해 가르칩니다.\"\n",
      "test_6,#Person2#는 수두에 걸렸다고 #Person1#에게 말한다. #Person1#는 #Person2#가 수두에 걸린 것 같다고 생각하고 #Person2#에게 의사를 만나라고 권한다.\n",
      "test_7,#Person2#는 체크아웃하고 세탁 서비스 비용을 청구받았습니다. #Person1#는 실수로 청구서를 수정할 것입니다.\n",
      "test_8,\"#Person1#은 자신의 잘못을 깨달았고, 아내와 이혼하려고 합니다. 스티븐은 #Person1#에게 그녀를 설득하기 위해 최선을 다하겠다고 맹세합니다.\"\n",
      "test_9,\"#Person2#는 #Person1#에게 에이브러햄 링컨을 예로 들어, 그가 미국 대통령으로서의 성격을 소개합니다.\"\n",
      "test_10,#Person1#은 #Person2#에게 허베이가 모래폭풍에 취약하다고 말합니다.\n",
      "test_11,\"프란시스는 #Person2#에게 그의 생일 파티에 초대하고, #Person2#는 프란시스에게 선물을 준다. 프란시스는 그것을 매우 좋아한다.\"\n",
      "test_12,토니는 스티븐에게 부정행위를 하다가 실패했다고 말한다. 스티븐은 그가 공부하지 않고 부정행위를 했다고 생각한다.\n",
      "test_13,#Person1#은 톰에게 늦은 것에 대해 묻습니다. 톰은 20분이면 충분하다고 생각합니다.\n",
      "test_14,\"#Person1#은 매일 밤 잠을 잘 못 자고, 자주 피곤해합니다. #Person2#는 #Person1#에게 충분한 수면을 취하고, 매일 아침 운동을 좀 해보라고 조언합니다.\"\n",
      "test_15,\"#Person1#은 루오지아의 파티에 #Person2#를 초대합니다. #Person1#은 루오지아가 결혼했다고 #Person2#에게 알리고, #Person2#는 차 세트를 사야 합니다.\"\n",
      "test_16,\"#Person1#은 #Person2#에게 줄기를 당기고 뒷면을 벗기라고 말한다. #Person2#는 그것이 재미있다고 생각하지만, #Person1#은 그것이 잔인하다고 생각한다.\"\n",
      "test_17,#Person1#은 마이크에게 누나에 대해 물어본다. 마이크는 그녀가 #Person1#과 비슷하지만 그녀는 #Person1#보다 똑똑하지 않다고 말한다.\n",
      "test_18,#Person1#은 머리가 아프다고 #Person2#에게 말합니다. #Person2#는 #Person1#에게 체온을 측정하고 전화를 걸라고 조언합니다.\n",
      "test_19,\"#Person2#는 새로운 휴대폰을 사고 싶어하고, #Person1#은 #Person2#에게 카메라, MP3 플레이어, 그리고 비디오 통화 기능이 있는 휴대폰을 추천합니다.\"\n",
      "test_20,\"프랭크는 주디에게 새로운 일자리를 얻은 것을 알리고, 그 이유는 우체국에서 일하는 것이 그에게 좋은 건강보험 혜택을 제공한다는 것을 설명한다.\"\n",
      "test_21,\"#Person2#는 #Person1#에게 #Person2#가 컴퓨터 프로그램을 작성할 수 있으며, 비서 기술에 능숙하고, 의사 면허와 운전 면허를 가지고 있다고 말합니다.\"\n",
      "test_22,#Person1#은 스테이크가 너무 익혀져서 미디엄 레어로 바꿔달라고 요청했습니다.\n",
      "test_23,#Person1#은 톰에게 그의 소설이 노벨상을 받았다고 알려준다. 톰은 놀라워한다.\n",
      "test_24,#Person2#는 #Person1#에게 #Person2#가 자동차 디자인 전공자이며 과학 석사 학위를 가지고 있다고 말합니다.\n",
      "test_25,\"#Person1#은 맥주를 좋아하지 않고, #Person2#는 술을 많이 마셔요. #Person1#은 맥주를 좋아하지 않지만, #Person2#는 술을 많이 마셔요.\"\n",
      "test_26,\"#Person1#은 메이에게 피크닉 준비를 도와달라고 요청한다. 메이는 다니엘에게 도움을 청하지만, 그는 혼자서 할 수 있다고 말한다.\"\n",
      "test_27,드루글라스씨와 더글라스씨는 서로 인사를 나누고 휴가에 대해 이야기합니다. 더글라스씨는 수잔에게 스키를 타는 것을 즐겼다고 말합니다.\n",
      "test_28,\"#Person1#은 ATM에서 돈을 뽑고 싶지만 바보 같은 기계로 인해 돈이 나가지 않습니다. #Person2#는 #Person1#에게 위험한 상황이라고 말하고, 현지 당국이 도착할 때까지 문이 잠겨 있을 것이라고 말합니다.\"\n",
      "test_29,\"#Person2#는 #Person1#에게 사회적인 사람이라고 말하고, 소통에서 가장 중요한 것은 당신의 진심이라고 말합니다.\"\n",
      "test_30,폴리 씨는 끔찍한 일 때문에 탄산 음료를 사고 싶어합니다. #Person1#은 폴리 씨가 가게에 가서 한 병을 사는 것을 도와줍니다.\n",
      "test_31,모니카는 프란시스에게 보고서를 언제 작업할 수 있을지 묻습니다. 프란시스는 금요일 오후 1시부터 4시까지 가능합니다.\n",
      "test_32,\"#Person2#는 #Person1#에게 면접 수업에 대해 설명하고, 면접에서 무엇을 해야 할지에 대한 추가적인 팁을 제공합니다.\"\n",
      "test_33,#Person1#은 #Person2#에게 제이슨과 로라는 이미 3년 동안 함께 있었기 때문에 분노와 슬픔을 동시에 느끼지 않을 것이라고 말한다.\n",
      "test_34,#Person1#은 토드 부인을 방문하고 싶어합니다. 토드 부인은 #Person1#에게 정원에 있는 그녀를 인사하러 가기로 합니다.\n",
      "test_35,\"빌은 피곤해요. 그는 매일 밤 10시쯤까지 일했고, 미국에 출장을 갔어요. 그의 동생은 아직도 출장을 갔다고 합니다.\"\n",
      "test_36,\"클레오는 시위에 가고 싶지 않지만, 사이먼은 그녀에게 시위에 가는 것을 격려한다. 클레오는 시위가 평화롭다고 생각하고, 그녀의 언니에게 커피를 마시러 가야 한다.\"\n",
      "test_37,#Person1#은 사람들이 자신의 잘못을 말하지 않도록 하기 위해서 사람들이 자신의 잘못을 말하지 않도록 하기 때문에 그들이 말하는 것을 막는다고 말합니다.\n",
      "test_38,마크는 매기에게 역사 과목 노트를 빌려달라고 요청한다. 매기는 마크에게 수업 중에 깨어 있을 때 깨우는 것을 약속한다.\n",
      "test_39,#Person2#는 터너 교수님의 강의를 좋아하고 미국 서부의 지질학에 관심이 많습니다. #Person2#는 터너 교수님에게 등록을 허락해 달라고 요청합니다.\n",
      "test_40,\"#Person1#은 펜던트가 부러졌고, #Person2#는 #Person1#에게 새 것으로 바꿔줄 것입니다.\"\n",
      "test_41,\"#Person1#은 #Person2#에게 스웨터를 보여주고, #Person2#는 그 스웨터가 너무 화려하다고 생각합니다. #Person1#은 #Person2#에게 빨리 결정하라고 요청합니다.\"\n",
      "test_42,#Person2#는 #Person1#에게 잡지를 위해 글을 쓰는 것과 컴퓨터와 함께 일하는 것을 좋아한다고 말한다.\n",
      "test_43,#Person2#는 막 왔지만 #Person1#는 그에게 몇 가지 방법을 제안한다. #Person1#는 #Person2#에게 신문을 읽고 십자말풀이 게임을 하라고 조언한다.\n",
      "test_44,사라는 #Person1#에게 그녀의 남편과 사는 이유가 회사 근처에 집을 사는 것이 비싸다는 것을 말해줍니다. 사라는 시누이와 남편이 방금 그런 식으로 집을 샀다고 #Person1#에게 말해줍니다.\n",
      "test_45,\"#Person1#은 '만나는 사람들'에서 마크 리치를 인터뷰합니다. 마크 리치는 정보 팀의 담당관으로, 매년 약 50만 명의 방문객들을 대상으로 관광 정보 서비스를 제공합니다.\"\n",
      "test_46,\"루시와 린팡은 영어와 수학이 어렵다고 생각하는 반면, 낸시는 영어를 좋아하고 수학을 싫어한다.\"\n",
      "test_47,제임스는 토마스 부인에게 낙엽을 다 씻고 제사를 쓸 때 도와준다. 토마스 부인은 제사를 쓸 때 제사를 쓸 때 도와준다.\n",
      "test_48,#Person1#은 난방을 꺼버리고 밤에 여전히 춥다고 #Person2#에게 말합니다. #Person2#는 밖에 나가서 바람을 불어넣는 것을 제안합니다.\n",
      "test_49,#Person1#은 마이크에게 3년 동안 함께해온 제이슨과 로라는 3년 동안 함께 있었기 때문에 제이슨과 로라는 상처받고 슬퍼하지 않을 것이라고 말한다.\n",
      "test_50,\"#Person1#은 프렌드십 호텔로 가는 택시를 요청하고, #Person2#는 #Person1#에게 거스름돈을 주고 있습니다.\"\n",
      "test_51,#Person1#은 배가 고프다. #Person2#는 버스 기사에게 환승을 요청하라고 조언한다.\n",
      "test_52,\"#Person2#는 #Person1#에게 시내로 가는 방법, 회사들이 있는 곳, 그리고 직원 식당이 있는지 알려줍니다.\"\n",
      "test_53,#Person1#은 #Person2#에게 루루가 빅과 헤어졌다고 말한다.\n",
      "test_54,\"샐리는 데이브에게 짐이 짐이 없다고 전화를 걸었고, 데이브는 샐리에게 전화를 걸어달라고 요청했습니다.\"\n",
      "test_55,\"#Person2#는 #Person1#에게 시청으로 가는 방법을 알려주고, #Person1#은 #Person2#의 조언을 따라가고 있습니다.\"\n",
      "test_56,#Person1#은 여권을 반납한 사람이 없다고 #Person2#에게 말합니다. #Person2#는 #Person1#에게 여권을 찾는 데 도움을 줍니다.\n",
      "test_57,레아가 나다니엘에게 전화를 걸어 콜린스 선생님에게 전화를 할 수 없다고 말합니다. 레아는 오늘 오후 2시 15분에 리우 씨와 통화하기로 결정합니다.\n",
      "test_58,#Person1#은 #Person2#에게 그녀가 딕 이외의 남자와는 결혼하지 않겠다고 말했을 때 무서웠다고 말합니다.\n",
      "test_59,#Person1#과 #Person2#는 파티에서 즐거운 시간을 보내고 있다. 그들은 섹시한 여자들과 맥주를 마시고 있다. #Person1#은 #Person2#에게 그녀를 격려한다.\n",
      "test_60,\"잭은 #Person1#에게 이번 학기 수업이 정치학 수업이었고, 작년에 비즈니스 커뮤니케이션 수업을 들었다고 말했다.\"\n",
      "test_61,#Person1#과 #Person2#는 베이징의 날씨에 대해 이야기하고 있습니다. 그들은 베이징의 가을이 아름답고 여름이 아쉽다고 생각합니다. 그들은 또한 베이징의 봄과 겨울에 대해 이야기합니다.\n",
      "test_62,\"#Person1#은 #Person2#에게 영화를 보러 가자고 제안하지만, #Person2#는 추리 영화, 코미디, 러브 스토리, 전쟁 영화를 거절합니다.\"\n",
      "test_63,\"#Person1#은 아담에게 학교 구경을 제안하고, 그들은 학교 구경을 한다.\"\n",
      "test_64,#Person1#은 #Person2#에게 #Person2#의 아버지가 될 것이라고 말한다.\n",
      "test_65,#Person1#과 #Person2#는 존이 일주일에 그녀와 일곱 번이나 만나고 있다고 생각합니다.\n",
      "test_66,\"#Person1#은 #Person2#에게 시스템 업그레이드를 고려해 보라고 조언합니다. #Person1#은 #Person2#에게 더 빠른 프로세서, 더 많은 메모리, 더 빠른 모뎀, CD-ROM 드라이브를 추가하는 것을 제안합니다.\"\n",
      "test_67,#Person2#는 중국에서 온 멕시코 사람이지만 #Person1#는 40살이고 미국에서 태어났습니다. #Person1#는 #Person2#가 젊고 흥미롭다고 생각합니다.\n",
      "test_68,#Person1#은 체중을 줄이고 싶어합니다. #Person2#는 식단 조절을 제안하고 운동을 더 해보라고 제안합니다.\n",
      "test_69,\"#Person1#은 8인 룸을 예약해주고, #Person2#에게 안내를 해줍니다.\"\n",
      "test_70,\"#Person2#는 #Person1#에게 공장의 면적, 설립 년도, 그리고 생산 공장에 대한 정보를 알려줍니다.\"\n",
      "test_71,\"레베카는 #Person1#에게 그녀의 대학 졸업 후 첫 직장에 대해 이야기합니다. 그녀는 지역 신문사에서 인턴으로 시작하여, 그 다음에는 지역 뉴스 기자 자리를 잡았습니다. 그녀는 런던에 본사를 둔 국가 신문사에서 자리를 찾았습니다.\"\n",
      "test_72,\"#Person1#은 #Person2#에게 발표를 위해 포스터를 만들기 위한 물건을 사러 문구점에 가라고 요청합니다. #Person2#는 먼저 쇼핑 목록을 만들고, 그 후 #Person1#에게 마커, 색연필, 형광펜, 브러시, 압정, 수정테이프, 클립을 사는 것을 요청합니다.\"\n",
      "test_73,메리는 매일 인력시장에 가서 많은 에너지를 소비하고 있습니다. #Person1#은 메리에게 인터넷에서 일자리를 찾는 방법을 가르쳐줍니다.\n",
      "test_74,#Person2#는 #Person1#에게 #Person2#의 예산 계획을 말해줍니다.\n",
      "test_75,\"제인은 수잔을 볼려고 병원에 가고, 헨리는 그녀를 보러 가는 방법을 제안한다.\"\n",
      "test_76,#Person1#은 판매 예측에 대해 이야기하고 싶어합니다. #Person2#는 다음 주 화요일 오후 2시 30분에 #Person1#을 그의 사무실로 데려다 줄 예정입니다.\n",
      "test_77,\"#Person2#는 #Person1#에게 뉴욕의 친구 서비스를 추천하고, 그 서비스는 개인 투어 가이드 서비스라고 말합니다.\"\n",
      "test_78,#Person2#는 #Person1#에게 회사의 위치와 직원 수에 대해 설명합니다. #Person2#는 영업 부서에서 일하고 싶어합니다. #Person1#는 #Person2#에게 시작 급여와 보너스에 대해 설명합니다.\n",
      "test_79,#Person1#은 계약서를 서명하고 싶어합니다. #Person2#는 계약서가 아직 준비되지 않았다고 말합니다. #Person1#은 오늘 중으로 받을 수 있도록 요청합니다.\n",
      "test_80,#Person1#은 차량 사고가 났고 친구가 심각하게 다쳤다고 #Person2#에게 말합니다. #Person2#는 바로 구급차와 경찰을 불러줄 것입니다.\n",
      "test_81,#Person2#는 #Person1#에게 학교 클리닉으로 가는 길을 알려줍니다.\n",
      "test_82,\"#Person2#는 방을 바꾸고 싶어합니다. #Person1#는 내일은 여분의 방이 없지만 내일 아침에 떠날 예정이므로, #Person2#는 내일 저녁 스위트룸에서 잠을 잘 수 있기를 바랍니다.\"\n",
      "test_83,\"#Person2#는 #Person1#의 도움으로 베이징 호텔에 탑승합니다. #Person1#은 #Person2#에게 호텔 서비스가 좋다고 말하고, #Person2#를 연회에 초대합니다.\"\n",
      "test_84,#Person1#은 길을 잃고 있습니다. #Person2#는 #Person1#에게 리우 이창으로 가는 방법을 알려줍니다.\n",
      "test_85,#Person2#의 컴퓨터가 계속 멈춰서 #Person1#은 수리공에게 전화할 것이다.\n",
      "test_86,\"#Person2#는 내일 #Person2#의 어머니의 생신을 기념하기 위해 좋은 선물을 찾고 있습니다. #Person1#은 금 시계를 추천하고, #Person2#는 그것을 선택합니다.\"\n",
      "test_87,\"로스 씨는 피셔 씨에게 자신의 회의를 위해 50명 이상의 참석자를 예상하고 있다고 말합니다. 피셔 씨는 100장의 초대장을 보냈지만, 로스 씨는 30명 정도만 올 것으로 예상합니다.\"\n",
      "test_88,\"#Person2#는 #Person1#에게 러시아와 캐나다의 주요 차이점을 설명합니다. #Person2#는 러시아에서 은행에 가는 것이 몇 시간이 걸리고, 캐나다에서는 이런 곳들을 빠르게 통과하는 것이 상당히 쉽다고 말합니다.\"\n",
      "test_89,\"#Person2#는 카리브해로 여행을 가려고 하고, #Person1#은 그곳의 날씨가 가끔 정말 안 좋을 때가 있다고 말합니다.\"\n",
      "test_90,#Person1#은 소풍 갈 때 가져갈 과일을 엄마에게 물어봅니다.\n",
      "test_91,\"#Person2#는 #Person1#에게 소형차 렌트 비용을 알려주고, #Person1#의 운전 면허증을 요청합니다.\"\n",
      "test_92,#Person1#은 #Person2#에게 사람들이 질리지 않고 미소를 유지하는 것을 보는 것을 좋아한다고 말합니다.\n",
      "test_93,\"#Person1#과 #Person2#는 이전에 이렇게 많이 팔아본 적이 없지만, 올해 성장률이 놀랍다고 말합니다. 그들은 회사의 성과에 대해 이야기합니다.\"\n",
      "test_94,\"#Person2#는 #Person1#에게 내 지갑을 잃어버렸다고 말한다. #Person1#는 #Person2#에게 돈을 빌려주고, #Person2#가 돈을 갚을 때 50달러를 요구한다.\"\n",
      "test_95,\"린은 스티븐에게 중국에서의 식사를 칭찬하고, 중국에서의 팁에 대해 묻습니다. 스티븐은 팁을 주지 않고, 택시 기사와 짐꾼들에게는 팁을 받지 않도록 지시받습니다.\"\n",
      "test_96,빌은 #Person1#에게 그의 룸메이트 브레인 로커에 대해 이야기한다.\n",
      "test_97,\"#Person1#은 톰 윌슨이고, #Person2#는 #Person1#의 청구서를 확인하고, #Person1#은 신용카드로 청구서를 지불합니다.\"\n",
      "test_98,#Person1#이 #Person2#에게 캐롤이 지금 전화를 받을 수 없습니다. #Person2#는 캐롤이 내일 밤 8시 30분에 질의 집에서 디저트를 가져오라고 말해줄 것이라고 #Person1#에게 알려줍니다.\n",
      "test_99,\"#Person1#은 #Person2#를 커먼 헬스장에서 본 것 같다고 생각합니다. #Person2#는 모르겠지만, #Person1#은 그를 기억합니다.\"\n",
      "test_100,#Person1#과 #Person2#는 대통령 선거에서 어떻게 생각하는지에 대해 이야기하고 있습니다.\n",
      "test_101,#Person2#는 #Person1#에게 ATM 사용법을 가르쳐준다.\n",
      "test_102,수잔이 존에게 메모 복사본을 요청합니다.\n",
      "test_103,\"#Person1#은 릴리에게 강가로 소풍을 가는 것을 제안하고, 릴리는 그것이 좋다고 생각합니다.\"\n",
      "test_104,\"#Person2#는 중국 사람들이 독특한 경험을 하며, 외국인이 중국 식사 도구에 익숙해지는 것이 어렵다고 말합니다. #Person1#는 젓가락을 놓아서는 안 된다고 말합니다.\"\n",
      "test_105,\"메리는 프랭크에게 그녀가 대부분의 시간을 영화 보내고, 프랭크는 어떤 종류의 영화를 좋아하는지에 대해 이야기한다.\"\n",
      "test_106,\"#Person2#는 정치 당에 소속되어 있지 않았지만, 녹색당에 가입하는 것을 생각해 본 적이 있습니다. #Person1#는 정치 당이 선거에서 이길 가능성이 없다고 말합니다.\"\n",
      "test_107,\"윌슨 씨는 #Person1#에게 상품의 실수에 대해 사과하고, 샘플에 미치지 못하는 모든 상품을 교환하겠다고 합니다.\"\n",
      "test_108,#Person2#는 강도가 들어왔지만 모든 것을 보지 못했습니다. #Person1#는 #Person2#에게 추가 질문을 요청합니다.\n",
      "test_109,#Person2#는 아빠와 엄마를 데리고 나가는 데이트를 하려고 합니다. #Person1#는 그것이 정기적으로 일어날 것이라고 생각합니다.\n",
      "test_110,#Person1#은 다이어트를 시작하기로 결정하고 캐롤에게 그 새로운 사람이 될 것이라고 말한다. 캐롤은 기다려야 한다.\n",
      "test_111,카렌 후앙은 비교문학 287 수업에 등록하고 싶어합니다. #Person1#은 그녀에게 터치톤 등록 시스템을 통해 등록하도록 도와줍니다.\n",
      "test_112,#Person1#은 급하게 가야 하기 때문에 #Person2#에게 깜빡한 급한 시간을 물어봅니다. #Person2#는 같이 걸어갈 것입니다.\n",
      "test_113,잭이 데이지에게 새 차를 보여준다. 데이지는 그 차가 빠르고 멋지다고 생각한다.\n",
      "test_114,#Person2#는 #Person1#에게 그 큰 불이 밤 10시쯤 일어났다고 말합니다.\n",
      "test_115,\"#Person2#는 남편의 계산서를 받고, #Person1#는 #Person2#에게 서비스 요금을 청구합니다. #Person2#는 남편의 신용카드를 가지고 있고, #Person1#는 영수증을 주고 포장해 줍니다.\"\n",
      "test_116,\"#Person2#는 #Person1#의 도움으로 차를 세차하고 싶어합니다. #Person1#는 일반 세차 패키지를 추천하고, #Person2#는 동의합니다.\"\n",
      "test_117,해리는 #Person1#에게 휴가 계획에 대해 이야기합니다. 그는 아내가 항상 걱정을 해서 여행을 가기 전에 이런 것들을 해결해야 한다고 말합니다.\n",
      "test_118,\"존슨은 #Person1#에게 기계를 어떻게 사용하는지 알려준다. 존슨은 웨이트를 해본 경험이 없고, #Person2#는 존슨에게 웨이트를 해보라고 권한다.\"\n",
      "test_119,\"#Person1#은 일자리를 잃었고, #Person2#는 면접 보러 간 적이 있다.\"\n",
      "test_120,#Person1#은 #Person2#에게 강아지들에게 밥을 주고 목욕을 시켜 줄 것을 요청합니다. #Person2#는 동의합니다.\n",
      "test_121,#Person1#은 에이든에게 200달러를 빚어서 집주인에게 돈을 갚으라고 요청한다. 에이든은 돈이 부족해서 거절한다. 그들은 결국 6시에 만날 예정이다.\n",
      "test_122,#Person2#는 자선 단체에서 일한 경험이 #Person2#의 사고 방식에 영향을 미쳤다고 말합니다.\n",
      "test_123,#Person1#은 #Person2#에게 연락을 어떻게 해야 하는지 물어봅니다.\n",
      "test_124,\"#Person2#는 #Person1#에게 무탄과 베이징 오리구이를 추천하고, #Person1#은 베이징 오리구이를 시도해보고 싶어합니다.\"\n",
      "test_125,댄이 안젤라에게 전화를 걸어 그녀에게 결혼식에 가는 메건을 초대한다. 안젤라는 댄에게 메건을 데리러 가자고 제안한다.\n",
      "test_126,#Person2#는 디저트 시간이에요. #Person1#는 디저트를 먹고 싶어서 #Person2#의 디저트를 먹어보려고 합니다. #Person2#는 티라미수를 먹어보고 바나나 튀김을 먹어보려고 합니다.\n",
      "test_127,\"#Person1#은 스미스 씨에게 스미스 씨의 대학, 학문, 나이, 그리고 직장 경험에 대해 물어봅니다.\"\n",
      "test_128,#Person1#은 #Person2#의 가게에서 바비 인형을 구입합니다.\n",
      "test_129,#Person2#는 조던 스포츠 신발을 사고 싶어합니다. #Person1#은 조던 스포츠 신발을 추천합니다.\n",
      "test_130,#Person1#은 과학 박물관에 가고 싶어합니다. #Person2#는 #Person1#에게 기차를 타고 박물관으로 가는 방법을 알려줍니다.\n",
      "test_131,\"#Person1#은 은퇴 후에 어떻게 보내고 싶어하는지에 대해 사이먼에게 묻습니다. 사이먼은 단계적 은퇴라는 프로그램에 참여하고 있어서, 일을 6개월 동안 쉰 후에는 회사에서 프로젝트 작업을 신청할 수 있습니다.\"\n",
      "test_132,\"#Person1#은 로키에게 밤새도록 앉아서 여자를 만나라고 요청하지만, 로키는 여자를 좋아하지 않는다. 로키는 집에 있고, #Person1#은 로키에게 외향적이고 사람들의 차이를 비판하지 않는 여자를 좋아한다고 말한다.\"\n",
      "test_133,#Person1#과 #Person2#는 폭풍에 대해 이야기하고 있습니다. 그들은 불평하지 않습니다.\n",
      "test_134,\"#Person1#은 TV를 보는 것이 지루하다고 생각하지만, #Person2#는 그것이 나에게 좋지 않다고 생각한다. 그들은 함께 나눌 수 있는 다양한 활동을 찾을 것이다.\"\n",
      "test_135,\"#Person1#은 벤에게 내일 수업 준비를 격려하고, 수업 시간표와 점심시간에 대해 알려준다.\"\n",
      "test_136,\"애덤은 의사에게 무릎이 훨씬 나아졌다고 말하고, 토요일에는 괜찮을 것 같다고 말한다. 애덤은 미시간이 강한 팀이므로 경기를 하게 될 것이라고 생각한다. 애덤은 내일 전체 훈련에 참여하러 돌아올 것이다.\"\n",
      "test_137,\"#Person1#은 프린터가 고장났고, #Person2#는 그것을 복사해주는 것을 요청합니다.\"\n",
      "test_138,#Person1#은 커튼을 걸고 싶어하고 #Person2#는 #Person1#을 도와줄 것이다.\n",
      "test_139,#Person1#은 잭에게 주말 캠핑 여행을 계획하고 싶어합니다. 잭은 다다음 주말이 괜찮을 것 같다고 생각합니다.\n",
      "test_140,#Person2#는 #Person1#에게 #Person2#가 임신했다고 말한다. #Person3#는 #Person2#에게 #Person2#가 실제로 임신했다고 말한다. #Person2#는 #Person1#에게 #Person2#가 아기가 #Person2#의 아기가 아니라고 말한다.\n",
      "test_141,#Person2#는 딸이 대학을 결정하지 못하고 있다. #Person1#는 #Person2#에게 딸이 스스로 결정을 내릴 수 있다고 말한다.\n",
      "test_142,\"#Person1#은 직장을 잃고 싶지 않지만, #Person1#의 상사는 #Person1#가 진실을 말하지 않을 것이라고 말한다. #Person1#은 #Person2#에게 #Person1#의 돈을 어떻게 사용할지 물어본다. #Person2#는 #Person1#에게 평소에 사던 불필요한 것들을 몇 달 동안 사지 않으면 돈을 절약할 수 있다고 말한다.\"\n",
      "test_143,#Person2#는 #Person1#에게 #Person2#의 친구가 영국에서 방문을 왔다고 말한다. #Person2#는 그 친구를 #Person2#의 연구실에서 강연하도록 초대할 예정이다.\n",
      "test_144,#Person1#은 존의 집에 가자고 제안하지만 #Person2#는 아프다고 말합니다. #Person2#는 잠을 자러 갈 것이라고 말합니다.\n",
      "test_145,파버 씨가 요크 호텔에 전화하여 3박 동안 더블룸을 예약했습니다.\n",
      "test_146,\"#Person2#는 #Person1#에게 웨스트 더비를 추천하고, #Person1#는 연립 주택에만 관심이 있다고 말합니다. #Person2#는 #Person1#에게 존 고드프리의 전화번호를 알려줍니다.\"\n",
      "test_147,#Person1#은 #Person2#가 경찰에게 돈을 주려고 하지 않았다면 이런 일이 일어나지 않았을 것이라고 주장합니다. #Person2#는 #Person1#이 잘못을 나고 있다고 생각합니다.\n",
      "test_148,달린이 댄에게 전화를 걸어 9월 10일에 주문한 컴퓨터에 대해 확인하라고 요청합니다. 댄은 사실 18일까지 주문을 전달할 수 있다고 말합니다.\n",
      "test_149,#Person1#과 #Person2#는 워싱턴 포스트와 뉴욕 타임즈에 대해 이야기하고 있습니다.\n",
      "test_150,#Person2#의 컴퓨터가 바이러스에 걸렸습니다. #Person1#은 압축해서 보내는 것을 제안합니다.\n",
      "test_151,#Person1#은 #Person2#에게 주말을 즐겁게 보냈다고 말합니다. #Person2#는 #Person1#에게 다시 다시 머물러 주실 것을 약속합니다.\n",
      "test_152,#Person1#은 #Person2#의 제안에 따라 중국 음식을 사올 것입니다.\n",
      "test_153,메리는 톰에게 판매 직원 자리를 다른 사람에게 제공하기로 결정했다고 알려준다. 톰은 기회를 주실 것을 부탁한다.\n",
      "test_154,#Person1#은 #Person2#에게 전화를 걸어 #Person2#가 체포될 것이라고 경찰에 신고하라고 요청합니다.\n",
      "test_155,#Person2#는 음악 선생님이 되고 싶어합니다. #Person2#는 음악 선생님이 되고 싶어하는 이유는 #Person2#가 어릴 때부터 음악을 좋아했기 때문입니다. #Person2#는 클래식 음악을 좋아합니다. #Person1#는 #Person2#에게 클래식 음악을 듣는 것이 스트레스를 줄이는 데 도움이 된다고 말합니다. #Person1#는 인터넷에서 클래식 음악을 찾아보라고 추천합니다.\n",
      "test_156,#Person2#는 #Person1#에게 오늘 저녁에 미국 여자와 만났다고 말합니다. #Person2#는 그녀를 저녁 식사에 초대하고 싶어합니다. #Person1#는 #Person2#에게 행운을 빌어줍니다.\n",
      "test_157,#Person1#은 미렐라가 회사에 어떻게 왔는지 봤다. #Person2#는 미렐라가 서부 해안의 일하는 방식에 영향을 받았다고 생각한다.\n",
      "test_158,#Person2#는 자신만의 법률 사무소를 세우려 하고 있습니다. #Person1#는 #Person2#에게 도움을 청하고 행운을 빌어줍니다.\n",
      "test_159,피터는 온라인 게임을 했고 케이트는 피터가 휴식을 취해야 한다고 말한다.\n",
      "test_160,#Person1#과 #Person2#는 사람들이 배로 여행하고 싶어하지 않는 이유가 대양간 화물 운송의 대부분이 배로 이루어지기 때문이라고 생각합니다.\n",
      "test_161,\"패니는 앤디에게 어젯밤 악몽을 꿨다고 말한다. 앤디는 어젯밤에 잠을 잘 못 잤다고 말한다. 앤디는 미친 밤이었고, 묘지를 헤집으며 나를 쫓는 유령들이 무덤에서 튀어나왔다고 말한다.\"\n",
      "test_162,#Person1#은 어니에게 캠퍼스에서 가장 멋진 학생들이 될 것이라고 말한다. 그들은 바닐라 아이스의 노래를 연주할 계획이다.\n",
      "test_163,\"#Person1#은 #Person2#에게 뉴올리언스 여행에 대해 묻고, #Person2#는 극장에 가는 것을 제안합니다.\"\n",
      "test_164,#Person1#은 신용카드로 #Person2#의 도움으로 옷을 구매했습니다.\n",
      "test_165,#Person1#은 포스터 씨에게 훈련 매뉴얼을 보내달라고 요청합니다. 포스터 씨는 지금 복사 중입니다.\n",
      "test_166,#Person2#는 #Person1#에게 휴가 계획을 세우고 있다고 말합니다. #Person2#는 롱아일랜드에서 4일 동안 운전을 하며 형과 그의 가족과 함께 그의 40번째 생일을 축하할 예정입니다.\n",
      "test_167,#Person1#은 파멜라를 돌보는 것을 잊고 비행기를 놓치고 싶지 않습니다. #Person2#는 #Person1#에게 파멜라를 돌보는 것을 도와줄 것이라고 약속합니다.\n",
      "test_168,#Person2#는 #Person1#에게 77번 거리에서 12번 버스를 타고 7번 거리까지 가는 길을 알려줍니다.\n",
      "test_169,\"#Person2#는 #Person1#에게 이슬람에 대한 프로그램을 소개하고, 무슬림들이 하지 않은 능력이 있는 모든 남자가 적어도 한 번은 하지 않는다고 말한다. #Person2#는 또한 #Person1#에게 영국, 프랑스, 그리고 루르드 같은 곳에서 사람들이 치유받으러 가는 곳에 대해 이야기한다.\"\n",
      "test_170,#Person1#은 센트럴 백화점으로 가는 길을 #Person2#에게 물어봅니다. #Person2#는 #Person1#에게 길을 알려줍니다.\n",
      "test_171,#Person1#은 #Person2#에게 런던에 가기 위해 기차로 가는 것을 제안한다. #Person2#는 기차가 더 비싸지만 더 빠르다고 생각한다.\n",
      "test_172,\"톰은 음식점에서 닭고기가 안 익었고, 캐서린은 집에서 싸온 점심을 먹었다. 그들은 미국인의 3분의 2가 패스트푸드를 피하는 것에 동의한다.\"\n",
      "test_173,\"#Person2#는 레모네이드 한 잔과 바비큐 윙을 주문하고, #Person1#는 #Person2#에게 나머지 음식 주문을 요청합니다.\"\n",
      "test_174,\"#Person2#가 #Person1#의 도움으로 더블 치즈버거, 감자튀김, 그리고 펩시콜라를 주문했습니다.\"\n",
      "test_175,#Person1#은 계란을 프라이하는 방법에 놀랍니다. #Person2#는 #Person1#에게 계란을 한쪽만 프라이하라고 조언합니다.\n",
      "test_176,#Person2#는 #Person1#에게 그랜드 호텔의 위치를 알려줍니다.\n",
      "test_177,#Person1#은 #Person2#의 사진을 찍고 싶어합니다. #Person2#는 괜찮다고 합니다.\n",
      "test_178,#Person2#는 내일 빈 방을 원합니다. #Person1#은 #Person2#에게 세 블록 떨어진 선셋 호텔을 추천합니다.\n",
      "test_179,\"#Person2#는 미국에 공부하러 가기 위해 비자를 신청하고, #Person1#에게 미국 가는 비자는 받기가 무척 어렵다고 말합니다. #Person2#는 양식을 제대로 작성하지 않거나 필요한 서류를 모두 내지 않기 때문이라고 생각합니다.\"\n",
      "test_180,\"앤은 삼-오에게 일찍 잘 거라고 말하고, 재미있게 놀았지만, 앤은 피곤해서 내일 술집에 가기에는 안 돼.\"\n",
      "test_181,메리는 온라인 쇼핑이 편리하고 시간을 절약한다고 말합니다. #Person1#은 온라인 은행에 계좌를 개설하고 온라인으로 옷을 사려고 했지만 어떻게 결제해야 하는지 알 수 없었습니다.\n",
      "test_182,#Person1#은 #Person2#에게 미국 회계에 대해 묻습니다.\n",
      "test_183,제인은 피터에게 시안으로 가는 여름 휴가에 대해 이야기한다. 제인은 피터에게 비용에 대해 알려준다. 그들은 휴가를 어디로 가고 싶은지에 대해 이야기한다.\n",
      "test_184,\"#Person2#는 #Person1#의 도움으로 영화를 대여합니다. #Person2#는 딸에게 보여줄 영화를 대여하고 싶어합니다. #Person1#는 #Person2#에게 회원 양식을 작성하라고 요청하고, #Person2#는 5달러 딜을 사용할 수 있습니다.\"\n",
      "test_185,#Person1#이 미스터 리에게 소포를 보냅니다. 미스터 리는 #Person1#에게 서명을 요청합니다.\n",
      "test_186,#Person2#는 #Person1#에게 내일 아침까지 비행기가 뜨지 못한다고 알려준다. #Person1#는 불을 켜놓지 않으면 잠을 자지 못한다.\n",
      "test_187,#Person1#은 #Person2#에게 컴퓨터를 도난당했다고 말합니다. #Person2#는 #Person1#에게 식당을 찾아줄 것이라고 말합니다.\n",
      "test_188,#Person2#는 스트레스 때문에 아직 잠을 잘 못 자고 있다. #Person1#는 #Person2#에게 요가 수업을 듣거나 이완 요법을 배우고 휴식을 취하라고 조언한다. #Person1#는 또한 #Person2#에게 음악을 듣는 것을 제안한다.\n",
      "test_189,#Person1#은 #Person2#에게 주방을 새롭게 만들고 싶다고 말합니다.\n",
      "test_190,월터는 스털링에게 정신이 딴 것 같다고 말한다.\n",
      "test_191,\"#Person1#은 #Person2#에게 검사 결과를 확인하러 왔습니다. #Person2#는 #Person1#에게 추가 검사를 하는 것을 제안하고, #Person1#은 오후에 다시 찾아갈 것입니다.\"\n",
      "test_192,마틴은 램 선생님의 도움으로 시험 준비를 하고 있습니다. 그는 또한 버스 요금을 지불할 수 없었습니다.\n",
      "test_193,#Person1#은 특급으로 소포를 한국에 보내고 싶어합니다. #Person2#는 패키지 우편을 추천합니다.\n",
      "test_194,#Person1#은 린다에게 휴대폰을 찾아달라고 요청한다. 린다는 결혼식 전에 휴대폰을 찾아가기 위해 여동생에게 전화할 것이다.\n",
      "test_195,#Person1#은 로스앤젤레스에서 영국인으로 여행을 했습니다. #Person2#는 #Person1#에게 음료를 가져다 줄 것을 약속했습니다.\n",
      "test_196,\"#Person1#은 여름방학이 다가오고 있고, #Person2#는 휴식을 취하고 싶어한다. #Person2#는 #Person1#에게 졸업 후에 장소를 찾아보고 직업에 대해 진지하게 생각할 것을 권한다.\"\n",
      "test_197,\"#Person2#는 차 사고를 당했고, #Person2#는 우유 배달 중에 개가 #Person2#를 쫓아가는 것을 찍었다.\"\n",
      "test_198,\"#Person2#는 #Person1#에게 6년 동안 일했던 회사에서의 변화에 대해 이야기합니다. #Person2#는 지금 일을 더 오래 하고 있고, 매니지먼트 교육 과정을 두 번 수료했습니다.\"\n",
      "test_199,#Person1#은 당좌예금 계좌를 개설하고 싶어합니다. #Person2#는 #Person1#에게 당좌예금 계좌는 이자를 지급하지 않는다고 알려줍니다. #Person1#은 돈을 어떻게 인출하길 원합니다.\n",
      "test_200,#Person1#은 중국 요리를 먹고 싶어합니다. #Person2#는 #Person1#에게 중국 요리에 대해 알려줍니다. #Person1#은 베이징 요리를 먹고 싶어합니다. #Person2#는 가장 좋은 곳을 알려줍니다.\n",
      "test_201,#Person2#는 배송이 느려서 상사에게 답을 요청합니다. #Person1#는 배송이 빠르게 이루어지지 않아서 상사에게 동의했습니다.\n",
      "test_202,#Person1#은 #Person2#에게 방의 독서등을 깨뜨렸다고 말합니다. #Person2#는 양식을 작성하라고 요청합니다.\n",
      "test_203,#Person1#은 #Person2#에게 마케팅 계획의 첫 부분으로 시작합니다. #Person2#는 #Person1#에게 2005년과 2006년의 판매 비율을 보여줍니다.\n",
      "test_204,\"#Person2#는 휴가 동안 유럽을 여행하고 싶어합니다. #Person2#는 파리에서 시작해서 밀라노로 가고, 그 다음에는 영국으로 가며 축제에 참석할 예정입니다.\"\n",
      "test_205,#Person2#는 지미 폭스에게 중형 차량이 없다고 말합니다. 지미 폭스는 차량이 없을 수도 있다고 생각합니다. #Person2#는 지미 폭스에게 보험을 제공하고 대여료를 할인해 줄 것이라고 말합니다.\n",
      "test_206,#Person1#은 잠시 카드 게임을 하려고 합니다. #Person1#의 엄마는 #Person1#에게 단지 5분만이라고 요청합니다.\n",
      "test_207,앤이 존스 씨에게 오늘 오후 5시에 회계사와의 회의가 있다고 알려준다. 앤은 또한 폰 씨와의 회의를 잡는다.\n",
      "test_208,\"#Person2#는 #Person1#에게 세계 지도를 보여주고, 세계의 대부분이 물로 덮여 있다고 말한다. #Person1#는 그곳의 화산 활동과 강이 깊은 계곡과 그랜드 캐년을 즐길 수 있다고 말한다.\"\n",
      "test_209,#Person2#는 방을 바꾸고 싶어합니다. #Person1#는 바로 금연 방을 준비해 줄 것입니다.\n",
      "test_210,#Person1#은 빌에게 작업자들이 공지를 가져오러 창고에 가서 젖은 페인트를 두고 가야 한다고 경고합니다.\n",
      "test_211,벤은 엘라에게 전화를 걸어 다음 주에 다시 만나기로 합니다. 엘라는 벤에게 그녀의 전화번호를 남깁니다.\n",
      "test_212,빌이 짐에게 딕이 아파서 이탈리아에서 돌아온 후로 아팠다고 말한다.\n",
      "test_213,\"#Person1#은 #Person2#가 야근을 하고 있다고 생각한다. #Person2#는 최저임금으로 일하고 있지만, #Person2#는 보너스를 받지 못한다. #Person1#은 #Person2#가 다른 일자리를 찾지 못할 것이라고 생각한다.\"\n",
      "test_214,\"마크는 리사에게 그녀의 남편이 그녀를 속이고 있다고 말한다. 리사는 마크에게 마크의 남편이 대략 두 달 동안 다른 사람을 만났다고 말한다. 마크는 처음에는 어리석은 변명을 하려고 했지만, 그런 다음 작은 실수를 인정했다.\"\n",
      "test_215,#Person2#는 #Person1#에게 적색 육류를 줄이고 식단을 정리하라고 조언했습니다.\n",
      "test_216,\"#Person1#은 #Person2#에게 인생을 같이 보낼 것을 부탁하지만, #Person2#는 #Person1#에게 다시는 그를 보지 않을 것이라고 말한다.\"\n",
      "test_217,\"#Person2#는 #Person1#에게 도서관 이용 방법을 알려주고, 책을 대출하는 방법과 기한, 그리고 연장 방법에 대해 설명합니다.\"\n",
      "test_218,\"#Person1#과 #Person2#는 좋은 날씨에 대해 이야기하고, 그들은 점심을 먹기 위해 밖으로 나가기로 결정합니다.\"\n",
      "test_219,#Person1#은 #Person2#에게 사진을 찍을 수 없다고 말합니다. #Person2#는 슬라이드나 그림 엽서를 어디서 살 수 있는지 물어봅니다.\n",
      "test_220,\"#Person2#는 대출 신청에 대한 정보를 얻고 싶어합니다. #Person1#는 #Person2#에게 대출 정책의 일반적인 조건을 설명하고, #Person2#의 신용 점수가 매우 낮다고 말합니다.\"\n",
      "test_221,\"#Person1#은 모니카의 회의에서의 발표에 만족하고 있다. 모니카는 #Person1#에게 그녀가 최선을 다했음을 알리고, 그녀의 동료들과 경제 전문가의 도움을 감사한다.\"\n",
      "test_222,\"톰은 아침에 달리는 것을 좋아하지만, #Person1#은 아침에 달리는 것을 좋아하지 않는다. 그들은 내일 같이 조깅을 가기로 결정한다.\"\n",
      "test_223,#Person2#는 #Person1#에게 일본 레스토랑의 영업 시간과 메뉴를 알려줍니다.\n",
      "test_224,\"#Person1#은 심슨 씨에게 점심 식사를 제안하고, 심슨 씨는 동의합니다.\"\n",
      "test_225,#Person1#은 괜찮다면 그녀와 데이트를 가고 싶어합니다. #Person2#는 그에게 호텔의 레스토랑을 추천합니다. #Person1#은 그에게 네 번째 레스토랑을 추천합니다.\n",
      "test_226,#Person1#은 #Person2#에게 팁을 주지 않을 것이라고 말합니다.\n",
      "test_227,#Person2#는 #Person1#에게 #Person2#의 나라에서 가장 인기 있는 스포츠와 그 이유를 설명합니다.\n",
      "test_228,\"#Person2#는 헬싱키로 가고 싶어하고, #Person1#는 솔트레이크시티에서 뉴욕 케네디 공항으로 가는 1070편 비행기로 헬싱키로 가는 90편 비행기를 추천합니다. #Person2#는 채식주의자 식사를 원합니다.\"\n",
      "test_229,#Person1#은 내일 할머니를 방문할 예정입니다. #Person2#는 할머니가 항상 그곳을 잘 알고 있다고 말합니다.\n",
      "test_230,#Person2#는 호주에 가고 싶어합니다. #Person1#은 그곳의 물고기가 놀랍다고 말해줬다고 합니다.\n",
      "test_231,\"로라는 몸매 관리를 위해 헬스장에 가고, #Person1#은 즐거움과 건강을 위해 헬스장에 가는 편이다.\"\n",
      "test_232,\"#Person2#는 #Person1#에게 로스앤젤레스에서 태어났고, 시카고에서 자랐다고 말합니다. #Person2#는 유럽에 갔고, 뮌헨에 11년 동안 머물렀습니다.\"\n",
      "test_233,\"#Person1#은 #Person2#에게 새로운 정장을 보여주고, #Person2#는 그것이 좋은 거래라고 생각하지 않습니다.\"\n",
      "test_234,#Person1#은 앤에게 산호수 자전거 투어에 대해 설명합니다. 로빈은 투어의 길이와 출발지에 대해 #Person1#에게 알려줍니다.\n",
      "test_235,\"#Person2#는 #Person1#의 도움으로 애퍼티프와 싱거를 주문하고, 싱거를 추천받았습니다.\"\n",
      "test_236,\"에릭과 그레고리는 점심을 먹기로 결정하고, 그들은 서로에게 스포츠에 대해 이야기한다. 그레고리는 에릭에게 번지 점프가 무서워하지 않도록 격려한다.\"\n",
      "test_237,#Person1#은 #Person2#에게 노르망디 상륙작전에 대한 정보를 찾고 싶다고 말합니다. #Person2#는 #Person1#에게 역사 책을 읽는 것을 제안합니다.\n",
      "test_238,\"#Person1#은 #Person2#에게 기계를 사용하는 방법을 가르치고, 무게를 줄이고 스트레칭을 하는 것을 제안합니다.\"\n",
      "test_239,#Person1#은 캠퍼스 내에 주차할 공간이 필요합니다. #Person2#는 학생들을 위한 주차 구조물을 소개합니다.\n",
      "test_240,\"에밀리는 수잔에게 미국에서 받는 첫 번째 급여에 대해 몇 가지 질문을 하고, 수잔은 에밀리에게 공제에 대해 설명한다. 에밀리는 수잔에게 영국에서도 똑같다고 말한다.\"\n",
      "test_241,#Person1#은 간식을 사고 싶어합니다. #Person2#는 #Person1#에게 돈을 어떻게 넣어야 하는지 가르칩니다.\n",
      "test_242,#Person2#는 #Person1#에게 태국에 여자친구를 만나러 가려고 한다고 말한다. #Person2#는 #Person1#에게 그녀를 만나는 것이 이번이 처음이라고 말한다.\n",
      "test_243,\"제임스는 케이트의 가구를 칭찬하고, 케이트는 제임스의 가구를 칭찬한다. 그들은 가구에 대해 이야기한다.\"\n",
      "test_244,#Person2#는 빌에게 하루 운동 스케줄을 알려준다.\n",
      "test_245,마르켓은 #Person1#에게 과학 과목을 수강해야 한다고 말합니다. #Person1#은 지도학이 약하다고 생각합니다.\n",
      "test_246,\"팀은 #Person1#에게 자신의 친환경적인 삶에 대해 이야기한다. 그는 #Person1#에게 자신의 가족들도 관심이 있을 것이라고 알고 있었기 때문에, 그는 항상 차로 학교에 다녔다. 그는 학교에서 모든 학교 종이를 재활용하고 대부분의 친구들이 종이 양면을 사용하고 있다는 것을 알게 되었다. 그는 학교가 고기 없는 월요일을 시행하고 있다는 것을 읽었고, 그들은 우유, 물, 주스가 든 병을 판매한다.\"\n",
      "test_247,#Person1#은 토니에게 크리스마스가 다가오고 있다고 말한다. #Person1#은 쇼핑 센터의 장난감 부서에서 일하고 있기 때문에 늦게 일어나서 10분 늦게 출근한다.\n",
      "test_248,\"빌은 수에게 케이크를 가져다 달라고 요청하지만, 수는 수프를 원합니다. 수는 샐러드를 가져다 줄 것입니다. 그들은 식당에 가기로 결정합니다.\"\n",
      "test_249,\"#Person2#는 여름 옷을 찾고 있고, #Person1#는 #Person2#에게 20% 할인 중인 모든 여름 의류에 대해 알려줍니다.\"\n",
      "test_250,\"#Person1#은 예약 확인서를 가지고 있지만, #Person2#는 #Person1#에게 재확인하지 않는 모든 예약은 취소된다고 말합니다.\"\n",
      "test_251,\"이준은 #Person2#의 가족이 모두 여기에 있고, 그들은 점심을 먹는다.\"\n",
      "test_252,\"#Person1#은 토니가 매일 상처 주는 말을 하는 것을 걱정하고 있습니다. #Person2#는 #Person1#에게 토니에게 인내심, 애정, 존중을 가지고 대해주고, 그를 안내하거나 도와주는 것을 제안합니다.\"\n",
      "test_253,#Person1#은 #Person2#에게 자기 친구의 친구인 알렉스와 그의 베스트맨이 파티를 준비하고 있다고 말한다. #Person1#은 #Person2#에게 스트립 클럽에 가지 않을 것을 권한다. #Person2#는 결혼한 후에도 #Person1#의 파티에 가는 것을 허락하지 않는다.\n",
      "test_254,#Person2#는 투표용지를 어떻게 받아야 하는지 모른다. #Person1#은 #Person2#에게 투표 부스로 가서 투표하라고 조언한다.\n",
      "test_255,\"#Person1#은 회사가 인력을 줄일 것이라는 소식을 들었고, #Person2#는 조지, 앤디, 리사, 마이클, 나일이 해고될 것 같다고 생각한다. #Person1#은 걱정하고 있다.\"\n",
      "test_256,#Person1#과 #Person2#는 중국에서의 결혼 및 이혼에 대해 이야기하고 있다. 그들은 서로의 시점을 공유하고 있다.\n",
      "test_257,\"주디는 #Person1#에게 여행 일정에 따르면 13,000 RMB 이상의 돈을 쓸 것이라고 말한다. 주디는 #Person1#에게 유스호스텔을 선택하라고 제안한다.\"\n",
      "test_258,#Person1#은 #Person2#에게 메리가 파리에서 결혼했다고 말한다.\n",
      "test_259,\"#Person2#는 지갑을 잃어버렸다. #Person1#는 #Person2#에게 도움을 청하고, #Person2#는 #Person1#에게 돈을 빌려주기로 약속했다.\"\n",
      "test_260,#Person1#은 #Person2#에게 머피 뮤직과 U-튠즈가 합병한다고 말합니다. #Person2#는 그것이 의심스럽다고 생각합니다.\n",
      "test_261,#Person1#은 새로운 비서가 도움이 되는지 톰에게 물어봤다. 톰은 그녀가 도움이 되는지 걱정한다.\n",
      "test_262,\"사라는 회의에서 자신의 제안을 받아들일 수 없었고, 회의가 효율적이지 않았다고 생각합니다. #Person1#은 그녀에게 회의 중에 중요한 포인트를 제기하고, 회의 후에 직접 관련된 사람들과 이야기하라고 조언합니다.\"\n",
      "test_263,\"#Person2#는 #Person1#에게 이슬람에 대한 프로그램을 소개하고, 무슬림들이 하즈를 가는 이유와 순례자들이 하는 일에 대해 설명한다. #Person1#는 프랑스에도 치유를 받으러 가는 곳이 있다고 생각한다.\"\n",
      "test_264,\"테드는 마이크에게 제니에게 반했지만 그녀에게 말하지 않고, 그녀에게 말하지 않는다면 죽을 것이라고 말한다. 마이크는 테드에게 용기를 내고 말하라고 조언한다.\"\n",
      "test_265,#Person2#는 화가 날 때 먼저 진정하고 화를 일으킨 원인에 대해 생각합니다. #Person2#는 똑똑한 방법이라고 생각합니다.\n",
      "test_266,#Person1#은 #Person2#에게 #Person1#의 가족에 대해 묻습니다. #Person2#는 #Person1#에게 #Person2#의 삼촌 빌의 가족 구성원에 대해 설명합니다.\n",
      "test_267,스튜어트 씨가 #Person1#에게 마라톤에서 우승했다고 말합니다. #Person1#은 그가 흥분되고 행복했다고 말합니다.\n",
      "test_268,\"#Person2#는 아이들과 아내를 위한 선물을 고르고 있습니다. #Person1#는 #Person2#에게 운동화를 추천하고, #Person2#는 아내를 위한 향수를 사기로 결정합니다.\"\n",
      "test_269,#Person1#은 영국에 전화를 걸고 싶지만 로밍 요금을 감당할 수 없다. 홍은 #Person1#에게 SIM 카드를 사용하는 것을 제안한다.\n",
      "test_270,\"#Person2#는 #Person1#에게 월급이 1,800 위안이라고 말합니다. #Person2#는 #Person1#에게 처음에는 한 달에 2,500 위안을 지급할 것이라고 말합니다.\"\n",
      "test_271,\"#Person1#과 #Person2#는 서로의 성격에 대해 이야기하고 있다. #Person1#은 새로운 사람들과 이야기하는 것을 좋아하고, #Person2#는 새로운 사람들과 이야기하는 것을 싫어한다.\"\n",
      "test_272,#Person1#은 파사디나나 아카디아에 있는 전망이 있는 집을 사고 싶어합니다. #Person2#는 #Person1#에게 집을 찾아볼 것입니다.\n",
      "test_273,그랜트 씨는 #Person2#에게 샘플들을 여기에 남겨두고 가는 것을 제안하고 다음 주에 연락할 것입니다.\n",
      "test_274,#Person2#는 #Person1#에게 PHS에서 Sons까지 가는 버스를 어떻게 타야 하는지 알려줍니다.\n",
      "test_275,\"#Person1#은 집까지 태워드는 것을 돕고, #Person2#에게 우산을 꺼내는 것을 도와줍니다.\"\n",
      "test_276,#Person1#은 #Person2#에게 엑스레이를 찍고 싶어합니다. #Person1#은 #Person2#가 아픈 곳이 없다고 생각합니다. #Person1#은 #Person2#에게 하룻밤 병원에 가라고 제안합니다.\n",
      "test_277,\"#Person2#는 신용 카드를 잃어버렸다고 알려주고, #Person1#는 #Person2#에게 FRCM 일부 세부 사항을 받아서 도와줄 것입니다.\"\n",
      "test_278,#Person1#은 잠을 자고 싶지만 #Person2#는 깨울 수도 있다. #Person2#는 #Person1#에게 깨울 때까지 잠을 자라고 요청한다.\n",
      "test_279,\"#Person2#는 중국 음식을 먹고 싶어하고, #Person1#은 #Person2#에게 두유 한 잔과 고추장을 주문하는 것을 도와줍니다.\"\n",
      "test_280,\"#Person1#과 #Person2#는 식사를 하고 있습니다. 그들은 크림 케이크를 좋아하지 않지만, #Person1#은 그것을 좋아합니다.\"\n",
      "test_281,\"#Person1#은 루시에게 스탠리가 왔다고 말하고, 그가 노래하는 것을 듣고 싶어한다고 말한다.\"\n",
      "test_282,#Person2#는 영화관이 단지 영화를 보는 곳이 아니라 사람들을 만나는 곳이어야 한다고 생각합니다.\n",
      "test_283,\"#Person1#은 #Person2#에게 갈색 드레스를 추천하지만, #Person2#는 흰색을 선호합니다.\"\n",
      "test_284,조슈아는 #Person2#에게 13달러를 빚고 있다고 말한다. #Person2#는 은행이 문 닫았다고 생각한다. 조슈아는 #Person2#에게 돈을 좀 줄 수 있는 곳을 찾는 것을 제안한다.\n",
      "test_285,\"#Person2#는 내일 마이크의 생일 파티에 초대받았고, #Person1#은 #Person2#에게 차로 가자고 제안했다.\"\n",
      "test_286,#Person1#은 소포를 우등 우편으로 보내고 싶어합니다. #Person2#는 #Person1#에게 보험과 우표를 구매하는 방법을 알려줍니다.\n",
      "test_287,#Person1#과 #Person2#는 태풍과 지진에 대해 이야기하고 있습니다. #Person2#는 태풍이 지진보다 심하지 않다고 생각합니다. #Person1#은 태풍이 지진보다 심지 않다고 생각합니다. #Person2#는 태풍이 지진보다 심지 않다고 말합니다.\n",
      "test_288,#Person1#은 날씨가 고약하다고 생각합니다. #Person2#는 날씨가 익숙하다고 말합니다.\n",
      "test_289,\"#Person1#과 #Person2#는 배구 경기 후에 올림픽 기념품 가게에 가서 둘러보고, #Person1#은 빨간색 올림픽 마스코트를 사고 싶어합니다.\"\n",
      "test_290,#Person1#은 음식을 많이 요리하기 때문에 #Person2#의 도움으로 양이 많은 음식을 요리하는 알루미늄 팬을 구입합니다.\n",
      "test_291,#Person1#과 #Person2#는 퇴근 후에 뵐 예정입니다.\n",
      "test_292,\"#Person1#은 베커 씨에게 사무실이 아름답고 편안하며, 일이 흥미롭다고 말합니다. 베커 씨는 직급이 높지만, 노동자들의 기준에서는 높지 않다고 말합니다.\"\n",
      "test_293,\"피트는 헨리 존슨을 만나러 왔고, 피트는 브루클린 출신의 외국인 피트에게 뉴욕에서의 생활에 대해 묻습니다. 피트는 노래방에 가고 싶지만, 헨리는 노래방이 싫다고 생각합니다. 그들은 저녁 식사를 하고 바로 내려가기로 결정합니다.\"\n",
      "test_294,\"줄리는 식중독이라고 생각하는 것으로 의사에게 갔습니다. 그녀는 점심을 먹은 다른 사람들과 다르게, 그녀는 몸이 아프었습니다.\"\n",
      "test_295,\"#Person1#은 친구들이 오고 있고, 마이크는 #Person1#에게 커피를 내는 것을 도와줄 것이라고 말한다. 마이크는 과일을 사올 예정이다.\"\n",
      "test_296,\"#Person1#은 베를린에 도착했고, #Person2#는 런던에서 60유로에 버스로 왔습니다. #Person2#는 버스가 불편하다고 생각합니다. #Person1#은 #Person2#가 건강을 더 신경 써야 한다고 제안합니다.\"\n",
      "test_297,\"#Person1#은 #Person2#에게 일에 대해 묻고, #Person2#는 직업이 흥미로워서 일하고 싶다고 말합니다.\"\n",
      "test_298,\"지미는 에이미에게 어제 저녁에 제니와 빌이 그녀를 소풍에 초대해서 집에 늦게 왔다고 말한다. 그들은 베이하이 공원에서 점심을 먹고, 강가를 따라 산책하고, 친구들을 사귀고, 차를 몰고 집에 가기 시작했다.\"\n",
      "test_299,\"피터는 차 한잔을 하고 싶지만, 먼저 정원에 물을 줘야 합니다. #Person1#은 피터에게 정원을 깨끗이 하라고 요청합니다.\"\n",
      "test_300,\"#Person1#은 켄에게 문제에 대해 회의를 소집하라고 요청하고, 켄에게 진행하라고 요청합니다.\"\n",
      "test_301,\"#Person2#는 등기로 편지를 보내고 싶어하고, #Person1#는 #Person2#에게 등기와 당일 배송을 합치면 총 7달러라고 알려준다.\"\n",
      "test_302,스미스 씨가 감염이 심해서 약을 처방받기 위해 #Person1#에게 찾아갑니다.\n",
      "test_303,\"#Person2#는 중국 특유의 솜씨로 유명한 중국 가게에서 중국 특유의 상품을 사고 싶어합니다. #Person1#은 #Person2#에게 종이절편, 자수, 바틱을 추천합니다.\"\n",
      "test_304,#Person1#은 #Person2#에게 에펠탑의 역사와 설계자에 대해 설명합니다.\n",
      "test_305,\"브라이언은 대학에서 영어를 배웠고, 미국에서 3주 동안 영어를 공부했습니다.\"\n",
      "test_306,#Person1#은 #Person2#에게 그가 돌아오지 않았다고 말합니다. #Person2#는 그가 이미 성인이고 챙길 수 있을 것이라고 생각합니다.\n",
      "test_307,#Person1#은 #Person2#에게 계획에 따라 일을 하는 것이 문제가 없다고 말한다. #Person2#는 그것이 쉽게 진행되었기 때문에 걱정한다.\n",
      "test_308,#Person1#과 #Person2#는 존이 일주일에 일곱 번 그녀와 데이트를 한다는 사실에 동의한다.\n",
      "test_309,\"#Person1#과 #Person2#는 런던의 역사적 장소에 대해 이야기합니다. 그들은 웨스트민스터 대성당, 템즈 강변, 템즈 강변, 그리고 마담 투소의 밀랍 인형 박물관을 방문할 예정입니다.\"\n",
      "test_310,\"다니엘은 과학이 가장 좋아하고, #Person2#는 체육이 가장 좋아한다. 다니엘은 과학에 관심이 있어서 과학이 놀랍다고 생각한다.\"\n",
      "test_311,\"#Person1#은 #Person2#에게 베이비 샤워를 준비해준다. #Person1#은 베이비 샤워에 참석하고, #Person2#는 #Person1#에게 선물을 준다. #Person1#은 #Person2#에게 아기가 언제 태어날지 맞춰볼 사람이라고 말한다.\"\n",
      "test_312,\"#Person1#은 중국에 관광하러 가고 싶어하지만, #Person2#는 바쁘다.\"\n",
      "test_313,팀이 카렌에게 늦은 것에 대해 사과하고 다시 만날 것을 약속한다.\n",
      "test_314,#Person2#는 #Person1#에게 오토바이를 막 샀다고 말합니다. #Person2#는 자전거를 사고 싶어합니다.\n",
      "test_315,\"#Person2#는 영어와 프랑스어를 할 수 있으며, 영어를 읽고 쓰는 것보다 말하는 것에 더 관심이 있습니다. #Person2#는 영어 실력이 사무 업무를 수행하는 데 충분하다고 생각합니다.\"\n",
      "test_316,낸시가 나오미씨에게 전화를 걸어 그녀의 여동생인 나오미씨에게 메시지를 전달해줄 예정입니다.\n",
      "test_317,\"#Person1#은 뉴욕행 비행기가 취소되었다고 들었지만, #Person2#는 #Person1#에게 다른 항공사로 예약하라고 합니다.\"\n",
      "test_318,\"#Person1#은 버거퀸에 가자고 제안하고, #Person2#는 그것이 매력적으로 들리지만, 너무 많은 튀김 음식은 나를 살찌게 해서 거절한다.\"\n",
      "test_319,\"#Person1#은 #Person2#에게 짐이 8킬로그램을 초과했다고 알려주고, 이를 해결하기 위해 취약한 물품 표시를 달아주는 것을 요청합니다.\"\n",
      "test_320,#Person1#은 목이 말라서 #Person2#에게 물을 마시고 싶어합니다. #Person2#는 #Person1#에게 물을 마시고 탈수 상태일 때는 물을 마셔야 한다고 말합니다.\n",
      "test_321,#Person2#는 AB 회사의 왕 묘에게 그린 씨가 량 씨에게 사과를 전하고 싶어합니다. #Person1#은 그것을 전해줄 것입니다.\n",
      "test_322,\"#Person1#은 유광 가죽 신발을 원하고, #Person2#는 상관없다고 말합니다.\"\n",
      "test_323,\"벤자민은 프로젝트 보고서를 어떻게 써야 하는지 모른다. #Person1#은 벤자민에게 올해의 작업에 대한 최종 결론과 내년 계획에 대한 세부 사항을 포함하는 방법을 가르치고, 또한 벤자민에게 마이크로소프트 워드를 어떻게 사용하는지 가르치는다.\"\n",
      "test_324,\"#Person2#는 피자를 주문하고, #Person1#는 #Person2#에게 대형 피자를 두 개 주문하도록 권장합니다. #Person2#는 또한 해산물 피자와 도우를 얇게 만들어주고, 주소를 알려줍니다.\"\n",
      "test_325,\"#Person1#은 #Person2#의 도움으로 새우 칵테일, 토마토 수프, 양파 스테이크, 그리고 블랙 커피를 주문했습니다.\"\n",
      "test_326,#Person1#은 #Person2#에게 집의 장점을 소개합니다.\n",
      "test_327,#Person2#는 보여준 긁힌 핸드폰이 다른 사람들이 들을 수 있다고 주장합니다. #Person1#는 다른 모델로 교환해 줄 수 있을 것이라고 말합니다.\n",
      "test_328,\"#Person1#은 내년 기숙사 보증금을 내는 데 한 시간이나 걸렸고, 내년 9월에 기숙사방을 원한다면 서둘러야 한다. #Person2#는 캠퍼스 밖에서 살 계획이고, #Person1#은 도서관에서 공부하면 더 좋아질 수도 있다고 생각한다.\"\n",
      "test_329,#Person1#은 중고 서점을 둘러보고 #Person2#에게서 흥미로운 책을 찾습니다. #Person1#은 셰익스피어의 서명이 있는 책을 사고 싶어합니다. #Person2#는 #Person1#에게 75센트짜리 이야기가 더 나은 구매를 권합니다.\n",
      "test_330,\"#Person2#는 베이징 맛있는 레스토랑에 오고 있습니다. #Person1#는 #Person2#에게 중앙에 있는 테이블을 제공하고, #Person2#는 친구를 기다리는 동안 시간이 필요합니다.\"\n",
      "test_331,#Person1#은 #Person2#에게 아들이 받는 편지를 공인 우편으로 보내달라고 요청합니다.\n",
      "test_332,샐리는 #Person1#에게 톰이 보낸 편지를 읽어달라고 요청합니다. 톰은 샐리에게 1월에 도시에 올 예정이라고 알려줍니다.\n",
      "test_333,#Person1#은 과제를 해야 하는데 컴퓨터가 없다. #Person2#는 #Person1#이 스스로 컴퓨터를 구입할 수 있는 날을 기대하고 있다.\n",
      "test_334,\"#Person1#과 #Person2#는 날씨가 좋다고 생각합니다. #Person2#는 소풍을 제안하지만, #Person1#은 비가 올 것 같다고 말합니다.\"\n",
      "test_335,#Person1#은 참고자료실에서 컴퓨터에 대한 일반적인 정보를 찾고 있습니다. #Person2#는 #Person1#에게 어떻게 찾는지 보여줄 것입니다.\n",
      "test_336,\"#Person2#는 프렌치 가든 레스토랑에 왔습니다. #Person3#는 #Person2#에게 웨이트리스에게 주문을 요청하고, #Person2#는 샌드위치와 야채 수프를 주문합니다.\"\n",
      "test_337,\"#Person1#은 #Person2#에게 레모네이드, 바비큐 윙, 그리고 베이비 백 립을 주문하는 데 도움을 줍니다.\"\n",
      "test_338,#Person2#는 커피를 원하고 나중에 디저트를 주문할 예정입니다.\n",
      "test_339,#Person1#과 #Person2#는 로또에 당첨된다면 어떻게 할지에 대해 이야기하고 있다.\n",
      "test_340,\"#Person1#은 새로 태어난 아기의 사진을 잭에게 보여주고, 그가 재미있다고 말한다.\"\n",
      "test_341,#Person1#은 엄마에게 #Person1#의 엄마의 자전거가 훨씬 더 좋다고 말한다. #Person1#은 #Person1#의 엄마에게 큰 차를 사줄 것이라고 약속한다.\n",
      "test_342,\"#Person2#는 #Person1#의 추천에 따라 치마를 입어보고, 그것이 #Person2#의 피부톤에 잘 맞는다고 생각합니다.\"\n",
      "test_343,\"#Person2#는 #Person1#에게 #Person2#의 도시가 200년 전만 해도 그저 보잘것없는 작은 마을이었다고 말합니다. #Person2#는 #Person1#에게 #Person2#의 도시에 200년 이상 된 건물이 있고, 그 중 많은 건물들은 여행자들을 위한 여관이었다고 말합니다.\"\n",
      "test_344,\"#Person1#과 #Person2#는 환경 문제에 대해 이야기합니다. 그들은 환경 문제가 세계를 파괴할 수 있다고 생각하지만, 그들은 또한 환경 보호에 헌신하는 조직에 가입하는 것에 동의합니다.\"\n",
      "test_345,\"데니스는 온라인에서 많은 사람들과 이야기하고 있고, 새로운 온라인 친구를 만났습니다. #Person2#는 데니스에게 좋은 의사를 찾아보라고 조언합니다.\"\n",
      "test_346,\"#Person1#은 네이선에게 시카고에서의 연습 계획을 묻고, 네이선은 #Person1#에게 자신이 어떻게 할지 걱정하지 않을 것이라고 말한다. #Person1#은 네이선에게 직장에서의 훈련을 받을 수 있을 것이라고 말한다.\"\n",
      "test_347,\"#Person2#는 토요타 캐롤라를 3일 동안 빌리고 싶어합니다. #Person1#는 #Person2#에게 차를 렌트하는 방법을 알려주고, 신청서를 작성하라고 요청합니다.\"\n",
      "test_348,\"#Person1#은 다음 주에 뉴욕에 가서 사업 계약을 체결할 예정입니다. #Person2#는 #Person1#에게 뉴욕의 대학교, 컬럼비아 대학교, 그리고 도시의 지도를 보여주고, 관광 정보를 제공해 줄 것이라고 말합니다.\"\n",
      "test_349,#Person1#은 #Person2#에게 필름을 현상해 달라고 요청합니다.\n",
      "test_350,\"#Person1#은 비행기가 지연되었다는 안내를 들었습니다. #Person2#는 #Person1#에게 비행기가 폭우 때문이라고 설명하고, 최근 비행 안내 방송을 꼭 들어보라고 권합니다.\"\n",
      "test_351,\"#Person1#은 베이징 대학교로 가는 길을 #Person2#에게 물어보고, #Person2#는 경찰관에게 물어보라고 제안합니다.\"\n",
      "test_352,#Person2#는 #Person1#에게 신문에 나와 있는 것에 대해 이야기합니다. #Person2#는 #Person1#에게 일기 예보와 스포츠 섹션에 대해 알려줍니다.\n",
      "test_353,\"#Person1#은 컴퓨터 게임이 너무 폭력적이라고 생각하지만, #Person2#는 그렇지 않다고 생각한다.\"\n",
      "test_354,\"짐은 #Person1#에게 맥주를 마시는 것이 건강에 좋지 않다고 말한다. 그들은 노래를 부르고 친구들을 만나는 것을 제안한다. 그들은 운동장에 가서 4인조를 만들고, 그 후에 춤을 추는 것을 제안한다.\"\n",
      "test_355,#Person1#과 #Person2#는 맥주나 와인을 마시고 하우스 레드 한 병을 주문할 예정입니다.\n",
      "test_356,\"#Person2#는 #Person1#에게 안내 경험이 있지만, 경험이 많지 않다고 말합니다.\"\n",
      "test_357,잭이 #Person1#의 도움으로 더블룸을 예약했다.\n",
      "test_358,마크는 질에게 전화를 걸어서 아버지의 생일 파티에 참석하지 못한 이유를 설명한다. 질은 마크에게 아버지의 아내와 딸이 잘 지내고 있다고 알려준다.\n",
      "test_359,\"#Person1#은 내일 밤에 #Person2#를 초대하지만, #Person2#는 차라리 안하는 것을 선호합니다.\"\n",
      "test_360,\"#Person2#는 #Person1#에게 캘리포니아가 홈런을 쳤고, 볼티모어가 이기고 있다고 말합니다. #Person1#는 야구가 미국인들의 가장 좋아하는 여가활동이라고 생각합니다.\"\n",
      "test_361,#Person1#은 #Person2#를 위해 돕고 싶어합니다. #Person2#는 #Person1#에게 감사의 말을 전합니다.\n",
      "test_362,#Person2#는 #Person1#에게 #Person2#의 나라에서 수출하고 수입하는 자원에 대해 이야기합니다. #Person2#는 #Person1#에게 #Person2#의 나라에서 최근에 발견된 매장량에 대해 이야기합니다.\n",
      "test_363,\"#Person1#은 예술 전시회를 좋아하고, #Person2#는 조각을 좋아합니다. 그들은 예술 전시회에 가기로 결정하고, 그들은 12시 30분에 만날 예정입니다.\"\n",
      "test_364,#Person2#는 #Person1#에게 책을 반납하고 비디오를 대출하고 싶어합니다. #Person2#는 비디오를 잘 관리할 예정입니다.\n",
      "test_365,\"#Person1#은 #Person2#에게 볼링에 대해 설명하고, 각 선수는 두 번의 볼링을 할 수 있다고 말합니다.\"\n",
      "test_366,#Person2#는 은행과 증권사 간의 새로운 서비스에 대해 #Person1#에게 전화를 합니다. #Person1#는 #Person2#에게 전화로 상담 서비스를 이용하거나 인터넷을 통해 서비스를 이용할 수 있다고 말합니다.\n",
      "test_367,\"#Person1#은 #Person2#에게 짐을 보관할 공간을 제공하고, #Person2#는 보증금이 있는지 물어봅니다.\"\n",
      "test_368,#Person2#는 파티에 세 명이 올 예정입니다. #Person1#은 #Person2#에게 음식과 뷔페에 대해 알려줍니다.\n",
      "test_369,\"#Person2#는 해외에서 공부할 예정이고, #Person1#는 #Person2#에게 해외유학 대출에 대해 설명합니다.\"\n",
      "test_370,#Person1#은 영어 노래를 찾고 싶어합니다. #Person2#는 책을 찾는 데 몇 분 더 걸릴 것이라고 말합니다.\n",
      "test_371,#Person2#는 #Person1#에게 자신의 글쓰기 경험과 신문사에서 이 직무에 관심을 가진 이유를 설명합니다.\n",
      "test_372,#Person1#과 잭은 면접 결과에 대해 이야기하고 있다. 그들은 면접 결과에 대해 걱정하고 있다.\n",
      "test_373,\"#Person2#는 #Person1#에게 집을 보여주고, 그들이 옥수수 이삭을 깎는 것을 보여줍니다.\"\n",
      "test_374,\"#Person1#은 호텔에서 체크아웃하고 싶어합니다. #Person2#는 #Person1#에게 체크아웃 시간을 알려주고, #Person1#은 수하물에 대해 묻습니다.\"\n",
      "test_375,\"브랜든이 웹사이트를 가입하려고 하고 #Person1#에게 무료라고 말하지만, #Person1#은 브랜든이 속임수를 하고 있다고 생각합니다.\"\n",
      "test_376,#Person1#과 #Person2#는 새로운 실험실 건물이 필요하다고 생각합니다. 그들은 교장이 돈을 모으는 것을 제안합니다.\n",
      "test_377,\"케이트는 은행에서 준 신용카드를 가지고 다니게 된 것이 기쁘고, 헨리는 카드를 사용하도록 장려하는 은행이 돈을 갚도록 요구할 것이라고 말합니다.\"\n",
      "test_378,\"#Person1#은 스미스씨에게 내일의 계획을 알려주고, 스미스씨는 산악 지역의 마을을 방문하는 것이 좋을 것 같다고 말합니다.\"\n",
      "test_379,\"#Person1#은 스트레스와 우울증을 다루는 데 사용하는 방법에 대해 빈다. 벳은 아기를 가지게 되면서 목표나 꿈을 이루는 데 방해가 된 적이 있다. 그는 아기를 사랑하고, 아기를 위해 유타를 떠나고 싶어하고, 춤과 노래를 계속하고 싶어한다.\"\n",
      "test_380,#Person2#는 #Person1#에게 우표 수집에 관심을 가지게 되었을 때 어떻게 시작했는지 설명합니다.\n",
      "test_381,톰은 #Person1#에게 자신만의 회사를 가지고 싶다는 것을 알게 된 경험과 현재 회사를 위한 자금의 구체적인 방법에 대해 이야기합니다.\n",
      "test_382,\"#Person1#은 #Person2#에게 니스든의 보행자 지하도에서 발견된 40대 남자의 죽음을 살인으로 다루고 있다고 말합니다. #Person2#는 #Person1#에게 그가 술집을 떠난 시간, 술집의 위치, 그리고 다른 사람들과의 관계에 대해 설명합니다.\"\n",
      "test_383,셰리는 밥에게 퀘벡 시를 방문할 예정이라고 말한다. 밥은 프랑스어와 영어를 모두 사용할 수 있다고 말한다. 밥은 퀘벡 시를 방문할 예정이지만 대학 친구가 거기에 살고 있다.\n",
      "test_384,\"톰은 제인에게 수영하러 가자고 제안하지만, 제인은 논문을 마무리해야 합니다. 그들은 톰의 집에서 저녁 식사를 하기로 결정하고, 그들은 함께 시간을 보내기로 합니다.\"\n",
      "test_385,\"#Person1#은 약이 더 좋아져야 한다고 생각하지만, #Person2#는 약을 세 번 복용해야 한다고 말합니다.\"\n",
      "test_386,\"#Person1#은 휴대폰이 망가졌고, 프레드는 #Person1#에게 돈을 빌려주는 것을 제안한다.\"\n",
      "test_387,#Person1#은 글씨를 개선하고 싶어합니다. #Person2#는 #Person1#에게 인내심을 가져야 한다고 말합니다.\n",
      "test_388,\"#Person2#는 속눈썹을 집고 있고, #Person1#는 #Person2#가 겁쟁이라고 생각한다.\"\n",
      "test_389,\"#Person2#는 주말에만 시간이 있는 운전 수업에 관심이 있습니다. #Person1#는 #Person2#에게 수업의 시간과 장소, 코치, 그리고 연수 기회에 대해 설명합니다.\"\n",
      "test_390,티나는 #Person1#에게 8년 동안 피아노를 배웠다고 말합니다. 그녀의 선생님은 영국 출신입니다. #Person1#은 소개를 받고 싶어합니다.\n",
      "test_391,\"#Person2#는 #Person1#에게 #Person2#의 장점과 약점, 5년 후의 계획 등에 대해 이야기합니다. #Person1#는 #Person2#가 잘 맞는 사람일지도 모른다고 생각합니다.\"\n",
      "test_392,스테파니는 머리가 아파서 의사에게 가야 합니다. 조지는 그녀에게 금요일 아침에 보고서를 제출하도록 돕는다.\n",
      "test_393,\"#Person1#은 데이비드에게 호수에 얼음이 얹혀 있고, 많은 사람들이 스케이트를 타고 있다고 말한다. #Person1#은 데이비드에게 크리스마스를 보내기 위해 도시로 돌아가라고 제안한다.\"\n",
      "test_394,밥은 지난 주말에 친구를 만나러 갔다가 댄스 파티에 갔다고 #Person1#에게 말한다.\n",
      "test_395,#Person1#은 일자리가 없지만 #Person2#에게 50달러를 빌려주고 싶어한다. #Person2#는 결국 동의한다.\n",
      "test_396,\"#Person2#는 식당에서 재킷과 넥타이를 빌릴 수 없다고 #Person1#에게 말합니다. #Person2#는 회의를 미루기로 결정하고, #Person1#는 회의에 참석하는 사람들을 위한 좀 더 빠른 시간을 요청합니다.\"\n",
      "test_397,#Person2#는 #Person1#에게 아이들이 휴가 캠프를 즐겼거나 불평한지에 대해 이야기합니다. #Person2#는 아이들이 혼자 떠나보는 경험이 없어서 어린 아이들 중 일부는 불행해했습니다. 하지만 곧 회복했습니다.\n",
      "test_398,#Person1#은 아빠가 대학 입학 요건에 대해 많은 질문을 하셨다고 생각합니다. #Person1#은 #Person1#의 컴퓨터 전공으로 가족 사업을 시작할 계획입니다.\n",
      "test_399,칼리나는 차를 나무에 박아서 학교를 쉬게 되었습니다. #Person2#는 그녀에게 수업에 오지 않을 것이라고 알려줍니다.\n",
      "test_400,\"#Person2#는 집주인과 수리 비용에 대해 합의를 이루지 못하고 있습니다. #Person2#는 집주인에게 불평하고 있던 고장난 세탁기를 고치게 했지만, 집주인은 그것을 거부했습니다.\"\n",
      "test_401,\"#Person2#는 터너 인테리어에서 왔고, #Person1#은 #Person2#에게 L / C를 수령하는 방법을 알려줍니다.\"\n",
      "test_402,미르달이 핫도그를 사러 가는 길에 지갑을 잃어버렸다. 찰리는 그녀에게 지갑을 찾으러 가자고 제안한다.\n",
      "test_403,#Person1#은 #Person2#에게 설거지를 잘 하라고 요청합니다.\n",
      "test_404,\"#Person1#은 #Person2#를 사랑하고 있지만, #Person2#는 #Person1#을 사랑하지 않는다. 그들은 서로를 웃고 있다.\"\n",
      "test_405,#Person1#과 #Person2#는 실업이 사회 문제를 일으키는 것을 지적합니다.\n",
      "test_406,#Person1#은 #Person2#에게 국가 테마의 파티에 참석하기 위한 복장을 구하기 위해 #Person2#를 초대합니다. #Person2#는 #Person1#에게 쇼핑을 도와줄 것을 약속합니다.\n",
      "test_407,#Person2#는 베이징의 야간 생활이 흥미롭다고 생각합니다. #Person2#는 춤추러 가고 밴드를 즐기는 것을 추천합니다. #Person1#는 디스코 댄스를 좋아합니다. #Person2#는 #Person1#에게 왈츠를 가르쳐줍니다.\n",
      "test_408,\"#Person1#은 농장을 가지고 싶어하고, #Person2#는 그것이 힘든 일이라고 생각한다. #Person1#은 농부가 되기 전에 많은 훈련이 필요할 것이라고 생각한다. #Person2#는 #Person1#을 찾아갈 것이다.\"\n",
      "test_409,\"#Person1#은 탭에 하이네켄과 버드와이저가 있고, 나초와 모짜렐라 스틱을 주문했다.\"\n",
      "test_410,메리는 앤과의 큰 싸움으로 인해 끔찍한 상황에 처해 있다. #Person1#은 그녀에게 우정을 신중하게 보아야 한다고 조언한다.\n",
      "test_411,#Person2#는 #Person1#에게 담배와 기념품을 구입할 수 있는 장소를 알려준다.\n",
      "test_412,\"#Person1#은 미국의 패스트푸드 네이션에 대해 톰에게 이야기합니다. 톰은 미국인들이 미국의 패스트푸드 네이션이라는 이름을 받을 만큼, 사람들은 미국 곳곳에서 맥도날드, KFC, 피자헛을 찾을 수 있다고 말합니다.\"\n",
      "test_413,\"#Person1#은 #Person2#에게 탑승을 허용하고, #Person2#가 워싱턴 스퀘어 파크로 가는 버스를 놓칠 수도 있다고 말합니다.\"\n",
      "test_414,#Person1#과 #Person2#는 9/11 테러 공격 당시에 어디에 있었는지에 대해 이야기합니다.\n",
      "test_415,\"칼과 척은 이웃이 되는 것을 축하합니다. 칼은 시카고 출신이고, 척은 미네소타 출신입니다.\"\n",
      "test_416,#Person2#는 #Person1#에게 계란을 완전히 삶고 진한 토스트를 주문합니다.\n",
      "test_417,#Person1#은 피곤해서 침대에 들어갈 것입니다. 스티븐은 벌써 10시이지만 아직 졸리지 않아서 잠을 자고 싶어합니다.\n",
      "test_418,\"#Person1#은 제인에게 회의 전에 만나자고 제안하고, 제인은 동의한다.\"\n",
      "test_419,#Person2#는 여자친구에게 선물을 고르고 싶어합니다. #Person1#는 그녀에게 진주 귀걸이 세트나 팔찌를 선물하는 것을 제안합니다. #Person2#는 결국 #Person1#의 제안에 동의합니다.\n",
      "test_420,\"#Person1#은 새 차를 찾고 있습니다. #Person2#는 #Person1#에게 포드 핀토를 추천하고, #Person1#은 그것이 매우 가볍고 강력한 차량이라고 생각합니다. #Person1#은 이 차를 시승하고 계약서를 작성할 것입니다.\"\n",
      "test_421,\"#Person1#은 애플 코퍼레이션의 발람씨에게 전화를 걸어 컴퓨터 엔지니어 직위를 제안하고 월급에 대해 묻습니다. 발람씨는 가족을 부양하기 위해 월 4,000 위안을 받고 싶어합니다.\"\n",
      "test_422,#Person1#은 #Person2#에게 계약의 혜택을 소개하고 네트워크 결제 서비스를 추천합니다.\n",
      "test_423,#Person1#은 배가 고파서 #Person2#에게 간식을 만들어 먹으러 가자고 제안한다.\n",
      "test_424,\"#Person1#은 #Person2#에게 피 검사를 받고, 검사 결과를 어떻게 해야 하는지 묻습니다.\"\n",
      "test_425,스티븐이 전기가 나갔습니다. 셀러 씨는 스티븐에게 지하로 내려가서 회로 상자를 찾고 퓨즈를 교체하라고 요청합니다.\n",
      "test_426,파울라는 작은 문제로 코너스 씨와의 계약에 대해 #Person2#에게 상담합니다. #Person2#는 파울라에게 문제를 해결하는 데 도움을 줍니다.\n",
      "test_427,\"#Person1#은 에어컨이 작동하지 않고, 화장실 변기와 전기 배선도 고치고 싶어합니다. #Person2#는 #Person1#에게 수리공이 그 일을 맡을 것이라고 말합니다.\"\n",
      "test_428,\"#Person1#은 일자리 찾고 싶어하고, #Person2#는 전기기사 수습생 프로그램에 대해 묻습니다.\"\n",
      "test_429,#Person2#는 사장님과의 관계를 꽤 좋다고 생각합니다.\n",
      "test_430,\"#Person1#은 탕 씨에게 투어 가이드 자격증을 요청하고, 탕 씨는 영어와 러시아어를 할 수 있다고 말합니다.\"\n",
      "test_431,#Person2#는 금 시계를 사고 싶어합니다. #Person1#은 가격이 매우 적당하다고 말합니다. #Person2#는 몇 일 전에 가격을 내렸다고 말합니다.\n",
      "test_432,\"톰이 사라에게 전화를 했는데, 그녀는 전화를 받지 않았습니다. 사라는 켄을 돌보는 데 도와줄 수 있을 것이라고 제안합니다.\"\n",
      "test_433,에이미는 #Person1#에게 그녀의 첫 직장에서의 업무 내용과 급여에 대해 이야기합니다.\n",
      "test_434,\"앤드류는 뚱뚱해졌고, 앤드류는 스팸 메일에서 와푸 다이어트에 대해 읽어본 후에 앤드류가 뚱뚱해졌다. 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤드류는 5갤런의 물을 마시고, 앤\"\n",
      "test_435,\"그렉 손더스가 메리에게 전화를 걸어 그녀의 성적, 시험 점수, 그리고 스포츠 경험에 대해 묻습니다.\"\n",
      "test_436,#Person1#은 기차역으로 가고 싶어합니다. #Person2#는 #Person1#에게 기차역으로 가는 데 20분이 걸린다고 알려줍니다.\n",
      "test_437,\"브라이언은 대학에서 영어를 배웠고, 미국에서 3주 동안 영어를 공부했습니다.\"\n",
      "test_438,\"#Person2#는 새로운 건강보험에 가입하려고 하고, #Person1#는 #Person2#에게 건강검진을 받으러 가라고 권합니다.\"\n",
      "test_439,\"#Person1#은 #Person2#에게 세계 일주를 할 계획을 말한다. #Person2#는 그것이 흥미롭지 않다고 생각하지만, #Person1#은 그것이 의미가 있다고 생각한다. #Person2#는 #Person1#에게 월급 인상을 받고 스카치를 마시자고 제안한다.\"\n",
      "test_440,\"#Person1#은 결혼할 준비가 안 됐다고 말하고, #Person2#는 #Person1#에게 에이미를 떠나고, 단지 두려움을 느끼고 있을 뿐이라고 조언한다.\"\n",
      "test_441,\"#Person1#은 명함을 인쇄하고 싶어합니다. #Person2#는 양식을 작성하라고 요청하고, 일주일 후에 그것들을 찾아갈 예정입니다.\"\n",
      "test_442,브라이언은 #Person1#에게 비행기 시간에 체크인을 하고 회의를 위해 프로그램을 준비할 것이라고 말합니다.\n",
      "test_443,\"폴은 #Person1#의 집에서 추수감사절 저녁을 먹는 것을 초대받고, 폴의 부모님이 핀란드에 가기 때문에 혼자 보내야 한다고 걱정합니다. #Person1#은 폴에게 폴의 부모님과 함께 저녁을 먹으라고 요청합니다.\"\n",
      "test_444,\"존은 수잔에게 그의 사촌을 돌보는 데 도움을 청하고, 수잔은 수잔의 사촌을 돌볼 예정이라고 말한다. 그들은 금요일 밤에 수잔의 사촌을 수잔의 집에 데려다 줄 계획이다.\"\n",
      "test_445,\"#Person1#은 벤에게 벤이 매주 토요일마다 야구를 보고 있기 때문에 꽃꽂이라는 과정을 추천한다. 벤은 그것이 너무 비싸다고 생각하지만, 그 후에 벤은 인도 요리 과정을 추천한다.\"\n",
      "test_446,\"#Person1#은 #Person2#에게 피자 체험에 가자고 제안하지만, #Person2#는 브리짓이 고기를 안 먹기 때문에 거절한다. 그들은 대신 내일 저녁에 가기로 결정한다.\"\n",
      "test_447,\"진은 #Person1#에게 로스앤젤레스에서 운전 면허 시험을 볼 예정이라고 말합니다. 그는 수업을 받고 있고, 내일 시험을 볼 예정입니다. 그는 또한 차를 사려고 계획하고 있습니다.\"\n",
      "test_448,\"#Person1#은 #Person2#에게 펜을 빌리고, #Person2#는 그것을 현금으로 결제합니다.\"\n",
      "test_449,\"#Person2#는 회사의 기금 모금 행사가 잘 진행되었으며, 그들은 미국 암 협회를 위한 마라톤을 후원할 수 있었습니다. 또한, 그들은 10달러의 입장료를 지불하고, 참가자들이 1마일을 달릴 때마다 1달러를 약속하는 후원자를 구하기 위해 집집마다 돌아다녔습니다.\"\n",
      "test_450,#Person2#는 #Person1#에게 피크 트램으로 퀸스 로드를 따라 가는 방법을 알려준다.\n",
      "test_451,#Person2#는 #Person1#의 도움으로 전통적인 중국 예술과 공예품을 몇 가지 구입했습니다.\n",
      "test_452,#Person2#는 #Person1#에게 회사가 외부 요인에 의해 영향을 받는다고 말합니다.\n",
      "test_453,\"#Person1#은 #Person2#에게 작업을 시작하도록 요청하고, #Person2#는 2시에 준비 회의를 시작할 예정입니다.\"\n",
      "test_454,\"#Person2#는 #Person1#의 도시에서 하루만 머무르게 되었고, 짧은 투어를 추천받고 싶어합니다.\"\n",
      "test_455,\"#Person2#는 바나나 맛의 버거, 프렌치 프라이, 그리고 밀크 쉐이크를 주문했습니다.\"\n",
      "test_456,\"#Person1#과 #Person2#는 등 축제에 대해 이야기하고 있습니다. 그들은 등에 적힌 퍼즐을 풀어보고, 유리로 만들어진 거대한 입과 중국 시를 봅니다.\"\n",
      "test_457,#Person1#은 ABC 컴퍼니와의 첫 두 라운드 면접에 성공적으로 통과했다. #Person1#은 티나에게 축하 파티에 초대한다.\n",
      "test_458,\"팀이 카렌을 퇴근시키고, 그들은 다시 만날 기회를 가질 예정입니다.\"\n",
      "test_459,\"#Person1#은 #Person2#에게 10시에 부서 회의가 있고, #Person2#는 #Person1#에게 문구를 준비하라고 요청합니다. #Person1#은 #Person2#에게 사본을 만들고, #Person2#는 #Person1#에게 부서 회의에서 무엇을 논의하나요?라고 물어봅니다.\"\n",
      "test_460,#Person2#는 #Person1#에게 목욕을 하기 위해 목욕을 사용하는 방법을 가르쳐줍니다.\n",
      "test_461,\"#Person2#는 #Person1#에게 베스트셀러 진열대가 어디에 있는지 알려주고, 소설을 좋아하는지 물어봅니다.\"\n",
      "test_462,#Person1#은 #Person2#에게 자신의 친구가 영어를 말할 줄 알지 모른다고 말합니다. #Person2#는 #Person1#이 자원봉사자로서 #Person2#를 가르치는 것을 칭찬합니다.\n",
      "test_463,\"#Person2#는 #Person1#이 티켓을 예약하는 것을 도와주고, 티켓 가격은 $800임을 알려줍니다.\"\n",
      "test_464,\"#Person1#은 #Person2#에게 저녁 식사를 같이 만들어 보는 것을 제안하고, #Person2#는 냉동 피자를 오븐에 넣을 계획이에요. 그들은 재료를 사고 시작할 예정입니다.\"\n",
      "test_465,\"#Person2#는 #Person1#에게 두 가지 전화기 사용법을 가르쳐주고, 둘 다 사용해보라고 권합니다.\"\n",
      "test_467,\"#Person1#은 톰에게 중고 물품에 대해 묻습니다. 톰은 중고 물품이 새 것만큼 좋다고 생각하지만, 그들은 상황에 따라 다르다고 말합니다.\"\n",
      "test_467,#Person1#은 모건에게 중국 사람들이 식당에서 남은 음식을 집으로 가져가는지 묻습니다. 모건은 중국 사람들이 적게 주문해서 식사 후에 많이 버릴 것이라고 말합니다. 모건은 중국 사람들이 식당에서 많은 음식을 주문하는 것이 중국의 전통이라고 말합니다.\n",
      "test_468,\"해리는 중국 거리 시장에서 절대로 쇼핑하지 않을 것이라고 맹세합니다. 해리는 중국 동료들이 가방을 너무 비싸게 샀다고 말해줬기 때문에 화가 되었습니다. 해리는 흥정을 통해 삼십에 살 수 있었지만, 고객에게 그렇게 높은 마진으로 과다 청구하는 것은 불편합니다.\"\n",
      "test_469,#Person1#은 영어를 쓰는 것과 말하는 것 모두에 능숙하다고 생각하는 #Person2#를 인터뷰합니다.\n",
      "test_470,\"#Person2#는 새로운 계좌를 개설하고 싶어합니다. #Person1#는 #Person2#에게 서류를 작성하라고 요청하고, 최대 $1000의 초과 인출 금액이 있지만, 1%의 이자로 벌금이 부과된다고 알려줍니다.\"\n",
      "test_471,#Person2#는 #Person1#에게 쿠폰을 받기 위해 더 많이 구매하거나 다음에 상품을 사면 쿠폰을 받을 수 있다고 말합니다.\n",
      "test_472,로빈슨 부인은 스티브에게 쟈니를 돌보는 것을 도와준다. 스티브는 쟈니가 깨끗하게 청소했다고 말한다.\n",
      "test_473,스미스 씨가 기차 표를 잃어버렸습니다. #Person1#은 스미스 씨가 편안한 좌석을 사기 위해 4마오 부족합니다.\n",
      "test_474,\"앤은 #Person1#에게 미국 여행에서의 웰빙 프로그램에 대해 이야기한다. 앤은 #Person1#에게 술이나 커피를 마시지 않았고, 고기나 기름진 음식을 먹지 않았다고 말한다.\"\n",
      "test_475,\"메리는 일자리를 찾았고, 톰은 그녀에게 아버지에게 전화해달라고 요청한다.\"\n",
      "test_476,\"해리는 차에 치였지만, #Person1#은 해리가 위험한 운전자들이 도로에 있으므로 조심해야 한다고 생각한다.\"\n",
      "test_477,\"#Person1#은 사업가들을 위한 '비즈니스 월드'에서 스티븐 케인을 인터뷰합니다. 케인은 자신의 취미를 즐기기 위해 자신의 상점을 운영하고 싶었고, 은행에 가서 사업 대출을 받았습니다. 케인은 정규 근무 시간을 지키지 않는다고 말합니다.\"\n",
      "test_478,#Person1#과 #Person2#는 중년이 아닌 좋은 중년 부부에 대해 이야기하고 있습니다.\n",
      "test_479,#Person2#는 #Person1#에게 식사가 완벽했다고 말합니다. #Person2#는 친구들과 나눠 먹고 싶어합니다. #Person1#는 #Person2#에게 디저트를 준비하고 음료를 가져다 줄 것이라고 말합니다.\n",
      "test_480,\"#Person1#과 #Person2#는 공중에서 동전을 던져서 침대를 선택하고, 책상을 어떻게 설치해야 할지 논의하고 있다.\"\n",
      "test_481,\"#Person2#는 머레이 씨의 도서관 카드를 발급하고, 카드와 안내서에 운영 시간과 제한 사항을 알려줍니다.\"\n",
      "test_482,\"#Person2#는 #Person1#에게 #Person2#의 근무 일정, 휴식 시간, 그리고 상사의 반응에 대해 이야기합니다. #Person2#는 칸막이 사무실에서 일하지만, #Person1#는 그렇지 않습니다.\"\n",
      "test_483,\"닉은 옷을 빨래하는 방법을 모르고 있고, 앨리스는 옷을 빨래하는 방법을 가르쳐주고 있습니다.\"\n",
      "test_484,\"#Person1#과 #Person2# 모두 바쁘고, 그들은 오늘 밤에 전화할 예정이다.\"\n",
      "test_485,\"#Person1#은 케이티에게 일할 준비가 되어 있지 않다고 말하고, 몇 번이나 늦게 도착했지만, 지난달에는 한 번만 늦었다고 말한다.\"\n",
      "test_486,\"#Person1#은 할아버지의 생신 파티를 위해 집에서 음식을 준비하고, #Person2#는 샐러드를 만들기로 결정했습니다. #Person1#은 목도리나 모자는 안 돼서, #Person2#는 선물로 책을 준비할 것입니다.\"\n",
      "test_487,지나와 로버트는 회의에서 서로를 소개합니다. 로버트는 지나에게 그의 친구를 소개하고 싶어합니다.\n",
      "test_488,\"캐시는 #Person2#에게 시골이 시끄러워서 놀라며, 새들의 울음소리가 2034년까지 다시는 이런 일이 없을 것이라고 말한다.\"\n",
      "test_489,#Person2#는 대니스에서 칠면조 샌드위치와 스프를 주문합니다.\n",
      "test_490,\"제임스는 #Person1#에게 짐을 싸고 있고, #Person1#은 제임스에게 카메라와 쿠키를 가져가라고 요청한다.\"\n",
      "test_491,\"테드는 아내의 부모님 집에 머무를 예정이지만, #Person1#은 중국에서 몇 주를 보낼 예정이다.\"\n",
      "test_492,#Person1#은 아빠에게 영화관에 가자고 제안한다. #Person1#은 헬렌 아주머니의 영화를 보고 싶어한다. #Person1#은 아빠와 엄마도 같이 영화관에 가자고 제안한다.\n",
      "test_493,#Person2#는 어제 밤에 도둑들이 #Person2#의 집을 털어서 화가 있습니다.\n",
      "test_494,잭이 찰리에게 비디오 게임을 제안한다. 찰리는 게임을 보고 싶어한다.\n",
      "test_495,#Person2#는 #Person1#에게 컨트리 음악에 관심을 가지게 되었을 때 어떻게 되었는지 이야기합니다.\n",
      "test_496,앨리스는 #Person1#에게 세탁기를 어떻게 사용하는지 가르쳐준다. #Person1#은 옷을 깨끗하게 하고 싶어한다. 앨리스는 #Person1#에게 옷을 빨아주는 것을 멈추라고 조언한다.\n",
      "test_497,\"스티브는 매튜에게 그의 계약이 다음 달에 끝나고, 그는 거기서 집을 찾고 있다고 말한다. 매튜는 다우 부인에게 그녀의 딸이 아기를 가지게 돼서 그녀를 도와줄 수 있을 것이라고 말한다.\"\n",
      "test_498,프랭크는 승진한 후 친구들과의 큰 파티를 열려고 합니다. 벳시는 그를 위해 와주고 싶어합니다.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kkh/prediction/submission_google-gemma-2b-it-02.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# CSV 파일로 저장\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSUBMIT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     50\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[1;32m     51\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/envs/nlp/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kkh/prediction/submission_google-gemma-2b-it-02.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# 요약을 저장할 리스트\n",
    "summaries = []\n",
    "\n",
    "# 데이터셋 전체 요약 처리\n",
    "for i, ex in enumerate(DATASET_TEST['test']['dialogue']):\n",
    "    # 각 대화마다 메시지 포맷 설정\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"다음 글을 요약해주세요:\\n\\n{}\".format(ex)\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # 프롬프트 생성\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # 요약 파이프라인\n",
    "    pipe_finetuned = pipeline(\"text-generation\", model=finetune_model, tokenizer=tokenizer, max_new_tokens=512)\n",
    "    \n",
    "    # 모델을 통해 요약 생성\n",
    "    outputs = pipe_finetuned(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        temperature=0.01,\n",
    "        top_k=20,\n",
    "        top_p=0.92,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    # 요약 텍스트 저장\n",
    "    summary = outputs[0][\"generated_text\"][len(prompt):].strip()\n",
    "    \n",
    "    # 요약에 콤마가 있으면 쌍따옴표로 감싸기\n",
    "    if ',' in summary:\n",
    "        summary = f'\"{summary}\"'\n",
    "    \n",
    "    # summaries 리스트에 저장\n",
    "    summaries.append([f\"test_{i}\", summary])\n",
    "    \n",
    "    # 요약 출력\n",
    "    # test 문제에 466번은 원래 존재하지 않음\n",
    "    if i >= 466:\n",
    "        i += 1\n",
    "    print(f\"test_{i},{summary}\")\n",
    "\n",
    "# CSV 파일로 저장\n",
    "with open(SUBMIT_PATH, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"fname\", \"summary\"])\n",
    "    writer.writerows(summaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
