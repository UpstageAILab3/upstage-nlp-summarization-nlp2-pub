{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import platform\n",
    "\n",
    "os_name = platform.system()\n",
    "if os_name == 'Windows':\n",
    "    PRE_PATH = ''\n",
    "elif os_name == 'Linux':\n",
    "    PRE_PATH = '/kkh/'\n",
    "elif os_name == 'Darwin': # 맥\n",
    "    PRE_PATH = '/kkh/'\n",
    "\n",
    "DATA_PATH = PRE_PATH + \"data/\"\n",
    "TRAIN_PATH = DATA_PATH + 'train.csv'\n",
    "DEV_PATH = DATA_PATH + 'dev.csv'\n",
    "TRAIN_NEW_PATH = DATA_PATH + 'train_new.csv'\n",
    "DEV_NEW_PATH = DATA_PATH + 'dev_new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오타, 중복 수정(train, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to /kkh/data/train_new.csv\n",
      "Processed file saved to /kkh/data/dev_new.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def replace_text(dialogue, replacements):\n",
    "    for old, new in replacements.items():\n",
    "        dialogue = re.sub(re.escape(old), new, dialogue)\n",
    "    return dialogue\n",
    "\n",
    "def process_file(input_path, output_path, replacements):\n",
    "    df = pd.read_csv(input_path)\n",
    "    df['dialogue'] = df['dialogue'].apply(lambda x: replace_text(x, replacements))\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Processed file saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the replacements\n",
    "    replacements = {\n",
    "        'ㅋㅋ': '웃겨',\n",
    "        '배경ㅇ로': '배경으로',\n",
    "        '제ㅏ': '제가',\n",
    "        '아직ㅍ알맞는': '아직 알맞는',\n",
    "        '척했ㄷ거든': '척 했거든',\n",
    "        '...': '.',\n",
    "        '!!!': '!',\n",
    "        '하하하': '하하',\n",
    "        '아아아아아아': '아아',\n",
    "        '아아아아아': '아아',\n",
    "        '아아아아': '아아',\n",
    "        '아아아': '아아',\n",
    "        '똑똑똑': '똑똑',\n",
    "        '키스스스스스': '키스',\n",
    "        '허허허': '허허',\n",
    "        '너어어어무': '너무',\n",
    "        '헤헤헤': '헤헤',\n",
    "        '으으으으': '으으',\n",
    "        '제제제': ''\n",
    "    }\n",
    "\n",
    "    # Define file paths\n",
    "    input_files = [TRAIN_PATH, DEV_PATH]\n",
    "    output_files = [TRAIN_NEW_PATH, DEV_NEW_PATH]\n",
    "\n",
    "    # Process each file\n",
    "    for input_path, output_path in zip(input_files, output_files):\n",
    "        process_file(input_path, output_path, replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오타: 원본 파일에 수정되지 않고 잘 살아 있는지 확인(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: train_3154\n",
      "Utterance: #Person1#: 속았어! ㅋㅋ.. 완전 속았어. \n",
      "----------------------------------------\n",
      "File: train_5385\n",
      "Utterance: #Person2#: 먼저, 이것은 19세기 초 배경ㅇ로 설정된 로맨스 소설이에요.\n",
      "----------------------------------------\n",
      "File: train_5429\n",
      "Utterance: #Person2#: ㅋㅋ\n",
      "----------------------------------------\n",
      "File: train_6942\n",
      "Utterance: #Person2#: 'ㅣ'로 끝나는 이탈리아 이름 같네요. \n",
      "----------------------------------------\n",
      "File: train_7201\n",
      "Utterance: #Person1#: 편집장이 제ㅏ 다른 잡지에서 편집자로 일했던 경험이 있다는 걸 듣고, 그가 도우미 편집자가 되고 싶냐고 물어봤어요.\n",
      "----------------------------------------\n",
      "File: train_9677\n",
      "Utterance: #Person1#: 이제 그만. 너는 아직ㅍ알맞는 사람을 만나지 못했을 뿐이고, 너는 너무 많이 일하는 것 같아. 너는 어떻게 즐기고 삶을 즐기는 법을 배워야 해.\n",
      "----------------------------------------\n",
      "File: train_12181\n",
      "Utterance: #Person1#: 아무것도 안 했어. 그는 결국 나갔어. 그런데 오늘 또 그를 봤어. 신발 가게 밖에서. 카페 근처에서. 나는 CD 가게에 들어가서 CD를 보는 척했ㄷ거든. 그런데 그도 들어왔어.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def find_incomplete_hangul(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'dialogue' not in df.columns:\n",
    "        raise ValueError(\"'dialogue' 열이 CSV 파일에 없습니다.\")\n",
    "    consonants_and_vowels_pattern = re.compile(r'[ㄱ-ㅎㅏ-ㅣ]+')\n",
    "    \n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        fname = row['fname']\n",
    "        dialogue = row['dialogue']\n",
    "        utterances = dialogue.split('\\n')  # 각 발화는 줄바꿈으로 구분된다고 가정\n",
    "\n",
    "        for utterance in utterances:\n",
    "            incomplete_hangul = re.findall(consonants_and_vowels_pattern, utterance)\n",
    "            if incomplete_hangul:\n",
    "                results.append((fname, utterance))\n",
    "    return results\n",
    "\n",
    "incomplete_hangul_results = find_incomplete_hangul(TRAIN_PATH)\n",
    "\n",
    "# 결과 출력\n",
    "if incomplete_hangul_results:\n",
    "    for fname, utterance in incomplete_hangul_results:\n",
    "        print(f\"File: {fname}\")\n",
    "        print(f\"Utterance: {utterance}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No incomplete Hangul characters found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오타: NEW 파일에 잘 적용되었는지 확인(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: train_6942\n",
      "Utterance: #Person2#: 'ㅣ'로 끝나는 이탈리아 이름 같네요. \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "incomplete_hangul_results = find_incomplete_hangul(TRAIN_NEW_PATH)\n",
    "\n",
    "# 결과 출력\n",
    "if incomplete_hangul_results:\n",
    "    for fname, utterance in incomplete_hangul_results:\n",
    "        print(f\"File: {fname}\")\n",
    "        print(f\"Utterance: {utterance}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No incomplete Hangul characters found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중복: 원본 파일은 수정되지 않고 잘 살아 있는지 확인(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: train_276\n",
      "Sentence: #Person1#: 헤이, 그게 뭐예요? [아아아!]\n",
      "----------------------------------------\n",
      "File: train_460\n",
      "Sentence: #Person2#: 아아아아아아\n",
      "----------------------------------------\n",
      "File: train_901\n",
      "Sentence: #Person1#: (고통 속에서 울며) 아아아!\n",
      "----------------------------------------\n",
      "File: train_998\n",
      "Sentence: #Person2#: 하하하, 너 피곤하다고 했잖아. \n",
      "----------------------------------------\n",
      "File: train_1732\n",
      "Sentence: #Person2#: 아아아아, 아아아아.\n",
      "----------------------------------------\n",
      "File: train_1907\n",
      "Sentence: #Person1#: 아아아악!\n",
      "----------------------------------------\n",
      "File: train_2464\n",
      "Sentence: #Person1#: 그냥 똑똑똑 떨어지는 정도입니다. 그것도 물이 아니죠.\n",
      "----------------------------------------\n",
      "File: train_2727\n",
      "Sentence: #Person1#: 하하하, 아마 그게 너에게 체중 감량에 도움이 될지도 몰라. \n",
      "----------------------------------------\n",
      "File: train_4271\n",
      "Sentence: #Person2#: 잭, 너의 유머 감각이 그립다. 하하하! 세상에 너처럼 사는 사람은 처음 봤다. 넌 정말 천부적이야.\n",
      "----------------------------------------\n",
      "File: train_4401\n",
      "Sentence: #Person2#: 아아아아악! 침이 고이기 시작하던 참인데!\n",
      "----------------------------------------\n",
      "File: train_5429\n",
      "Sentence: #Person2#: 고마워. 일단 안녕. 키스스스스스.\n",
      "----------------------------------------\n",
      "File: train_6260\n",
      "Sentence: #Person1#: 그래. [주먹질과 발차기와 고함과 비명을 지르는 소리 ... ] 아, 오, 맨. 아아아. 아파.\n",
      "----------------------------------------\n",
      "File: train_6563\n",
      "Sentence: #Person2#: 허허허 ... 여자들이란! \n",
      "----------------------------------------\n",
      "File: train_7662\n",
      "Sentence: #Person2#: 하하하. 미안해. 그냥 장난이었어.\n",
      "----------------------------------------\n",
      "File: train_8060\n",
      "Sentence: #Person2#: 하하하, 너 피곤하다고 했잖아. \n",
      "----------------------------------------\n",
      "File: train_8206\n",
      "Sentence: #Person1#: 하하하.\n",
      "----------------------------------------\n",
      "File: train_9608\n",
      "Sentence: #Person1#: 이런 것들은 항상 너어어어무 지루해. 아무 소문 들은거 없어? 누구 큰 돈 번 사람 없나? \n",
      "----------------------------------------\n",
      "File: train_9982\n",
      "Sentence: #Person1#: 하하하! 그렇군요, 그건 제가 받아들여야겠네요. 설명해 드릴게요, 괜찮겠습니까?\n",
      "----------------------------------------\n",
      "File: train_10295\n",
      "Sentence: #Person1#: 하하하, 어디선가 아이스 커피라도 얻을 수 있으면 좋겠다.\n",
      "----------------------------------------\n",
      "File: train_11053\n",
      "Sentence: #Person2#: 아, 그건 쉬워요. 그는 밝은 빨간색 부츠와 보라색 모자를 썼어요... 음, 당신이 쓴 것처럼. 헤헤헤...\n",
      "----------------------------------------\n",
      "File: train_11677\n",
      "Sentence: #Person1#: 으으으으!!!\n",
      "----------------------------------------\n",
      "File: train_12167\n",
      "Sentence: #Person1#: 하하하! 그래, 남자들만의 세상이지!\n",
      "----------------------------------------\n",
      "File: train_12298\n",
      "Sentence: #Person2#: 하하하! 동감이에요. 그건 재미없죠.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def find_repeated_hangul(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'dialogue' not in df.columns:\n",
    "        raise ValueError(\"'dialogue' 열이 CSV 파일에 없습니다.\")\n",
    "    repeated_hangul_pattern = re.compile(r'([가-힣])\\1{2,}')  # 동일 한글 글자가 3번 이상 연속하는 패턴\n",
    "    \n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        fname = row['fname']\n",
    "        dialogue = row['dialogue']\n",
    "        \n",
    "        sentences = dialogue.split('\\n')  # 각 문장은 줄바꿈으로 구분된다고 가정\n",
    "        for sentence in sentences:\n",
    "            repeated_hangul = re.findall(repeated_hangul_pattern, sentence)\n",
    "            if repeated_hangul:\n",
    "                results.append((fname, sentence))\n",
    "    return results\n",
    "\n",
    "\n",
    "repeated_hangul_results = find_repeated_hangul(TRAIN_PATH)\n",
    "\n",
    "# 결과 출력\n",
    "if repeated_hangul_results:\n",
    "    for fname, sentence in repeated_hangul_results:\n",
    "        print(f\"File: {fname}\")\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No repeated Hangul characters found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복: NEW 파일에 잘 적용되었는지 확인(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repeated Hangul characters found.\n"
     ]
    }
   ],
   "source": [
    "repeated_hangul_results = find_repeated_hangul(TRAIN_NEW_PATH)\n",
    "\n",
    "# 결과 출력\n",
    "if repeated_hangul_results:\n",
    "    for fname, sentence in repeated_hangul_results:\n",
    "        print(f\"File: {fname}\")\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No repeated Hangul characters found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복: NEW 파일에 잘 적용되었는지 확인(dev)\n",
    "\n",
    "- dev 원본 확인은 생략하고, 바로 dev_new만 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repeated Hangul characters found.\n"
     ]
    }
   ],
   "source": [
    "repeated_hangul_results = find_repeated_hangul(DEV_NEW_PATH)\n",
    "\n",
    "# 결과 출력\n",
    "if repeated_hangul_results:\n",
    "    for fname, sentence in repeated_hangul_results:\n",
    "        print(f\"File: {fname}\")\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No repeated Hangul characters found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 원본 데이터 행 수: 12457\n",
      "Train 필터링된 데이터 행 수: 11844\n",
      "Train 제거된 행 수: 613\n",
      "Dev 원본 데이터 행 수: 499\n",
      "Dev 필터링된 데이터 행 수: 474\n",
      "Dev 제거된 행 수: 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "\n",
    "def extract_dialogue_metrics(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    if 'dialogue' not in df.columns:\n",
    "        raise ValueError(\"'dialogue' 열이 CSV 파일에 없습니다.\")\n",
    "    \n",
    "    # 발화 수 계산 함수\n",
    "    def count_utterances(dialogue):\n",
    "        return len(re.findall(r'#Person\\d+#', dialogue))\n",
    "    \n",
    "    # 발화당 문장 수 계산 함수\n",
    "    def count_sentences_per_utterance(dialogue):\n",
    "        utterances = re.split(r'#Person\\d+#', dialogue)[1:]  # 첫 번째 요소는 빈 문자열\n",
    "        return [len(utterance.split('. ')) - 1 for utterance in utterances]\n",
    "    \n",
    "    # 대화당 단어 수 계산 함수\n",
    "    def count_words(dialogue):\n",
    "        return len(dialogue.split())\n",
    "    \n",
    "    df['utterance_count'] = df['dialogue'].apply(count_utterances)\n",
    "    df['sentence_count_per_utterance'] = df['dialogue'].apply(lambda x: sum(count_sentences_per_utterance(x)) / count_utterances(x))\n",
    "    df['word_count'] = df['dialogue'].apply(count_words)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_data(df):\n",
    "    # 주어진 조건에 따라 필터링\n",
    "    filtered_df = df[(df['utterance_count'] <= 20) &\n",
    "                     (df['sentence_count_per_utterance'] <= 2) &\n",
    "                     (df['word_count'] <= 200)]\n",
    "    return filtered_df\n",
    "\n",
    "def print_row_counts(original_df, filtered_df, label):\n",
    "    print(f\"{label} 원본 데이터 행 수: {len(original_df)}\")\n",
    "    print(f\"{label} 필터링된 데이터 행 수: {len(filtered_df)}\")\n",
    "    print(f\"{label} 제거된 행 수: {len(original_df) - len(filtered_df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os_name = platform.system()\n",
    "    if os_name == 'Windows':\n",
    "        PRE_PATH = ''\n",
    "    elif os_name == 'Linux':\n",
    "        PRE_PATH = '/kkh/'\n",
    "    elif os_name == 'Darwin':  # 맥\n",
    "        PRE_PATH = '/kkh/'\n",
    "\n",
    "    DATA_PATH = PRE_PATH + \"data/\"\n",
    "    train_file_path = DATA_PATH + 'train_new.csv'\n",
    "    dev_file_path = DATA_PATH + 'dev_new.csv'\n",
    "    \n",
    "    # Train 데이터 메트릭 추출 및 통계량 출력\n",
    "    train_df = extract_dialogue_metrics(train_file_path)\n",
    "    \n",
    "    # Dev 데이터 메트릭 추출 및 통계량 출력\n",
    "    dev_df = extract_dialogue_metrics(dev_file_path)\n",
    "    \n",
    "    # 필터링된 데이터\n",
    "    filtered_train_df = filter_data(train_df)\n",
    "    filtered_dev_df = filter_data(dev_df)\n",
    "\n",
    "    # 행 수 출력\n",
    "    print_row_counts(train_df, filtered_train_df, \"Train\")\n",
    "    print_row_counts(dev_df, filtered_dev_df, \"Dev\")\n",
    "    \n",
    "    # 필터링된 데이터 저장\n",
    "    filtered_train_df.to_csv(DATA_PATH + 'train_new2.csv', index=False)\n",
    "    filtered_dev_df.to_csv(DATA_PATH + 'dev_new2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
